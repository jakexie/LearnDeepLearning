{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#load data\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(\"/home/super-workstation/program/LearnDeepLearning/data/mnist.npz\")\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 10:27:20.645387 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0814 10:27:20.663993 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0814 10:27:20.672426 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0814 10:27:20.682118 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0814 10:27:20.686713 139894501590848 deprecation.py:506] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0814 10:27:20.709579 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0814 10:27:20.719970 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 784)\n",
      "(None, 1024)\n",
      "(None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 814,090\n",
      "Trainable params: 814,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# setup shallow network 一个隐藏层\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28))) # 展开\n",
    "print(model.output_shape)\n",
    "model.add(Dense(1024, activation='relu')) # 全连接(隐藏层1)\n",
    "print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax')) # 输出\n",
    "print(model.output_shape)\n",
    "\n",
    "sgd=SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=[\"accuracy\"]) # 编译\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.trainAndEvaluateData(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npredicts = model.predict(x_test)\\n\\nplt.figure(figsize=(10,10))\\nfor i in range(49):\\n    plt.subplot(7,7,i+1)\\n    plt.xticks([])\\n    plt.yticks([])\\n    plt.grid(False)\\n    #plt.imshow(x_test[i])#, cmap=plt.cm.binary)\\n    pred = predicts[i].tolist()\\n    pred_num = pred.index(max(pred))\\n    plt.xlabel(pred_num)\\n    plt.ylabel(y_test[i])\\n    if pred_num != y_test[i]:\\n        plt.imshow(x_test[i], cmap=plt.cm.binary)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "predicts = model.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    #plt.imshow(x_test[i])#, cmap=plt.cm.binary)\n",
    "    pred = predicts[i].tolist()\n",
    "    pred_num = pred.index(max(pred))\n",
    "    plt.xlabel(pred_num)\n",
    "    plt.ylabel(y_test[i])\n",
    "    if pred_num != y_test[i]:\n",
    "        plt.imshow(x_test[i], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 10:27:54.838543 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1-->  (None, 28, 28, 6)\n",
      "avg_pooling_1-->  (None, 14, 14, 6)\n",
      "conv2d_2-->  (None, 10, 10, 16)\n",
      "avg_pooling_2-->  (None, 5, 5, 16)\n",
      "flatten -->  (None, 400)\n",
      "full_1 -->  (None, 120)\n",
      "full_2 -->  (None, 84)\n",
      "output -->  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (!!!error)setup letnet-5 (7 layers)\n",
    "# alias avg_pooling == ap\n",
    "# conv1 + ap_1(5*5) + cov2 + ap_2(5*5) + full_1 + full_2 + output\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, AveragePooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, (5,5), padding='same', input_shape=(28,28,1))) #1\n",
    "print(\"conv2d_1--> \", model.output_shape)\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#2\n",
    "print(\"avg_pooling_1--> \", model.output_shape)\n",
    "model.add(Conv2D(16, (5,5)))#3\n",
    "print(\"conv2d_2--> \", model.output_shape)\n",
    "model.add(Dropout(0.375))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#4\n",
    "print(\"avg_pooling_2--> \", model.output_shape)\n",
    "model.add(Flatten())\n",
    "print(\"flatten --> \", model.output_shape)\n",
    "model.add(Dense(120))#5\n",
    "print(\"full_1 --> \", model.output_shape)\n",
    "model.add(Dense(84))#6\n",
    "print(\"full_2 --> \", model.output_shape)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print('output --> ', model.output_shape)#7\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.trainAndEvaluateData(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding-->  (None, 32, 32, 1)\n",
      "conv2d_1-->  (None, 28, 28, 6)\n",
      "avg_pooling_1-->  (None, 14, 14, 6)\n",
      "conv2d_2-->  (None, 10, 10, 16)\n",
      "avg_pooling_2-->  (None, 5, 5, 16)\n",
      "conv2d_3 -->  (None, 1, 1, 120)\n",
      "full_1 -->  (None, 84)\n",
      "output -->  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "rbf_layer_1 (RBFLayer)       (None, 10)                840       \n",
      "=================================================================\n",
      "Total params: 61,696\n",
      "Trainable params: 61,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######## Lenet5 1998 #########\n",
    "# (correction)setup lenet-5 (7 layers) 原始版本\n",
    "# alias avg_pooling == ap\n",
    "# conv1 + ap_1(5*5) + cov2 + ap_2(5*5) + conv_3 + full_1 + output\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, AveragePooling2D, Dropout, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(name='mu',\n",
    "                                  shape=(int(input_shape[1]), self.units),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.mu\n",
    "        l2 = K.sum(K.pow(diff,2), axis=1) # 高斯径向基函数\n",
    "        res = K.exp(-1 * self.gamma * l2) # \n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D(2, input_shape=(28,28,1)))\n",
    "print(\"padding--> \", model.output_shape) \n",
    "#1 28×28×6\n",
    "# 训练参数计算规则 （cx_size*cy_size*上一层维度（特征图个数）+1）*当前层维度\n",
    "# 连接数 当前层和上一层的连接数  训练参数个数*特征图w*特征图h\n",
    "# 训练参数 156 = （5×5+1）×6 \n",
    "# 连接数 122304 = （5×5+1）×6×（28×28）\n",
    "model.add(Conv2D(6, (5,5)))#1 \n",
    "print(\"conv2d_1--> \", model.output_shape) \n",
    "#2 14×14×6 \n",
    "#训练参数 12 6*(1+1) 当前层数（偏置+采样参数）\n",
    "#连接数 5880 = （2×2 + 1）*6*(14*14)\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#2\n",
    "print(\"avg_pooling_1--> \", model.output_shape)\n",
    "#3 10×10×16 \n",
    "#训练参数 1516 = (3*5*5+ 1)*6 + (4*5*5+1)*6 + (4*5*5+1)*3 + (6*5*5+1)\n",
    "#连接数 151600 = (3*5*5+ 1)*6×（10×10） + (4*5*5+1)*6×（10×10） + (4*5*5+1)*3*(10*10) + (6*5*5+1)*(10*10)\n",
    "model.add(Conv2D(16, (5,5)))#3\n",
    "print(\"conv2d_2--> \", model.output_shape)\n",
    "#4 5*5*16\n",
    "#训练参数 32 = 16*(1+1)\n",
    "#连接个数 2000 = （2*2*1 + 1）*6*(5*5) \n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#4\n",
    "print(\"avg_pooling_2--> \", model.output_shape)\n",
    "#5 1*1*120\n",
    "#训练参数 48120 = (5*5*16 + 1)*120\n",
    "#连接个数 48120 = (5*5*16 + 1)*120*(1*1)\n",
    "model.add(Conv2D(120, (5,5)))#5\n",
    "print(\"conv2d_3 --> \", model.output_shape)\n",
    "model.add(Flatten())\n",
    "#6 1*1*84\n",
    "#训练参数 10164 = (1*1*120+1)*84\n",
    "#连接个数 10164 = (1*1*120+1)*84*(1*1)\n",
    "model.add(Dense(84, activation='tanh'))#6\n",
    "print(\"full_1 --> \", model.output_shape)\n",
    "#7 1*1*10\n",
    "#训练参数 850 = （1*1*84+1)*10(1*1)\n",
    "#连接个数 850 = （1*1*84+1)*10(1*1)\n",
    "#model.add(Dense(10, activation='sigmoid'))#7\n",
    "model.add(RBFLayer(10,0.5))\n",
    "print('output --> ', model.output_shape)\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_data = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "test_data = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "train_label = y_train\n",
    "test_label = y_test\n",
    "\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 227, 227, 3)   (20000,)   (2000, 227, 227, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## Alexnet 2012 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 227\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "# 首次处理数据 将mnist数据集转换成需要形式（227×227×3）\n",
    "# x_train, y_train x_test y_test mnist 原始数据集\n",
    "'''\n",
    "import tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(\"/home/super-workstation/program/LearnDeepLearning/data/mnist.npz\")\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "'''\n",
    "\n",
    "alex_train_label = y_train[:train_nums]\n",
    "alex_test_label = y_test[:test_nums]\n",
    "\n",
    "alex_train_data = utils.preprocess4Alexnet(x_train, train_nums, dsize=(dims, dims))\n",
    "alex_test_data = utils.preprocess4Alexnet(x_test, test_nums, dsize=(dims, dims))\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "data_io.save_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\", \n",
    "                 alex_train_data, alex_train_label,\n",
    "                 alex_test_data, alex_test_label)\n",
    "\n",
    "\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1（input）:  (None, 55, 55, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 10:28:31.612388 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0814 10:28:31.649690 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_pool_1:  (None, 27, 27, 96)\n",
      "conv_2:  (None, 27, 27, 256)\n",
      "max_pool_2:  (None, 13, 13, 256)\n",
      "conv_3:  (None, 13, 13, 384)\n",
      "conv_4:  (None, 13, 13, 384)\n",
      "conv_5:  (None, 13, 13, 256)\n",
      "max_pool_3 (None, 6, 6, 256)\n",
      "full_1:  (None, 1, 1, 4096)\n",
      "flatten:  (None, 4096)\n",
      "full_2:  (None, 4096)\n",
      "full_3(output):  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 1, 4096)        37752832  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 62,389,762\n",
      "Trainable params: 62,389,058\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########## Alexnet 2012 ###################\n",
    "# 8 layers 5 conv + 3 maxpool + 2 full + 1 output\n",
    "# 1-2 layers: conv(11*11, 5*5) + relu + normal + maxpool\n",
    "# 3-4 layers: conv(3*3, 3*3) + relu\n",
    "# 5 layers: conv + relu + maxpool\n",
    "# 6 layers: full(4096) + relu\n",
    "# 7 layers: full(4096)\n",
    "# 8 layers: full(1000 output)\n",
    "# 9 layers: full(10) 为mnist数据额外添加（因为mnist手写数据有10个类别）\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# 1 \n",
    "# conv1\n",
    "# output dim = (227-11)/4 + 1 = 55 --> 55*55*96\n",
    "model.add(Conv2D(96, (11,11), strides=4, activation='relu', input_shape=(227, 227, 3)))\n",
    "print(\"conv_1（input）: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_1 27*27*96\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_1: \", model.output_shape)\n",
    "# 2\n",
    "# conv2 27*27*256\n",
    "model.add(Conv2D(256, (5,5), padding='same', activation='relu'))\n",
    "print(\"conv_2: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_2 13*13*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_2: \", model.output_shape)\n",
    "# 3\n",
    "# conv3 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_3: \", model.output_shape)\n",
    "# 4\n",
    "# conv4 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_4: \", model.output_shape)\n",
    "# 5\n",
    "# conv5 13*13*256\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_5: \", model.output_shape)\n",
    "# max_pool_3 6*6*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_3\", model.output_shape)\n",
    "\n",
    "# 6\n",
    "# full_1\n",
    "model.add(Conv2D(4096, (6,6), activation='relu'))\n",
    "print(\"full_1: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "print(\"flatten: \", model.output_shape)\n",
    "# 7\n",
    "# full_2\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "print(\"full_2: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "# 8\n",
    "# full_3\n",
    "#model.add(Dense(1000, activation='softmax'))\n",
    "# change for apply mnist\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))                \n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "print(\"full_3(output): \", model.output_shape)\n",
    "\n",
    "# !使用adam 会导致结果不收敛\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "loss:  0.025560790936113336\n",
      "cost:  0.989\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import cv2\n",
    "image_size = 227\n",
    "train_image = [cv2.cvtColor(cv2.resize(img,(image_size,image_size)),cv2.COLOR_GRAY2BGR) for img in x_train.astype('float32')]\n",
    "#test_image = [cv2.cvtColor(cv2.resize(img,(image_size,image_size)),cv2.COLOR_GRAY2BGR) for img in x_test]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1（input）:  (None, 111, 111, 96)\n",
      "max_pool_1:  (None, 55, 55, 96)\n",
      "conv_2:  (None, 28, 28, 256)\n",
      "max_pool_2:  (None, 13, 13, 256)\n",
      "conv_3:  (None, 13, 13, 384)\n",
      "conv_4:  (None, 13, 13, 384)\n",
      "conv_5:  (None, 13, 13, 256)\n",
      "max_pool_3 (None, 6, 6, 256)\n",
      "full_1:  (None, 1, 1, 4096)\n",
      "flatten:  (None, 4096)\n",
      "full_2:  (None, 4096)\n",
      "full_3(output):  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 111, 111, 96)      14208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 111, 111, 96)      384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 4096)        37752832  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 62,369,026\n",
      "Trainable params: 62,368,322\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########## ZFnet 2013 ###################\n",
    "# 8 layers 5 conv + 3 maxpool + 2 full + 1 output\n",
    "# 1-2 layers: conv(7*7, 5*5) + relu + normal + maxpool\n",
    "# 3-4 layers: conv(3*3, 3*3) + relu\n",
    "# 5 layers: conv + relu + maxpool\n",
    "# 6 layers: full(4096) + relu\n",
    "# 7 layers: full(4096)\n",
    "# 8 layers: full(1000 output)\n",
    "# 9 layers: full(10) 为mnist数据额外添加（因为mnist手写数据有10个类别）\n",
    "# zfnet 和 alexnet 区别在于 1，2层:\n",
    "# alexnet 1 layer: conv 11*11*96 strides=4, 227*227*3 -> 55*55*96 + maxpool 55*55*96 -> 27*27*96\n",
    "#         2 layer: conv 5*5*256 strides=1, 27*27*96 -> 27*27*256 + maxpool 27*27*256 -> 13*13*256\n",
    "# zfnet   1 layer: conv 7*7*96 strides=2 227*227*3 -> 111*111*96 + maxpool 111*111*96 -> 55*55*96\n",
    "#         2 layer: conv 5*5*256 strides=2 padding=same 55*55*96 -> 27*27*256 + maxpool --> 13*13*256\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# 1 \n",
    "# conv1\n",
    "# output dim = (227-7)/2 + 1 = 111 --> 111*111*96\n",
    "model.add(Conv2D(96, (7,7), strides=2, activation='relu', input_shape=(227, 227, 3)))\n",
    "print(\"conv_1（input）: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_1 55*55*96\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_1: \", model.output_shape)\n",
    "\n",
    "# 2\n",
    "# conv2 26*26*256\n",
    "model.add(Conv2D(256, (5,5), strides=2, padding = 'same', activation='relu'))\n",
    "print(\"conv_2: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_2 13*13*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_2: \", model.output_shape)\n",
    "\n",
    "# 3\n",
    "# conv3 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_3: \", model.output_shape)\n",
    "# 4\n",
    "# conv4 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_4: \", model.output_shape)\n",
    "# 5\n",
    "# conv5 13*13*256\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_5: \", model.output_shape)\n",
    "# max_pool_3 6*6*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_3\", model.output_shape)\n",
    "\n",
    "# 6\n",
    "# full_1\n",
    "model.add(Conv2D(4096, (6,6), activation='relu'))\n",
    "print(\"full_1: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "print(\"flatten: \", model.output_shape)\n",
    "# 7\n",
    "# full_2\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "print(\"full_2: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "# 8\n",
    "# full_3\n",
    "#model.add(Dense(1000, activation='softmax'))\n",
    "# change for apply mnist\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))                \n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "print(\"full_3(output): \", model.output_shape)\n",
    "\n",
    "# !使用adam 会导致结果不收敛\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 224, 224, 3)   (20000,)   (2000, 224, 224, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## vggxnet 2014 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 224\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "# 首次处理数据 将mnist数据集转换成需要形式（227×227×3）\n",
    "# x_train, y_train x_test y_test mnist 原始数据集\n",
    "'''\n",
    "import tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(\"/home/super-workstation/program/LearnDeepLearning/data/mnist.npz\")\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "'''\n",
    "\n",
    "alex_train_label = y_train[:train_nums]\n",
    "alex_test_label = y_test[:test_nums]\n",
    "\n",
    "alex_train_data = utils.preprocess4Alexnet(x_train, train_nums, dsize=(dims, dims))\n",
    "alex_test_data = utils.preprocess4Alexnet(x_test, test_nums, dsize=(dims, dims))\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "data_io.save_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\", \n",
    "                 alex_train_data, alex_train_label,\n",
    "                 alex_test_data, alex_test_label)\n",
    "\n",
    "\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1:  (None, 224, 224, 64)\n",
      "conv_2:  (None, 224, 224, 64)\n",
      "max_pool_1:  (None, 112, 112, 64)\n",
      "conv_3:  (None, 112, 112, 128)\n",
      "conv_4:  (None, 112, 112, 128)\n",
      "max_pool_2:  (None, 56, 56, 128)\n",
      "conv_5:  (None, 56, 56, 256)\n",
      "conv_6:  (None, 56, 56, 256)\n",
      "conv_7:  (None, 56, 56, 256)\n",
      "max_pool_3:  (None, 28, 28, 256)\n",
      "conv_8:  (None, 28, 28, 512)\n",
      "conv_9:  (None, 28, 28, 512)\n",
      "conv_10:  (None, 28, 28, 512)\n",
      "max_pool_4:  (None, 14, 14, 512)\n",
      "conv_11:  (None, 14, 14, 512)\n",
      "conv_12:  (None, 14, 14, 512)\n",
      "conv_13:  (None, 14, 14, 512)\n",
      "max_pool_5:  (None, 7, 7, 512)\n",
      "full_1:  (None, 4096)\n",
      "full_2:  (None, 4096)\n",
      "full_3:  (None, 1000)\n",
      "output:  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 56, 56, 256)       65792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 133,648,962\n",
      "Trainable params: 133,648,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# vgg 16\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "# 64\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(224,224,3)))\n",
    "print(\"conv_1: \", model.output_shape)\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_2: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_1: \", model.output_shape)\n",
    "\n",
    "#128\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_3: \", model.output_shape)\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_4: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_2: \", model.output_shape)\n",
    "\n",
    "#256\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_5: \", model.output_shape)\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_6: \", model.output_shape)\n",
    "model.add(Conv2D(256, (1,1), activation='relu', padding='same'))\n",
    "print(\"conv_7: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_3: \", model.output_shape)\n",
    "\n",
    "#512\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_8: \", model.output_shape)\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_9: \", model.output_shape)\n",
    "model.add(Conv2D(512, (1,1), activation='relu', padding='same'))\n",
    "print(\"conv_10: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_4: \", model.output_shape)\n",
    "\n",
    "#512\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_11: \", model.output_shape)\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_12: \", model.output_shape)\n",
    "model.add(Conv2D(512, (1,1), activation='relu', padding='same'))\n",
    "print(\"conv_13: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_5: \", model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "print(\"full_1: \", model.output_shape)\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "print(\"full_2: \", model.output_shape)\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "print(\"full_3: \", model.output_shape)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"output: \", model.output_shape)\n",
    "\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "20000/20000 [==============================] - 149s 7ms/step - loss: 1.9738 - acc: 0.2918\n",
      "Epoch 2/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.3118 - acc: 0.9038\n",
      "Epoch 3/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.1500 - acc: 0.9541\n",
      "Epoch 4/12\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.1074 - acc: 0.9657\n",
      "Epoch 5/12\n",
      "20000/20000 [==============================] - 138s 7ms/step - loss: 0.0859 - acc: 0.9742\n",
      "Epoch 6/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.0712 - acc: 0.9781\n",
      "Epoch 7/12\n",
      "20000/20000 [==============================] - 141s 7ms/step - loss: 0.0605 - acc: 0.9819\n",
      "Epoch 8/12\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.0519 - acc: 0.9844\n",
      "Epoch 9/12\n",
      "20000/20000 [==============================] - 141s 7ms/step - loss: 0.0432 - acc: 0.9864\n",
      "Epoch 10/12\n",
      "20000/20000 [==============================] - 142s 7ms/step - loss: 0.0392 - acc: 0.9888\n",
      "Epoch 11/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.0337 - acc: 0.9891\n",
      "Epoch 12/12\n",
      "20000/20000 [==============================] - 141s 7ms/step - loss: 0.0299 - acc: 0.9905\n",
      "2000/2000 [==============================] - 6s 3ms/step\n",
      "loss:  0.03546125781838782\n",
      "acc:  0.988\n"
     ]
    }
   ],
   "source": [
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 224, 224, 3)   (20000,)   (2000, 224, 224, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## googLenet 2014 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 224\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 112, 112, 64) 9472        input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_152 (MaxPooling2D (None, 56, 56, 64)   0           conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 56, 56, 64)   256         max_pooling2d_152[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 56, 56, 64)   4160        batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 56, 56, 192)  110784      conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 56, 56, 192)  768         conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_153 (MaxPooling2D (None, 28, 28, 192)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 28, 28, 96)   18528       max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 28, 28, 16)   3088        max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 28, 28, 96)   384         conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 28, 28, 16)   64          conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 28, 28, 96)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 28, 28, 16)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_154 (MaxPooling2D (None, 28, 28, 192)  0           max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 28, 28, 64)   12352       max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 28, 28, 128)  110720      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 28, 28, 32)   12832       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 28, 28, 32)   6176        max_pooling2d_154[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 28, 28, 64)   256         conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 28, 28, 128)  512         conv2d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 28, 28, 32)   128         conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 28, 28, 32)   128         conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 28, 28, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 28, 28, 128)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 28, 28, 32)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 28, 28, 32)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 28, 28, 256)  0           activation_169[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 28, 28, 128)  32896       concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_673 (Conv2D)             (None, 28, 28, 32)   8224        concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 28, 28, 128)  512         conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 28, 28, 32)   128         conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 28, 28, 128)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 28, 28, 32)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_155 (MaxPooling2D (None, 28, 28, 256)  0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 28, 28, 128)  32896       concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 28, 28, 192)  221376      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 28, 28, 96)   76896       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 28, 28, 64)   16448       max_pooling2d_155[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 28, 28, 128)  512         conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 28, 28, 192)  768         conv2d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 28, 28, 96)   384         conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 28, 28, 64)   256         conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 28, 28, 128)  0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 28, 28, 192)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 28, 28, 96)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 28, 28, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 28, 28, 480)  0           activation_175[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "                                                                 activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_156 (MaxPooling2D (None, 14, 14, 480)  0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_677 (Conv2D)             (None, 14, 14, 96)   46176       max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_679 (Conv2D)             (None, 14, 14, 16)   7696        max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 14, 14, 96)   384         conv2d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 14, 14, 16)   64          conv2d_679[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 14, 14, 96)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 14, 14, 16)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_157 (MaxPooling2D (None, 14, 14, 480)  0           max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 14, 14, 192)  92352       max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_678 (Conv2D)             (None, 14, 14, 208)  179920      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_680 (Conv2D)             (None, 14, 14, 48)   19248       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_681 (Conv2D)             (None, 14, 14, 64)   30784       max_pooling2d_157[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 14, 14, 192)  768         conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 14, 14, 208)  832         conv2d_678[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 14, 14, 48)   192         conv2d_680[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 14, 14, 64)   256         conv2d_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 14, 14, 192)  0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 14, 14, 208)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 14, 14, 48)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 14, 14, 64)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 14, 14, 512)  0           activation_181[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "                                                                 activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_684 (Conv2D)             (None, 14, 14, 112)  57456       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_686 (Conv2D)             (None, 14, 14, 24)   12312       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 14, 14, 112)  448         conv2d_684[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 14, 14, 24)   96          conv2d_686[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 14, 14, 112)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 14, 14, 24)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_158 (MaxPooling2D (None, 14, 14, 512)  0           concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_683 (Conv2D)             (None, 14, 14, 160)  82080       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_685 (Conv2D)             (None, 14, 14, 224)  226016      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_687 (Conv2D)             (None, 14, 14, 64)   38464       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_688 (Conv2D)             (None, 14, 14, 64)   32832       max_pooling2d_158[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 14, 14, 160)  640         conv2d_683[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 14, 14, 224)  896         conv2d_685[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 14, 14, 64)   256         conv2d_687[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 14, 14, 64)   256         conv2d_688[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 14, 14, 160)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 14, 14, 224)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 14, 14, 64)   0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 14, 14, 64)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 14, 14, 512)  0           activation_188[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "                                                                 activation_192[0][0]             \n",
      "                                                                 activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_690 (Conv2D)             (None, 14, 14, 128)  65664       concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_692 (Conv2D)             (None, 14, 14, 24)   12312       concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 14, 14, 128)  512         conv2d_690[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 14, 14, 24)   96          conv2d_692[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 14, 14, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 14, 14, 24)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_159 (MaxPooling2D (None, 14, 14, 512)  0           concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_689 (Conv2D)             (None, 14, 14, 128)  65664       concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_691 (Conv2D)             (None, 14, 14, 256)  295168      activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_693 (Conv2D)             (None, 14, 14, 64)   38464       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_694 (Conv2D)             (None, 14, 14, 64)   32832       max_pooling2d_159[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 14, 14, 128)  512         conv2d_689[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 14, 14, 256)  1024        conv2d_691[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 14, 14, 64)   256         conv2d_693[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 14, 14, 64)   256         conv2d_694[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 14, 14, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 14, 14, 256)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 14, 14, 64)   0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 14, 14, 64)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 14, 14, 512)  0           activation_194[0][0]             \n",
      "                                                                 activation_196[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_696 (Conv2D)             (None, 14, 14, 114)  58482       concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_698 (Conv2D)             (None, 14, 14, 32)   16416       concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 14, 14, 114)  456         conv2d_696[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 14, 14, 32)   128         conv2d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 14, 14, 114)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 14, 14, 32)   0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_160 (MaxPooling2D (None, 14, 14, 512)  0           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_695 (Conv2D)             (None, 14, 14, 112)  57456       concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_697 (Conv2D)             (None, 14, 14, 288)  295776      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_699 (Conv2D)             (None, 14, 14, 64)   51264       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_700 (Conv2D)             (None, 14, 14, 64)   32832       max_pooling2d_160[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 14, 14, 112)  448         conv2d_695[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 14, 14, 288)  1152        conv2d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 14, 14, 64)   256         conv2d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 14, 14, 64)   256         conv2d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 14, 14, 112)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 14, 14, 288)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 14, 14, 64)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 14, 14, 64)   0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 14, 14, 528)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_204[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_703 (Conv2D)             (None, 14, 14, 160)  84640       concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_705 (Conv2D)             (None, 14, 14, 32)   16928       concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 14, 14, 160)  640         conv2d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 14, 14, 32)   128         conv2d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 14, 14, 160)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 14, 14, 32)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_161 (MaxPooling2D (None, 14, 14, 528)  0           concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_702 (Conv2D)             (None, 14, 14, 256)  135424      concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_704 (Conv2D)             (None, 14, 14, 320)  461120      activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_706 (Conv2D)             (None, 14, 14, 128)  102528      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_707 (Conv2D)             (None, 14, 14, 128)  67712       max_pooling2d_161[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 14, 14, 256)  1024        conv2d_702[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 14, 14, 320)  1280        conv2d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 14, 14, 128)  512         conv2d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 14, 14, 128)  512         conv2d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 14, 14, 256)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 14, 14, 320)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 14, 14, 128)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 14, 14, 128)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 14, 14, 832)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_211[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_162 (MaxPooling2D (None, 7, 7, 832)    0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_709 (Conv2D)             (None, 7, 7, 160)    133280      max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_711 (Conv2D)             (None, 7, 7, 32)     26656       max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    640         conv2d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 32)     128         conv2d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 7, 7, 32)     0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_163 (MaxPooling2D (None, 7, 7, 832)    0           max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_708 (Conv2D)             (None, 7, 7, 256)    213248      max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_710 (Conv2D)             (None, 7, 7, 320)    461120      activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_712 (Conv2D)             (None, 7, 7, 128)    102528      activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_713 (Conv2D)             (None, 7, 7, 128)    106624      max_pooling2d_163[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 256)    1024        conv2d_708[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 320)    1280        conv2d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 128)    512         conv2d_712[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 128)    512         conv2d_713[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 7, 7, 256)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 7, 7, 320)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 128)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 128)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 7, 7, 832)    0           activation_213[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_715 (Conv2D)             (None, 7, 7, 192)    159936      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_717 (Conv2D)             (None, 7, 7, 48)     39984       concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    768         conv2d_715[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 48)     192         conv2d_717[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 48)     0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_164 (MaxPooling2D (None, 7, 7, 832)    0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_714 (Conv2D)             (None, 7, 7, 384)    319872      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_716 (Conv2D)             (None, 7, 7, 384)    663936      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_718 (Conv2D)             (None, 7, 7, 128)    153728      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_719 (Conv2D)             (None, 7, 7, 128)    106624      max_pooling2d_164[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 384)    1536        conv2d_714[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 384)    1536        conv2d_716[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 128)    512         conv2d_718[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 128)    512         conv2d_719[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 384)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 384)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 7, 7, 1024)   0           activation_219[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_223[0][0]             \n",
      "                                                                 activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePo (None, 1, 1, 1024)   0           concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1, 1, 1024)   0           average_pooling2d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 1024)         0           dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 1000)         1025000     flatten_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000)         0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 10)           10010       dropout_63[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,944,156\n",
      "Trainable params: 6,929,784\n",
      "Non-trainable params: 14,372\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#google net 2014\n",
    "# 训练时需要副分类器， 预测时无视\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, AveragePooling2D, Dense, Flatten\n",
    "from keras.layers import BatchNormalization, Input, Dropout, Activation\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def getMaxPool(input):\n",
    "    return MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(input)\n",
    "\n",
    "# conv strides=1 padding=same\n",
    "# maxpool size(3,3) strides=2 padding='same'\n",
    "# nums --> nums of filter for special size(1x1, 3x3, 5x5, pool)\n",
    "def Inception(input, nums_11, nums_11_33, nums_33, nums_11_55, nums_55, nums_11_pool):\n",
    "    conv_11 = conv2d_bn(input, nums_11, (1,1))\n",
    "    \n",
    "    conv_11_33 = conv2d_bn(input, nums_11_33, (1,1))\n",
    "    conv_33 = conv2d_bn(conv_11_33, nums_33, (3,3))\n",
    "    \n",
    "    conv_11_55 = conv2d_bn(input, nums_11_55, (1,1))\n",
    "    conv_55 = conv2d_bn(conv_11_55, nums_55, (5,5))\n",
    "    \n",
    "    conv_max_pool = getMaxPool(input)\n",
    "    conv_max_pool_11 = conv2d_bn(conv_max_pool, nums_11_pool, (1,1))\n",
    "    \n",
    "    output = keras.layers.concatenate([conv_11, conv_33, conv_55, conv_max_pool_11], axis=-1)\n",
    "    return output\n",
    "\n",
    "def AuxiliaryClassifier(input):\n",
    "    x = AveragePooling2D(pool_size=(5, 5), strides=3)(input)\n",
    "    x = conv2d_bn(x, 128, (1,1))\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    #output = Dense(1000, activation='softmax')(x)\n",
    "    # add 1 full layer for mnist\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    output = Dense(10, activation = 'softmax')(x)\n",
    "    return output\n",
    "\n",
    "def MainClassifier(input):\n",
    "    x = AveragePooling2D(pool_size=(7, 7), strides=1)(input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    #output = Dense(1000, activation='softmax')(x)\n",
    "    # add 1 full layer for mnist\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    return output\n",
    "    \n",
    "    \n",
    "input = Input(shape=(224, 224, 3))\n",
    "x = Conv2D(64, (7,7), strides=2, padding='same', activation='relu')(input)\n",
    "#x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, (1,1), activation='relu')(x)\n",
    "x = Conv2D(192, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "\n",
    "# inception_3a\n",
    "x = Inception(x, 64, 96, 128, 16, 32, 32)\n",
    "# inception_3b\n",
    "x = Inception(x, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "\n",
    "# inception_4a\n",
    "x = Inception(x, 192, 96, 208, 16, 48, 64)\n",
    "# Auxiliary Classifier 0\n",
    "softmax0 = AuxiliaryClassifier(x)\n",
    "# inception_4b\n",
    "x = Inception(x, 160, 112, 224, 24, 64, 64)\n",
    "# inception_4c\n",
    "x = Inception(x, 128, 128, 256, 24, 64, 64)\n",
    "# inception_4d\n",
    "x = Inception(x, 112, 114, 288, 32, 64, 64)\n",
    "# Auxiliary Classifier 1\n",
    "softmax1 = AuxiliaryClassifier(x)\n",
    "# inception_4e\n",
    "x = Inception(x, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "\n",
    "# inception_5a\n",
    "x = Inception(x, 256, 160, 320, 32, 128, 128)\n",
    "# inception_5b\n",
    "x = Inception(x, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "# Main classifier\n",
    "softmax2 = MainClassifier(x)\n",
    "\n",
    "#[softmax0, softmax1, softmax2]\n",
    "model = Model(input, outputs=softmax2, name=\"googLenet\")\n",
    "#model.build(input)\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.get_config()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "18000/18000 [==============================] - 57s 3ms/step - loss: 0.1535 - acc: 0.9584 - val_loss: 0.0540 - val_acc: 0.9815\n",
      "Epoch 2/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0715 - acc: 0.9806 - val_loss: 0.0545 - val_acc: 0.9845\n",
      "Epoch 3/12\n",
      "18000/18000 [==============================] - 56s 3ms/step - loss: 0.0547 - acc: 0.9844 - val_loss: 0.0599 - val_acc: 0.9820\n",
      "Epoch 4/12\n",
      "18000/18000 [==============================] - 54s 3ms/step - loss: 0.0401 - acc: 0.9883 - val_loss: 0.0693 - val_acc: 0.9795\n",
      "Epoch 5/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0314 - acc: 0.9911 - val_loss: 0.1001 - val_acc: 0.9705\n",
      "Epoch 6/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0219 - acc: 0.9933 - val_loss: 0.1082 - val_acc: 0.9690\n",
      "Epoch 7/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0188 - acc: 0.9943 - val_loss: 0.0434 - val_acc: 0.9880\n",
      "Epoch 8/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0134 - acc: 0.9969 - val_loss: 0.0247 - val_acc: 0.9925\n",
      "Epoch 9/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0346 - val_acc: 0.9905\n",
      "Epoch 10/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0263 - val_acc: 0.9915\n",
      "Epoch 11/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0340 - val_acc: 0.9895\n",
      "Epoch 12/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0440 - val_acc: 0.9880\n",
      "2000/2000 [==============================] - 3s 1ms/step\n",
      "loss:  0.06674277622526278\n",
      "acc:  0.9765\n"
     ]
    }
   ],
   "source": [
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 224, 224, 3)   (20000,)   (2000, 224, 224, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## googLenet 2014 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 224\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 112, 112, 64) 9472        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 112, 112, 64) 256         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 112, 112, 64) 0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 56, 56, 64)   0           activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 56, 56, 64)   36928       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 56, 56, 64)   256         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 56, 56, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 56, 56, 64)   36928       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 56, 56, 64)   4160        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 56, 56, 64)   256         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 56, 56, 64)   256         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 56, 56, 64)   0           batch_normalization_212[0][0]    \n",
      "                                                                 batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 56, 56, 64)   0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 56, 56, 64)   36928       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 56, 56, 64)   256         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 56, 56, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 56, 56, 64)   36928       activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 56, 56, 64)   256         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 56, 56, 64)   256         activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 56, 56, 64)   0           batch_normalization_215[0][0]    \n",
      "                                                                 batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 56, 56, 64)   0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 56, 56, 64)   36928       activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 56, 56, 64)   256         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 56, 56, 64)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 56, 56, 64)   36928       activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 56, 56, 64)   256         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 56, 56, 64)   256         activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 56, 56, 64)   0           batch_normalization_218[0][0]    \n",
      "                                                                 batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 56, 56, 64)   0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 28, 28, 128)  73856       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 28, 28, 128)  512         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 28, 28, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 28, 28, 128)  147584      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 28, 28, 128)  8320        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 28, 28, 128)  512         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 28, 28, 128)  512         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 28, 28, 128)  0           batch_normalization_221[0][0]    \n",
      "                                                                 batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 28, 28, 128)  0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 28, 28, 128)  147584      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 28, 28, 128)  512         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 28, 28, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 28, 28, 128)  147584      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 28, 28, 128)  512         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 28, 28, 128)  512         activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 28, 28, 128)  0           batch_normalization_224[0][0]    \n",
      "                                                                 batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 28, 28, 128)  0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 28, 28, 128)  147584      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 28, 28, 128)  512         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 28, 28, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 28, 28, 128)  147584      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 28, 28, 128)  512         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 28, 28, 128)  512         activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 28, 28, 128)  0           batch_normalization_227[0][0]    \n",
      "                                                                 batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 28, 28, 128)  0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 28, 28, 128)  147584      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 28, 28, 128)  512         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 28, 28, 128)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 28, 28, 128)  147584      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 28, 28, 128)  512         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 28, 28, 128)  512         activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 28, 28, 128)  0           batch_normalization_230[0][0]    \n",
      "                                                                 batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 28, 28, 128)  0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 14, 14, 256)  295168      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 14, 14, 256)  1024        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 14, 256)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 14, 14, 256)  590080      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 14, 14, 256)  33024       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 14, 14, 256)  1024        conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 14, 14, 256)  1024        conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 14, 14, 256)  0           batch_normalization_233[0][0]    \n",
      "                                                                 batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 14, 14, 256)  0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 14, 14, 256)  590080      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 14, 14, 256)  1024        conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 14, 256)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 14, 14, 256)  590080      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 14, 14, 256)  1024        conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 14, 14, 256)  1024        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 14, 14, 256)  0           batch_normalization_236[0][0]    \n",
      "                                                                 batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 14, 14, 256)  0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 14, 14, 256)  590080      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 14, 14, 256)  1024        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 14, 14, 256)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 14, 14, 256)  590080      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 14, 14, 256)  1024        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 14, 14, 256)  1024        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 14, 14, 256)  0           batch_normalization_239[0][0]    \n",
      "                                                                 batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 14, 14, 256)  0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 14, 14, 256)  590080      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 14, 14, 256)  1024        conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 14, 14, 256)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 14, 14, 256)  590080      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 14, 14, 256)  1024        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 14, 14, 256)  1024        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 14, 14, 256)  0           batch_normalization_242[0][0]    \n",
      "                                                                 batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 256)  0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 14, 14, 256)  590080      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 14, 14, 256)  1024        conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 256)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 14, 14, 256)  590080      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 14, 14, 256)  1024        conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 14, 14, 256)  1024        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 14, 14, 256)  0           batch_normalization_245[0][0]    \n",
      "                                                                 batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 14, 14, 256)  0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 14, 14, 256)  590080      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 14, 14, 256)  1024        conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 14, 14, 256)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 14, 14, 256)  590080      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 14, 14, 256)  1024        conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 14, 14, 256)  1024        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 14, 14, 256)  0           batch_normalization_248[0][0]    \n",
      "                                                                 batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 14, 14, 256)  0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 512)    1180160     activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 512)    2048        conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 512)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 512)    2359808     activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 512)    131584      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 512)    2048        conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 512)    2048        conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 7, 7, 512)    0           batch_normalization_251[0][0]    \n",
      "                                                                 batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 512)    0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 512)    2359808     activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 512)    2048        conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 512)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 512)    2359808     activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 512)    2048        conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 512)    2048        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 7, 7, 512)    0           batch_normalization_254[0][0]    \n",
      "                                                                 batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 7, 7, 512)    0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 512)    2359808     activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 512)    2048        conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 7, 7, 512)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 512)    2359808     activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 512)    2048        conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 512)    2048        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 7, 7, 512)    0           batch_normalization_257[0][0]    \n",
      "                                                                 batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 7, 7, 512)    0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 512)    0           activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1, 1, 512)    0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 512)          0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1000)         513000      flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000)         0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10)           10010       dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,848,898\n",
      "Trainable params: 21,826,114\n",
      "Non-trainable params: 22,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet 2015\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# 匹配输入尺度和输出尺度\n",
    "# 每个convn_x 第一层调用\n",
    "def conv_block34(input, filter_nums1, filter_nums2, strides=2):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (3,3), strides=strides)\n",
    "    x = Conv2D(filter_nums2, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = Conv2D(filter_nums2, (1,1), strides=strides)(input)\n",
    "    short_cut = BatchNormalization()(short_cut)\n",
    "    # add\n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# identity mapping\n",
    "# 紧接conv_block34 调用\n",
    "def identity_block34(input, filter_nums1, filter_nums2):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (3,3))\n",
    "    x = Conv2D(filter_nums2, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = BatchNormalization()(input)\n",
    "    \n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# 匹配输入尺度和输出尺度\n",
    "# 每个convn_x 第一层调用\n",
    "def conv_block(input, filter_nums1, filter_nums2, filter_nums3, strides=2):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (1,1), strides=strides)\n",
    "    x = conv2d_bn(x, filter_nums2, (3,3))\n",
    "    x = Conv2D(filter_nums3, (1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = Conv2D(filter_nums3, (1,1), strides=strides)(input)\n",
    "    short_cut = BatchNormalization()(short_cut)\n",
    "    # add\n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# identity mapping\n",
    "# 紧接conv_block 调用\n",
    "def identity_block(input, filter_nums1, filter_nums2, filter_nums3):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (1,1))\n",
    "    x = conv2d_bn(x, filter_nums2, (3,3))\n",
    "    x = Conv2D(filter_nums3, (1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = BatchNormalization()(input)\n",
    "    \n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def full_block(input):\n",
    "    x = AveragePooling2D(pool_size=(7,7))(input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_19 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_348 (Conv2D)             (None, 112, 112, 64) 9472        input_19[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_403 (BatchN (None, 112, 112, 64) 256         conv2d_348[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_279 (Activation)     (None, 112, 112, 64) 0           batch_normalization_403[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_27 (MaxPooling2D) (None, 56, 56, 64)   0           activation_279[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_349 (Conv2D)             (None, 56, 56, 64)   36928       max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_404 (BatchN (None, 56, 56, 64)   256         conv2d_349[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_280 (Activation)     (None, 56, 56, 64)   0           batch_normalization_404[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_350 (Conv2D)             (None, 56, 56, 64)   36928       activation_280[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_351 (Conv2D)             (None, 56, 56, 64)   4160        max_pooling2d_27[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_405 (BatchN (None, 56, 56, 64)   256         conv2d_350[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_406 (BatchN (None, 56, 56, 64)   256         conv2d_351[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_115 (Add)                   (None, 56, 56, 64)   0           batch_normalization_405[0][0]    \n",
      "                                                                 batch_normalization_406[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_281 (Activation)     (None, 56, 56, 64)   0           add_115[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_352 (Conv2D)             (None, 56, 56, 64)   36928       activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_407 (BatchN (None, 56, 56, 64)   256         conv2d_352[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_282 (Activation)     (None, 56, 56, 64)   0           batch_normalization_407[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_353 (Conv2D)             (None, 56, 56, 64)   36928       activation_282[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_408 (BatchN (None, 56, 56, 64)   256         conv2d_353[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_409 (BatchN (None, 56, 56, 64)   256         activation_281[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_116 (Add)                   (None, 56, 56, 64)   0           batch_normalization_408[0][0]    \n",
      "                                                                 batch_normalization_409[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_283 (Activation)     (None, 56, 56, 64)   0           add_116[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_354 (Conv2D)             (None, 56, 56, 64)   36928       activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_410 (BatchN (None, 56, 56, 64)   256         conv2d_354[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_284 (Activation)     (None, 56, 56, 64)   0           batch_normalization_410[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_355 (Conv2D)             (None, 56, 56, 64)   36928       activation_284[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_411 (BatchN (None, 56, 56, 64)   256         conv2d_355[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_412 (BatchN (None, 56, 56, 64)   256         activation_283[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_117 (Add)                   (None, 56, 56, 64)   0           batch_normalization_411[0][0]    \n",
      "                                                                 batch_normalization_412[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_285 (Activation)     (None, 56, 56, 64)   0           add_117[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_356 (Conv2D)             (None, 28, 28, 128)  73856       activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_413 (BatchN (None, 28, 28, 128)  512         conv2d_356[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_286 (Activation)     (None, 28, 28, 128)  0           batch_normalization_413[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_357 (Conv2D)             (None, 28, 28, 128)  147584      activation_286[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_358 (Conv2D)             (None, 28, 28, 128)  8320        activation_285[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_414 (BatchN (None, 28, 28, 128)  512         conv2d_357[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_415 (BatchN (None, 28, 28, 128)  512         conv2d_358[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_118 (Add)                   (None, 28, 28, 128)  0           batch_normalization_414[0][0]    \n",
      "                                                                 batch_normalization_415[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_287 (Activation)     (None, 28, 28, 128)  0           add_118[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_359 (Conv2D)             (None, 28, 28, 128)  147584      activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_416 (BatchN (None, 28, 28, 128)  512         conv2d_359[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_288 (Activation)     (None, 28, 28, 128)  0           batch_normalization_416[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_360 (Conv2D)             (None, 28, 28, 128)  147584      activation_288[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_417 (BatchN (None, 28, 28, 128)  512         conv2d_360[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_418 (BatchN (None, 28, 28, 128)  512         activation_287[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_119 (Add)                   (None, 28, 28, 128)  0           batch_normalization_417[0][0]    \n",
      "                                                                 batch_normalization_418[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_289 (Activation)     (None, 28, 28, 128)  0           add_119[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_361 (Conv2D)             (None, 28, 28, 128)  147584      activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_419 (BatchN (None, 28, 28, 128)  512         conv2d_361[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_290 (Activation)     (None, 28, 28, 128)  0           batch_normalization_419[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_362 (Conv2D)             (None, 28, 28, 128)  147584      activation_290[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_420 (BatchN (None, 28, 28, 128)  512         conv2d_362[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_421 (BatchN (None, 28, 28, 128)  512         activation_289[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_120 (Add)                   (None, 28, 28, 128)  0           batch_normalization_420[0][0]    \n",
      "                                                                 batch_normalization_421[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_291 (Activation)     (None, 28, 28, 128)  0           add_120[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_363 (Conv2D)             (None, 28, 28, 128)  147584      activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_422 (BatchN (None, 28, 28, 128)  512         conv2d_363[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_292 (Activation)     (None, 28, 28, 128)  0           batch_normalization_422[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_364 (Conv2D)             (None, 28, 28, 128)  147584      activation_292[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_423 (BatchN (None, 28, 28, 128)  512         conv2d_364[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_424 (BatchN (None, 28, 28, 128)  512         activation_291[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_121 (Add)                   (None, 28, 28, 128)  0           batch_normalization_423[0][0]    \n",
      "                                                                 batch_normalization_424[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_293 (Activation)     (None, 28, 28, 128)  0           add_121[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_365 (Conv2D)             (None, 14, 14, 256)  295168      activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_425 (BatchN (None, 14, 14, 256)  1024        conv2d_365[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_294 (Activation)     (None, 14, 14, 256)  0           batch_normalization_425[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_366 (Conv2D)             (None, 14, 14, 256)  590080      activation_294[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_367 (Conv2D)             (None, 14, 14, 256)  33024       activation_293[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_426 (BatchN (None, 14, 14, 256)  1024        conv2d_366[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_427 (BatchN (None, 14, 14, 256)  1024        conv2d_367[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_122 (Add)                   (None, 14, 14, 256)  0           batch_normalization_426[0][0]    \n",
      "                                                                 batch_normalization_427[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_295 (Activation)     (None, 14, 14, 256)  0           add_122[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_368 (Conv2D)             (None, 14, 14, 256)  590080      activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_428 (BatchN (None, 14, 14, 256)  1024        conv2d_368[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_296 (Activation)     (None, 14, 14, 256)  0           batch_normalization_428[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_369 (Conv2D)             (None, 14, 14, 256)  590080      activation_296[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_429 (BatchN (None, 14, 14, 256)  1024        conv2d_369[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_430 (BatchN (None, 14, 14, 256)  1024        activation_295[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_123 (Add)                   (None, 14, 14, 256)  0           batch_normalization_429[0][0]    \n",
      "                                                                 batch_normalization_430[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_297 (Activation)     (None, 14, 14, 256)  0           add_123[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_370 (Conv2D)             (None, 14, 14, 256)  590080      activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_431 (BatchN (None, 14, 14, 256)  1024        conv2d_370[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_298 (Activation)     (None, 14, 14, 256)  0           batch_normalization_431[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_371 (Conv2D)             (None, 14, 14, 256)  590080      activation_298[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_432 (BatchN (None, 14, 14, 256)  1024        conv2d_371[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_433 (BatchN (None, 14, 14, 256)  1024        activation_297[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_124 (Add)                   (None, 14, 14, 256)  0           batch_normalization_432[0][0]    \n",
      "                                                                 batch_normalization_433[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_299 (Activation)     (None, 14, 14, 256)  0           add_124[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_372 (Conv2D)             (None, 14, 14, 256)  590080      activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_434 (BatchN (None, 14, 14, 256)  1024        conv2d_372[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_300 (Activation)     (None, 14, 14, 256)  0           batch_normalization_434[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_373 (Conv2D)             (None, 14, 14, 256)  590080      activation_300[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_435 (BatchN (None, 14, 14, 256)  1024        conv2d_373[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_436 (BatchN (None, 14, 14, 256)  1024        activation_299[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_125 (Add)                   (None, 14, 14, 256)  0           batch_normalization_435[0][0]    \n",
      "                                                                 batch_normalization_436[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_301 (Activation)     (None, 14, 14, 256)  0           add_125[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_374 (Conv2D)             (None, 14, 14, 256)  590080      activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_437 (BatchN (None, 14, 14, 256)  1024        conv2d_374[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_302 (Activation)     (None, 14, 14, 256)  0           batch_normalization_437[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_375 (Conv2D)             (None, 14, 14, 256)  590080      activation_302[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_438 (BatchN (None, 14, 14, 256)  1024        conv2d_375[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_439 (BatchN (None, 14, 14, 256)  1024        activation_301[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_126 (Add)                   (None, 14, 14, 256)  0           batch_normalization_438[0][0]    \n",
      "                                                                 batch_normalization_439[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_303 (Activation)     (None, 14, 14, 256)  0           add_126[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_376 (Conv2D)             (None, 14, 14, 256)  590080      activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_440 (BatchN (None, 14, 14, 256)  1024        conv2d_376[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_304 (Activation)     (None, 14, 14, 256)  0           batch_normalization_440[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_377 (Conv2D)             (None, 14, 14, 256)  590080      activation_304[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_441 (BatchN (None, 14, 14, 256)  1024        conv2d_377[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_442 (BatchN (None, 14, 14, 256)  1024        activation_303[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_127 (Add)                   (None, 14, 14, 256)  0           batch_normalization_441[0][0]    \n",
      "                                                                 batch_normalization_442[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_305 (Activation)     (None, 14, 14, 256)  0           add_127[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_378 (Conv2D)             (None, 7, 7, 512)    1180160     activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_443 (BatchN (None, 7, 7, 512)    2048        conv2d_378[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_306 (Activation)     (None, 7, 7, 512)    0           batch_normalization_443[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_379 (Conv2D)             (None, 7, 7, 512)    2359808     activation_306[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_380 (Conv2D)             (None, 7, 7, 512)    131584      activation_305[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_444 (BatchN (None, 7, 7, 512)    2048        conv2d_379[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_445 (BatchN (None, 7, 7, 512)    2048        conv2d_380[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_128 (Add)                   (None, 7, 7, 512)    0           batch_normalization_444[0][0]    \n",
      "                                                                 batch_normalization_445[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_307 (Activation)     (None, 7, 7, 512)    0           add_128[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_381 (Conv2D)             (None, 7, 7, 512)    2359808     activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_446 (BatchN (None, 7, 7, 512)    2048        conv2d_381[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_308 (Activation)     (None, 7, 7, 512)    0           batch_normalization_446[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_382 (Conv2D)             (None, 7, 7, 512)    2359808     activation_308[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_447 (BatchN (None, 7, 7, 512)    2048        conv2d_382[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_448 (BatchN (None, 7, 7, 512)    2048        activation_307[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_129 (Add)                   (None, 7, 7, 512)    0           batch_normalization_447[0][0]    \n",
      "                                                                 batch_normalization_448[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_309 (Activation)     (None, 7, 7, 512)    0           add_129[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_383 (Conv2D)             (None, 7, 7, 512)    2359808     activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_449 (BatchN (None, 7, 7, 512)    2048        conv2d_383[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_310 (Activation)     (None, 7, 7, 512)    0           batch_normalization_449[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_384 (Conv2D)             (None, 7, 7, 512)    2359808     activation_310[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_450 (BatchN (None, 7, 7, 512)    2048        conv2d_384[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_451 (BatchN (None, 7, 7, 512)    2048        activation_309[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_130 (Add)                   (None, 7, 7, 512)    0           batch_normalization_450[0][0]    \n",
      "                                                                 batch_normalization_451[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_311 (Activation)     (None, 7, 7, 512)    0           add_130[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_10 (AveragePo (None, 1, 1, 512)    0           activation_311[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_16 (Dropout)            (None, 1, 1, 512)    0           average_pooling2d_10[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_12 (Flatten)            (None, 512)          0           dropout_16[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_27 (Dense)                (None, 1000)         513000      flatten_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_17 (Dropout)            (None, 1000)         0           dense_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_28 (Dense)                (None, 10)           10010       dropout_17[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,848,898\n",
      "Trainable params: 21,826,114\n",
      "Non-trainable params: 22,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet34\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "# conv1 112*112\n",
    "input = Input(shape=(224,224,3))\n",
    "x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "\n",
    "# conv2_x 56*56 3subs\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = conv_block34(x, 64, 64, 1) #1\n",
    "for i in range(2):\n",
    "    x = identity_block34(x, 64, 64) #2\n",
    "\n",
    "# conv3_x 28*28 4subs\n",
    "x = conv_block34(x, 128, 128) #1\n",
    "for i in range(3):\n",
    "    x = identity_block34(x, 128, 128) #3\n",
    "\n",
    "# conv4_x 14*14 6subs\n",
    "x = conv_block34(x, 256, 256) #1\n",
    "for i in range(5):\n",
    "    x = identity_block34(x, 256, 256) #2\n",
    "\n",
    "\n",
    "# conv5_x 7*7 3subs\n",
    "x = conv_block34(x, 512, 512) #1\n",
    "for i in range(2):\n",
    "    x = identity_block34(x, 512, 512) #2\n",
    "\n",
    "# avg_pool 1\n",
    "x = full_block(x)\n",
    "\n",
    "model = Model(input, x, name=\"resnet\")\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "18000/18000 [==============================] - 83s 5ms/step - loss: 0.8273 - acc: 0.7223 - val_loss: 0.2442 - val_acc: 0.9245\n",
      "Epoch 2/12\n",
      "18000/18000 [==============================] - 75s 4ms/step - loss: 0.1345 - acc: 0.9614 - val_loss: 0.1162 - val_acc: 0.9655\n",
      "Epoch 3/12\n",
      "18000/18000 [==============================] - 77s 4ms/step - loss: 0.0735 - acc: 0.9784 - val_loss: 0.0789 - val_acc: 0.9785\n",
      "Epoch 4/12\n",
      "18000/18000 [==============================] - 76s 4ms/step - loss: 0.0443 - acc: 0.9876 - val_loss: 0.0597 - val_acc: 0.9815\n",
      "Epoch 5/12\n",
      "18000/18000 [==============================] - 75s 4ms/step - loss: 0.0300 - acc: 0.9909 - val_loss: 0.1168 - val_acc: 0.9645\n",
      "Epoch 6/12\n",
      "18000/18000 [==============================] - 75s 4ms/step - loss: 0.0195 - acc: 0.9945 - val_loss: 0.0408 - val_acc: 0.9870\n",
      "Epoch 7/12\n",
      "18000/18000 [==============================] - 75s 4ms/step - loss: 0.0136 - acc: 0.9964 - val_loss: 0.0495 - val_acc: 0.9840\n",
      "Epoch 8/12\n",
      "18000/18000 [==============================] - 74s 4ms/step - loss: 0.0128 - acc: 0.9968 - val_loss: 0.0608 - val_acc: 0.9825\n",
      "Epoch 9/12\n",
      "18000/18000 [==============================] - 74s 4ms/step - loss: 0.0092 - acc: 0.9974 - val_loss: 0.0370 - val_acc: 0.9910\n",
      "Epoch 10/12\n",
      "18000/18000 [==============================] - 76s 4ms/step - loss: 0.0100 - acc: 0.9969 - val_loss: 0.0524 - val_acc: 0.9880\n",
      "Epoch 11/12\n",
      "18000/18000 [==============================] - 75s 4ms/step - loss: 0.0069 - acc: 0.9984 - val_loss: 0.0370 - val_acc: 0.9910\n",
      "Epoch 12/12\n",
      "18000/18000 [==============================] - 75s 4ms/step - loss: 0.0068 - acc: 0.9982 - val_loss: 0.0642 - val_acc: 0.9830\n",
      "cost:  914\n",
      "2000/2000 [==============================] - 4s 2ms/step\n",
      "loss:  0.07898581893648952\n",
      "acc:  0.979\n"
     ]
    }
   ],
   "source": [
    "from dpl import utils\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_25 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_803 (Conv2D)             (None, 112, 112, 64) 9472        input_25[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_981 (BatchN (None, 112, 112, 64) 256         conv2d_803[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_710 (Activation)     (None, 112, 112, 64) 0           batch_normalization_981[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_33 (MaxPooling2D) (None, 56, 56, 64)   0           activation_710[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_804 (Conv2D)             (None, 56, 56, 64)   4160        max_pooling2d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_982 (BatchN (None, 56, 56, 64)   256         conv2d_804[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_711 (Activation)     (None, 56, 56, 64)   0           batch_normalization_982[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_805 (Conv2D)             (None, 56, 56, 64)   36928       activation_711[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_983 (BatchN (None, 56, 56, 64)   256         conv2d_805[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_712 (Activation)     (None, 56, 56, 64)   0           batch_normalization_983[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_806 (Conv2D)             (None, 56, 56, 256)  16640       activation_712[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_807 (Conv2D)             (None, 56, 56, 256)  16640       max_pooling2d_33[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_984 (BatchN (None, 56, 56, 256)  1024        conv2d_806[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_985 (BatchN (None, 56, 56, 256)  1024        conv2d_807[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_262 (Add)                   (None, 56, 56, 256)  0           batch_normalization_984[0][0]    \n",
      "                                                                 batch_normalization_985[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_713 (Activation)     (None, 56, 56, 256)  0           add_262[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_808 (Conv2D)             (None, 56, 56, 64)   16448       activation_713[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_986 (BatchN (None, 56, 56, 64)   256         conv2d_808[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_714 (Activation)     (None, 56, 56, 64)   0           batch_normalization_986[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_809 (Conv2D)             (None, 56, 56, 64)   36928       activation_714[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_987 (BatchN (None, 56, 56, 64)   256         conv2d_809[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_715 (Activation)     (None, 56, 56, 64)   0           batch_normalization_987[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_810 (Conv2D)             (None, 56, 56, 256)  16640       activation_715[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_988 (BatchN (None, 56, 56, 256)  1024        conv2d_810[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_989 (BatchN (None, 56, 56, 256)  1024        activation_713[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_263 (Add)                   (None, 56, 56, 256)  0           batch_normalization_988[0][0]    \n",
      "                                                                 batch_normalization_989[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_716 (Activation)     (None, 56, 56, 256)  0           add_263[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_811 (Conv2D)             (None, 56, 56, 64)   16448       activation_716[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_990 (BatchN (None, 56, 56, 64)   256         conv2d_811[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_717 (Activation)     (None, 56, 56, 64)   0           batch_normalization_990[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_812 (Conv2D)             (None, 56, 56, 64)   36928       activation_717[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_991 (BatchN (None, 56, 56, 64)   256         conv2d_812[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_718 (Activation)     (None, 56, 56, 64)   0           batch_normalization_991[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_813 (Conv2D)             (None, 56, 56, 256)  16640       activation_718[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_992 (BatchN (None, 56, 56, 256)  1024        conv2d_813[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_993 (BatchN (None, 56, 56, 256)  1024        activation_716[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_264 (Add)                   (None, 56, 56, 256)  0           batch_normalization_992[0][0]    \n",
      "                                                                 batch_normalization_993[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_719 (Activation)     (None, 56, 56, 256)  0           add_264[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_814 (Conv2D)             (None, 28, 28, 128)  32896       activation_719[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_994 (BatchN (None, 28, 28, 128)  512         conv2d_814[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_720 (Activation)     (None, 28, 28, 128)  0           batch_normalization_994[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_815 (Conv2D)             (None, 28, 28, 128)  147584      activation_720[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_995 (BatchN (None, 28, 28, 128)  512         conv2d_815[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_721 (Activation)     (None, 28, 28, 128)  0           batch_normalization_995[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_816 (Conv2D)             (None, 28, 28, 252)  32508       activation_721[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_817 (Conv2D)             (None, 28, 28, 252)  64764       activation_719[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_996 (BatchN (None, 28, 28, 252)  1008        conv2d_816[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_997 (BatchN (None, 28, 28, 252)  1008        conv2d_817[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_265 (Add)                   (None, 28, 28, 252)  0           batch_normalization_996[0][0]    \n",
      "                                                                 batch_normalization_997[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_722 (Activation)     (None, 28, 28, 252)  0           add_265[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_818 (Conv2D)             (None, 28, 28, 128)  32384       activation_722[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_998 (BatchN (None, 28, 28, 128)  512         conv2d_818[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_723 (Activation)     (None, 28, 28, 128)  0           batch_normalization_998[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_819 (Conv2D)             (None, 28, 28, 128)  147584      activation_723[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_999 (BatchN (None, 28, 28, 128)  512         conv2d_819[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_724 (Activation)     (None, 28, 28, 128)  0           batch_normalization_999[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_820 (Conv2D)             (None, 28, 28, 252)  32508       activation_724[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1000 (Batch (None, 28, 28, 252)  1008        conv2d_820[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1001 (Batch (None, 28, 28, 252)  1008        activation_722[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_266 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1000[0][0]   \n",
      "                                                                 batch_normalization_1001[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_725 (Activation)     (None, 28, 28, 252)  0           add_266[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_821 (Conv2D)             (None, 28, 28, 128)  32384       activation_725[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1002 (Batch (None, 28, 28, 128)  512         conv2d_821[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_726 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1002[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_822 (Conv2D)             (None, 28, 28, 128)  147584      activation_726[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1003 (Batch (None, 28, 28, 128)  512         conv2d_822[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_727 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1003[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_823 (Conv2D)             (None, 28, 28, 252)  32508       activation_727[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1004 (Batch (None, 28, 28, 252)  1008        conv2d_823[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1005 (Batch (None, 28, 28, 252)  1008        activation_725[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_267 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1004[0][0]   \n",
      "                                                                 batch_normalization_1005[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_728 (Activation)     (None, 28, 28, 252)  0           add_267[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_824 (Conv2D)             (None, 28, 28, 128)  32384       activation_728[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1006 (Batch (None, 28, 28, 128)  512         conv2d_824[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_729 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1006[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_825 (Conv2D)             (None, 28, 28, 128)  147584      activation_729[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1007 (Batch (None, 28, 28, 128)  512         conv2d_825[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_730 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1007[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_826 (Conv2D)             (None, 28, 28, 252)  32508       activation_730[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1008 (Batch (None, 28, 28, 252)  1008        conv2d_826[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1009 (Batch (None, 28, 28, 252)  1008        activation_728[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_268 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1008[0][0]   \n",
      "                                                                 batch_normalization_1009[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_731 (Activation)     (None, 28, 28, 252)  0           add_268[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_827 (Conv2D)             (None, 14, 14, 256)  64768       activation_731[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1010 (Batch (None, 14, 14, 256)  1024        conv2d_827[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_732 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1010[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_828 (Conv2D)             (None, 14, 14, 256)  590080      activation_732[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1011 (Batch (None, 14, 14, 256)  1024        conv2d_828[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_733 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1011[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_829 (Conv2D)             (None, 14, 14, 1024) 263168      activation_733[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_830 (Conv2D)             (None, 14, 14, 1024) 259072      activation_731[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1012 (Batch (None, 14, 14, 1024) 4096        conv2d_829[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1013 (Batch (None, 14, 14, 1024) 4096        conv2d_830[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_269 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1012[0][0]   \n",
      "                                                                 batch_normalization_1013[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_734 (Activation)     (None, 14, 14, 1024) 0           add_269[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_831 (Conv2D)             (None, 14, 14, 256)  262400      activation_734[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1014 (Batch (None, 14, 14, 256)  1024        conv2d_831[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_735 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1014[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_832 (Conv2D)             (None, 14, 14, 256)  590080      activation_735[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1015 (Batch (None, 14, 14, 256)  1024        conv2d_832[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_736 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1015[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_833 (Conv2D)             (None, 14, 14, 1024) 263168      activation_736[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1016 (Batch (None, 14, 14, 1024) 4096        conv2d_833[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1017 (Batch (None, 14, 14, 1024) 4096        activation_734[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_270 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1016[0][0]   \n",
      "                                                                 batch_normalization_1017[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_737 (Activation)     (None, 14, 14, 1024) 0           add_270[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_834 (Conv2D)             (None, 14, 14, 256)  262400      activation_737[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1018 (Batch (None, 14, 14, 256)  1024        conv2d_834[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_738 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1018[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_835 (Conv2D)             (None, 14, 14, 256)  590080      activation_738[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1019 (Batch (None, 14, 14, 256)  1024        conv2d_835[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_739 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1019[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_836 (Conv2D)             (None, 14, 14, 1024) 263168      activation_739[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1020 (Batch (None, 14, 14, 1024) 4096        conv2d_836[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1021 (Batch (None, 14, 14, 1024) 4096        activation_737[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_271 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1020[0][0]   \n",
      "                                                                 batch_normalization_1021[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_740 (Activation)     (None, 14, 14, 1024) 0           add_271[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_837 (Conv2D)             (None, 14, 14, 256)  262400      activation_740[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1022 (Batch (None, 14, 14, 256)  1024        conv2d_837[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_741 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1022[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_838 (Conv2D)             (None, 14, 14, 256)  590080      activation_741[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1023 (Batch (None, 14, 14, 256)  1024        conv2d_838[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_742 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1023[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_839 (Conv2D)             (None, 14, 14, 1024) 263168      activation_742[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1024 (Batch (None, 14, 14, 1024) 4096        conv2d_839[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1025 (Batch (None, 14, 14, 1024) 4096        activation_740[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_272 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1024[0][0]   \n",
      "                                                                 batch_normalization_1025[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_743 (Activation)     (None, 14, 14, 1024) 0           add_272[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_840 (Conv2D)             (None, 14, 14, 256)  262400      activation_743[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1026 (Batch (None, 14, 14, 256)  1024        conv2d_840[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_744 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1026[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_841 (Conv2D)             (None, 14, 14, 256)  590080      activation_744[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1027 (Batch (None, 14, 14, 256)  1024        conv2d_841[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_745 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1027[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_842 (Conv2D)             (None, 14, 14, 1024) 263168      activation_745[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1028 (Batch (None, 14, 14, 1024) 4096        conv2d_842[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1029 (Batch (None, 14, 14, 1024) 4096        activation_743[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_273 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1028[0][0]   \n",
      "                                                                 batch_normalization_1029[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_746 (Activation)     (None, 14, 14, 1024) 0           add_273[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_843 (Conv2D)             (None, 14, 14, 256)  262400      activation_746[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1030 (Batch (None, 14, 14, 256)  1024        conv2d_843[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_747 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1030[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_844 (Conv2D)             (None, 14, 14, 256)  590080      activation_747[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1031 (Batch (None, 14, 14, 256)  1024        conv2d_844[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_748 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1031[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_845 (Conv2D)             (None, 14, 14, 1024) 263168      activation_748[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1032 (Batch (None, 14, 14, 1024) 4096        conv2d_845[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1033 (Batch (None, 14, 14, 1024) 4096        activation_746[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_274 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1032[0][0]   \n",
      "                                                                 batch_normalization_1033[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_749 (Activation)     (None, 14, 14, 1024) 0           add_274[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_846 (Conv2D)             (None, 14, 14, 256)  262400      activation_749[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1034 (Batch (None, 14, 14, 256)  1024        conv2d_846[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_750 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1034[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_847 (Conv2D)             (None, 14, 14, 256)  590080      activation_750[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1035 (Batch (None, 14, 14, 256)  1024        conv2d_847[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_751 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1035[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_848 (Conv2D)             (None, 14, 14, 1024) 263168      activation_751[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1036 (Batch (None, 14, 14, 1024) 4096        conv2d_848[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1037 (Batch (None, 14, 14, 1024) 4096        activation_749[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_275 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1036[0][0]   \n",
      "                                                                 batch_normalization_1037[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_752 (Activation)     (None, 14, 14, 1024) 0           add_275[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_849 (Conv2D)             (None, 14, 14, 256)  262400      activation_752[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1038 (Batch (None, 14, 14, 256)  1024        conv2d_849[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_753 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1038[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_850 (Conv2D)             (None, 14, 14, 256)  590080      activation_753[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1039 (Batch (None, 14, 14, 256)  1024        conv2d_850[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_754 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1039[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_851 (Conv2D)             (None, 14, 14, 1024) 263168      activation_754[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1040 (Batch (None, 14, 14, 1024) 4096        conv2d_851[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1041 (Batch (None, 14, 14, 1024) 4096        activation_752[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_276 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1040[0][0]   \n",
      "                                                                 batch_normalization_1041[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_755 (Activation)     (None, 14, 14, 1024) 0           add_276[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_852 (Conv2D)             (None, 14, 14, 256)  262400      activation_755[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1042 (Batch (None, 14, 14, 256)  1024        conv2d_852[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_756 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1042[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_853 (Conv2D)             (None, 14, 14, 256)  590080      activation_756[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1043 (Batch (None, 14, 14, 256)  1024        conv2d_853[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_757 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1043[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_854 (Conv2D)             (None, 14, 14, 1024) 263168      activation_757[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1044 (Batch (None, 14, 14, 1024) 4096        conv2d_854[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1045 (Batch (None, 14, 14, 1024) 4096        activation_755[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_277 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1044[0][0]   \n",
      "                                                                 batch_normalization_1045[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_758 (Activation)     (None, 14, 14, 1024) 0           add_277[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_855 (Conv2D)             (None, 14, 14, 256)  262400      activation_758[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1046 (Batch (None, 14, 14, 256)  1024        conv2d_855[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_759 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1046[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_856 (Conv2D)             (None, 14, 14, 256)  590080      activation_759[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1047 (Batch (None, 14, 14, 256)  1024        conv2d_856[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_760 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1047[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_857 (Conv2D)             (None, 14, 14, 1024) 263168      activation_760[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1048 (Batch (None, 14, 14, 1024) 4096        conv2d_857[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1049 (Batch (None, 14, 14, 1024) 4096        activation_758[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_278 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1048[0][0]   \n",
      "                                                                 batch_normalization_1049[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_761 (Activation)     (None, 14, 14, 1024) 0           add_278[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_858 (Conv2D)             (None, 14, 14, 256)  262400      activation_761[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1050 (Batch (None, 14, 14, 256)  1024        conv2d_858[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_762 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1050[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_859 (Conv2D)             (None, 14, 14, 256)  590080      activation_762[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1051 (Batch (None, 14, 14, 256)  1024        conv2d_859[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_763 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1051[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_860 (Conv2D)             (None, 14, 14, 1024) 263168      activation_763[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1052 (Batch (None, 14, 14, 1024) 4096        conv2d_860[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1053 (Batch (None, 14, 14, 1024) 4096        activation_761[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_279 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1052[0][0]   \n",
      "                                                                 batch_normalization_1053[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_764 (Activation)     (None, 14, 14, 1024) 0           add_279[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_861 (Conv2D)             (None, 14, 14, 256)  262400      activation_764[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1054 (Batch (None, 14, 14, 256)  1024        conv2d_861[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_765 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1054[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_862 (Conv2D)             (None, 14, 14, 256)  590080      activation_765[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1055 (Batch (None, 14, 14, 256)  1024        conv2d_862[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_766 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1055[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_863 (Conv2D)             (None, 14, 14, 1024) 263168      activation_766[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1056 (Batch (None, 14, 14, 1024) 4096        conv2d_863[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1057 (Batch (None, 14, 14, 1024) 4096        activation_764[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_280 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1056[0][0]   \n",
      "                                                                 batch_normalization_1057[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_767 (Activation)     (None, 14, 14, 1024) 0           add_280[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_864 (Conv2D)             (None, 14, 14, 256)  262400      activation_767[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1058 (Batch (None, 14, 14, 256)  1024        conv2d_864[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_768 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1058[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_865 (Conv2D)             (None, 14, 14, 256)  590080      activation_768[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1059 (Batch (None, 14, 14, 256)  1024        conv2d_865[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_769 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1059[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_866 (Conv2D)             (None, 14, 14, 1024) 263168      activation_769[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1060 (Batch (None, 14, 14, 1024) 4096        conv2d_866[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1061 (Batch (None, 14, 14, 1024) 4096        activation_767[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_281 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1060[0][0]   \n",
      "                                                                 batch_normalization_1061[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_770 (Activation)     (None, 14, 14, 1024) 0           add_281[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_867 (Conv2D)             (None, 14, 14, 256)  262400      activation_770[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1062 (Batch (None, 14, 14, 256)  1024        conv2d_867[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_771 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1062[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_868 (Conv2D)             (None, 14, 14, 256)  590080      activation_771[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1063 (Batch (None, 14, 14, 256)  1024        conv2d_868[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_772 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1063[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_869 (Conv2D)             (None, 14, 14, 1024) 263168      activation_772[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1064 (Batch (None, 14, 14, 1024) 4096        conv2d_869[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1065 (Batch (None, 14, 14, 1024) 4096        activation_770[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_282 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1064[0][0]   \n",
      "                                                                 batch_normalization_1065[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_773 (Activation)     (None, 14, 14, 1024) 0           add_282[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_870 (Conv2D)             (None, 14, 14, 256)  262400      activation_773[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1066 (Batch (None, 14, 14, 256)  1024        conv2d_870[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_774 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1066[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_871 (Conv2D)             (None, 14, 14, 256)  590080      activation_774[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1067 (Batch (None, 14, 14, 256)  1024        conv2d_871[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_775 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1067[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_872 (Conv2D)             (None, 14, 14, 1024) 263168      activation_775[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1068 (Batch (None, 14, 14, 1024) 4096        conv2d_872[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1069 (Batch (None, 14, 14, 1024) 4096        activation_773[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_283 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1068[0][0]   \n",
      "                                                                 batch_normalization_1069[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_776 (Activation)     (None, 14, 14, 1024) 0           add_283[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_873 (Conv2D)             (None, 14, 14, 256)  262400      activation_776[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1070 (Batch (None, 14, 14, 256)  1024        conv2d_873[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_777 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1070[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_874 (Conv2D)             (None, 14, 14, 256)  590080      activation_777[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1071 (Batch (None, 14, 14, 256)  1024        conv2d_874[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_778 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1071[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_875 (Conv2D)             (None, 14, 14, 1024) 263168      activation_778[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1072 (Batch (None, 14, 14, 1024) 4096        conv2d_875[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1073 (Batch (None, 14, 14, 1024) 4096        activation_776[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_284 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1072[0][0]   \n",
      "                                                                 batch_normalization_1073[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_779 (Activation)     (None, 14, 14, 1024) 0           add_284[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_876 (Conv2D)             (None, 14, 14, 256)  262400      activation_779[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1074 (Batch (None, 14, 14, 256)  1024        conv2d_876[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_780 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1074[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_877 (Conv2D)             (None, 14, 14, 256)  590080      activation_780[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1075 (Batch (None, 14, 14, 256)  1024        conv2d_877[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_781 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1075[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_878 (Conv2D)             (None, 14, 14, 1024) 263168      activation_781[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1076 (Batch (None, 14, 14, 1024) 4096        conv2d_878[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1077 (Batch (None, 14, 14, 1024) 4096        activation_779[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_285 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1076[0][0]   \n",
      "                                                                 batch_normalization_1077[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_782 (Activation)     (None, 14, 14, 1024) 0           add_285[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_879 (Conv2D)             (None, 14, 14, 256)  262400      activation_782[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1078 (Batch (None, 14, 14, 256)  1024        conv2d_879[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_783 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1078[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_880 (Conv2D)             (None, 14, 14, 256)  590080      activation_783[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1079 (Batch (None, 14, 14, 256)  1024        conv2d_880[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_784 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1079[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_881 (Conv2D)             (None, 14, 14, 1024) 263168      activation_784[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1080 (Batch (None, 14, 14, 1024) 4096        conv2d_881[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1081 (Batch (None, 14, 14, 1024) 4096        activation_782[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_286 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1080[0][0]   \n",
      "                                                                 batch_normalization_1081[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_785 (Activation)     (None, 14, 14, 1024) 0           add_286[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_882 (Conv2D)             (None, 14, 14, 256)  262400      activation_785[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1082 (Batch (None, 14, 14, 256)  1024        conv2d_882[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_786 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1082[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_883 (Conv2D)             (None, 14, 14, 256)  590080      activation_786[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1083 (Batch (None, 14, 14, 256)  1024        conv2d_883[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_787 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1083[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_884 (Conv2D)             (None, 14, 14, 1024) 263168      activation_787[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1084 (Batch (None, 14, 14, 1024) 4096        conv2d_884[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1085 (Batch (None, 14, 14, 1024) 4096        activation_785[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_287 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1084[0][0]   \n",
      "                                                                 batch_normalization_1085[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_788 (Activation)     (None, 14, 14, 1024) 0           add_287[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_885 (Conv2D)             (None, 14, 14, 256)  262400      activation_788[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1086 (Batch (None, 14, 14, 256)  1024        conv2d_885[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_789 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1086[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_886 (Conv2D)             (None, 14, 14, 256)  590080      activation_789[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1087 (Batch (None, 14, 14, 256)  1024        conv2d_886[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_790 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1087[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_887 (Conv2D)             (None, 14, 14, 1024) 263168      activation_790[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1088 (Batch (None, 14, 14, 1024) 4096        conv2d_887[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1089 (Batch (None, 14, 14, 1024) 4096        activation_788[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_288 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1088[0][0]   \n",
      "                                                                 batch_normalization_1089[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_791 (Activation)     (None, 14, 14, 1024) 0           add_288[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_888 (Conv2D)             (None, 14, 14, 256)  262400      activation_791[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1090 (Batch (None, 14, 14, 256)  1024        conv2d_888[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_792 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1090[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_889 (Conv2D)             (None, 14, 14, 256)  590080      activation_792[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1091 (Batch (None, 14, 14, 256)  1024        conv2d_889[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_793 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1091[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_890 (Conv2D)             (None, 14, 14, 1024) 263168      activation_793[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1092 (Batch (None, 14, 14, 1024) 4096        conv2d_890[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1093 (Batch (None, 14, 14, 1024) 4096        activation_791[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_289 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1092[0][0]   \n",
      "                                                                 batch_normalization_1093[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_794 (Activation)     (None, 14, 14, 1024) 0           add_289[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_891 (Conv2D)             (None, 14, 14, 256)  262400      activation_794[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1094 (Batch (None, 14, 14, 256)  1024        conv2d_891[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_795 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1094[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_892 (Conv2D)             (None, 14, 14, 256)  590080      activation_795[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1095 (Batch (None, 14, 14, 256)  1024        conv2d_892[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_796 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1095[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_893 (Conv2D)             (None, 14, 14, 1024) 263168      activation_796[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1096 (Batch (None, 14, 14, 1024) 4096        conv2d_893[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1097 (Batch (None, 14, 14, 1024) 4096        activation_794[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_290 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1096[0][0]   \n",
      "                                                                 batch_normalization_1097[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_797 (Activation)     (None, 14, 14, 1024) 0           add_290[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_894 (Conv2D)             (None, 14, 14, 256)  262400      activation_797[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1098 (Batch (None, 14, 14, 256)  1024        conv2d_894[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_798 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1098[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_895 (Conv2D)             (None, 14, 14, 256)  590080      activation_798[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1099 (Batch (None, 14, 14, 256)  1024        conv2d_895[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_799 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1099[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_896 (Conv2D)             (None, 14, 14, 1024) 263168      activation_799[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1100 (Batch (None, 14, 14, 1024) 4096        conv2d_896[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1101 (Batch (None, 14, 14, 1024) 4096        activation_797[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_291 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1100[0][0]   \n",
      "                                                                 batch_normalization_1101[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_800 (Activation)     (None, 14, 14, 1024) 0           add_291[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_897 (Conv2D)             (None, 7, 7, 512)    524800      activation_800[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1102 (Batch (None, 7, 7, 512)    2048        conv2d_897[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_801 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1102[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_898 (Conv2D)             (None, 7, 7, 512)    2359808     activation_801[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1103 (Batch (None, 7, 7, 512)    2048        conv2d_898[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_802 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1103[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_899 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_802[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_900 (Conv2D)             (None, 7, 7, 2048)   2099200     activation_800[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1104 (Batch (None, 7, 7, 2048)   8192        conv2d_899[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1105 (Batch (None, 7, 7, 2048)   8192        conv2d_900[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_292 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1104[0][0]   \n",
      "                                                                 batch_normalization_1105[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_803 (Activation)     (None, 7, 7, 2048)   0           add_292[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_901 (Conv2D)             (None, 7, 7, 512)    1049088     activation_803[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1106 (Batch (None, 7, 7, 512)    2048        conv2d_901[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_804 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1106[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_902 (Conv2D)             (None, 7, 7, 512)    2359808     activation_804[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1107 (Batch (None, 7, 7, 512)    2048        conv2d_902[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_805 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1107[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_903 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_805[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1108 (Batch (None, 7, 7, 2048)   8192        conv2d_903[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1109 (Batch (None, 7, 7, 2048)   8192        activation_803[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_293 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1108[0][0]   \n",
      "                                                                 batch_normalization_1109[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_806 (Activation)     (None, 7, 7, 2048)   0           add_293[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_904 (Conv2D)             (None, 7, 7, 512)    1049088     activation_806[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1110 (Batch (None, 7, 7, 512)    2048        conv2d_904[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_807 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1110[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_905 (Conv2D)             (None, 7, 7, 512)    2359808     activation_807[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1111 (Batch (None, 7, 7, 512)    2048        conv2d_905[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_808 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1111[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_906 (Conv2D)             (None, 7, 7, 2048)   1050624     activation_808[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1112 (Batch (None, 7, 7, 2048)   8192        conv2d_906[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1113 (Batch (None, 7, 7, 2048)   8192        activation_806[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_294 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1112[0][0]   \n",
      "                                                                 batch_normalization_1113[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_809 (Activation)     (None, 7, 7, 2048)   0           add_294[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_16 (AveragePo (None, 1, 1, 2048)   0           activation_809[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_28 (Dropout)            (None, 1, 1, 2048)   0           average_pooling2d_16[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_18 (Flatten)            (None, 2048)         0           dropout_28[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_39 (Dense)                (None, 1000)         2049000     flatten_18[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_29 (Dropout)            (None, 1000)         0           dense_39[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_40 (Dense)                (None, 10)           10010       dropout_29[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 44,189,934\n",
      "Trainable params: 44,031,406\n",
      "Non-trainable params: 158,528\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet 50,101,152 2015\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "depth = 101\n",
    "assert depth in [50,101,152]\n",
    "conv_nums = [3,4,6,3]\n",
    "if depth == 101:\n",
    "    conv_nums[2]=23\n",
    "elif depth == 152:\n",
    "    conv_nums[1]=8\n",
    "    conv_nums[2]=36\n",
    "\n",
    "# conv1 112*112\n",
    "input = Input(shape=(224,224,3))\n",
    "x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "\n",
    "# conv2_x 56*56 3subs\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = conv_block(x, 64, 64, 256, 1) #1\n",
    "for i in range(conv_nums[0]-1):\n",
    "    x = identity_block(x, 64, 64, 256) #2\n",
    "\n",
    "# conv3_x 28*28 4subs\n",
    "x = conv_block(x, 128, 128, 252) #1\n",
    "for i in range(conv_nums[1]-1):\n",
    "    x = identity_block(x, 128, 128, 252) #2\n",
    "\n",
    "# conv4_x 14*14 6subs\n",
    "x = conv_block(x, 256, 256, 1024) #1\n",
    "for i in range(conv_nums[2]-1):\n",
    "    x = identity_block(x, 256, 256, 1024) #2\n",
    "\n",
    "# conv5_x 7*7 3subs\n",
    "x = conv_block(x, 512, 512, 2048) #1\n",
    "for i in range(conv_nums[3]-1):\n",
    "    x = identity_block(x, 512, 512, 2048) #2\n",
    "\n",
    "# avg_pool 1\n",
    "x = full_block(x)\n",
    "\n",
    "model = Model(input, x, name=\"resnet\")\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet101 2015\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "# conv1 112*112\n",
    "input = Input(shape=(224,224,3))\n",
    "x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "\n",
    "# conv2_x 56*56 3subs\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = conv_block34(x, 64, 64, 256, 1) #1\n",
    "for i in range(2)\n",
    "    x = identity_block34(x, 64, 64, 256) #2\n",
    "\n",
    "# conv3_x 28*28 4subs\n",
    "x = conv_block34(x, 128, 128, 252) #1\n",
    "for i in range(3)\n",
    "    x = identity_block34(x, 128, 128, 252) #3\n",
    "\n",
    "# conv4_x 14*14 23subs\n",
    "x = conv_block34(x, 256, 256, 1024) #1\n",
    "for i in range(22)\n",
    "    x = identity_block34(x, 256, 256, 1024) #22\n",
    "\n",
    "# conv5_x 7*7 3subs\n",
    "x = conv_block34(x, 512, 512, 2048) #1\n",
    "for i in range(2)\n",
    "    x = identity_block34(x, 512, 512, 1024) #2\n",
    "\n",
    "# avg_pool 1\n",
    "x = full_block(x)\n",
    "\n",
    "model = Model(input, x, name=\"resnet\")\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# resnet152 2015\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# 匹配输入尺度和输出尺度\n",
    "# 每个convn_x 第一层调用\n",
    "def conv_block(input, filter_nums1, filter_nums2, filter_nums3, strides=2):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (1,1), strides=strides)\n",
    "    x = conv2d_bn(input, filter_nums2, (3,3))\n",
    "    x = Conv2D(filter_nums3, (1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = Conv2D(filter_nums3, (1,1), strides=strides)(input)\n",
    "    short_cut = BatchNormalization()(short_cut)\n",
    "    # add\n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# identity mapping\n",
    "# 紧接conv_block34 调用\n",
    "def identity_block(input, filter_nums1, filter_nums2, filter_nums3):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (1,1))\n",
    "    x = conv2d_bn(input, filter_nums2, (3,3))\n",
    "    x = Conv2D(filter_nums3, (1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = BatchNormalization()(input)\n",
    "    \n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def full_block(input):\n",
    "    x = AveragePooling2D(pool_size=(7,7))(input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    return output\n",
    "\n",
    "# conv1 112*112\n",
    "input = Input(shape=(224,224,3))\n",
    "x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "\n",
    "# conv2_x 56*56 3subs\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = conv_block34(x, 64, 64, 256, 1) #1\n",
    "for i in range(2)\n",
    "    x = identity_block34(x, 64, 64, 256) #2\n",
    "\n",
    "# conv3_x 28*28 8subs\n",
    "x = conv_block34(x, 128, 128, 252) #1\n",
    "for i in range(7)\n",
    "    x = identity_block34(x, 128, 128, 252) #3\n",
    "\n",
    "# conv4_x 14*14 36subs\n",
    "x = conv_block34(x, 256, 256, 1024) #1\n",
    "for i in range(35)\n",
    "    x = identity_block34(x, 256, 256, 1024) #35\n",
    "\n",
    "# conv5_x 7*7 3subs\n",
    "x = conv_block34(x, 512, 512, 2048) #1\n",
    "for i in range(2)\n",
    "    x = identity_block34(x, 512, 512, 1024) #2\n",
    "\n",
    "# avg_pool 1\n",
    "x = full_block(x)\n",
    "\n",
    "model = Model(input, x, name=\"resnet\")\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
