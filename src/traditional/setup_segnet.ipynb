{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/ipykernel_launcher.py:28: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0903 16:04:10.862720 140494861784896 image.py:700] Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:\n",
      "image size -->  224 x 224\n",
      "channels -->  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:\n",
      "image size -->  224 x 224\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:\n",
      "image size -->  512 x 512\n",
      "channels -->  3\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "info:\n",
      "image size -->  512 x 512\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# read dataset pascal\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.io as scio\n",
    "import sys\n",
    "#print(sys.path)\n",
    "sys.path.insert(0, '../')\n",
    "from dpl import utils\n",
    "from dpl.data.pascal import preprocessing\n",
    "\n",
    "import keras\n",
    "import multiprocessing\n",
    "# 标签数据预处理\n",
    "#preprocessing.split_label_into_masks(\"/home/super-workstation/Data/pascal/VOC_Data/VOC2012/SegmentationClass\", \"/mask1/\")\n",
    "\n",
    "import os\n",
    "import cv2\n",
    "    \n",
    "from voc_data_generator import *\n",
    "from voc_data_generator_v2 import *\n",
    "\n",
    "image_root = \"/home/super-workstation/Data/pascal/VOC_Data/VOC2012/\"\n",
    "path = image_root\n",
    "# v1 get image and label\n",
    "import yaml\n",
    "with open(\"init_args.yml\", 'r') as stream:\n",
    "    try:\n",
    "        init_args = yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "\n",
    "datagen = PascalVocGenerator(image_shape=[224, 224, 3],\n",
    "                             image_resample=True,\n",
    "                             pixelwise_center=True,\n",
    "                             pixel_mean=[115.85100, 110.50989, 102.16182],\n",
    "                             pixelwise_std_normalization=True,\n",
    "                             pixel_std=[70.30930, 69.41244, 72.60676])\n",
    "\n",
    "train_loader = ImageSetLoader(**init_args['image_set_loader']['train'])\n",
    "val_loader = ImageSetLoader(**init_args['image_set_loader']['val'])\n",
    "val_gen = datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=5,\n",
    "        shuffle=False,\n",
    "        image_set_loader=val_loader)\n",
    "batch = next(val_gen)\n",
    "batch = next(val_gen)\n",
    "utils.showSingleImage(batch[0][0])\n",
    "utils.showSingleImage(batch[1][0,:,:,17])\n",
    "\n",
    "# v2 get image and label\n",
    "config = Config()\n",
    "config.batch_size = 5\n",
    "config.steps_per_epoch = 180\n",
    "config.validation_steps = 40\n",
    "config.shuffle=False\n",
    "train_dataset = PascalDataset(path, is_train=True)\n",
    "val_dataset = PascalDataset(path, is_train=False)\n",
    "\n",
    "train_gen = data_generator(train_dataset, config)\n",
    "val_gen = data_generator(val_dataset, config)\n",
    "\n",
    "img_label = next(val_gen)\n",
    "img_label = next(val_gen)\n",
    "#print(img_label[1].shape)\n",
    "utils.showSingleImage(img_label[0][0])\n",
    "utils.showSingleImage(img_label[1][0,:,:,17])\n",
    "\n",
    "#print(img_label[0][0][100:200,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 16:04:14.159532 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0903 16:04:14.168361 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0903 16:04:14.170025 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0903 16:04:14.185495 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0903 16:04:14.277392 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0903 16:04:14.281879 140494861784896 deprecation.py:506] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0903 16:04:14.319052 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0903 16:04:14.335122 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0903 16:04:14.346867 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3295: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 512, 512, 3)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 512, 512, 64)      1792      \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 512, 512, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 512, 512, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_2 (Activation)    (None, 512, 512, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 256, 256, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 256, 256, 128)     73856     \n",
      "_________________________________________________________________\n",
      "activation_3 (Activation)    (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 256, 256, 128)     147584    \n",
      "_________________________________________________________________\n",
      "activation_4 (Activation)    (None, 256, 256, 128)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 128, 128, 128)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 128, 128, 256)     295168    \n",
      "_________________________________________________________________\n",
      "activation_5 (Activation)    (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "activation_6 (Activation)    (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 128, 128, 256)     590080    \n",
      "_________________________________________________________________\n",
      "activation_7 (Activation)    (None, 128, 128, 256)     0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 64, 64, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "activation_8 (Activation)    (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_9 (Activation)    (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 64, 64, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_10 (Activation)   (None, 64, 64, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_11 (Activation)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_12 (Activation)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 32, 32, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "activation_13 (Activation)   (None, 32, 32, 512)       0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 16, 16, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 16, 16, 4096)      102764544 \n",
      "_________________________________________________________________\n",
      "activation_14 (Activation)   (None, 16, 16, 4096)      0         \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16, 16, 4096)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 16, 16, 21)        86037     \n",
      "_________________________________________________________________\n",
      "activation_16 (Activation)   (None, 16, 16, 21)        0         \n",
      "_________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2 (None, 512, 512, 21)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 512, 512, 21)      3990      \n",
      "_________________________________________________________________\n",
      "activation_17 (Activation)   (None, 512, 512, 21)      0         \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 512, 512, 21)      0         \n",
      "=================================================================\n",
      "Total params: 117,569,259\n",
      "Trainable params: 117,569,259\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fcn 32s\n",
    "# 直接从 pool5 上采样（反卷级）到原尺寸\n",
    "# 5 layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, UpSampling2D\n",
    "from keras.layers import Input, ZeroPadding2D, BatchNormalization, Activation\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    #x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def create_fcn32(input_size=(512,512,3)):\n",
    "    # model = Sequential()\n",
    "    # preprocessing\n",
    "    input = Input(shape=(input_size))\n",
    "    #x = ZeroPadding2D(100)(input)\n",
    "    # layer1 2conv  1/2\n",
    "    x = conv2d_bn(input, 64, (3,3))\n",
    "    x = conv2d_bn(x, 64, (3,3))\n",
    "    pool1 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer2 2conv 1/4\n",
    "    x = conv2d_bn(pool1, 128, (3,3))\n",
    "    x = conv2d_bn(x, 128, (3,3))\n",
    "    pool2 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer3 3conv 1/8\n",
    "    x = conv2d_bn(pool2, 256, (3,3))\n",
    "    x = conv2d_bn(x, 256, (3,3))\n",
    "    x = conv2d_bn(x, 256, (3,3))\n",
    "    pool3 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer4 3conv 1/16\n",
    "    x = conv2d_bn(pool3, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    pool4 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer5 3conv 1/32\n",
    "    x = conv2d_bn(pool4, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    pool5 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer6 2full\n",
    "    full_1 = conv2d_bn(pool5, 4096, (7,7))\n",
    "    drop_1 = Dropout(0.5)(full_1)\n",
    "    full_2 = conv2d_bn(drop_1, 4096, (1,1))\n",
    "    drop_2 = Dropout(0.5)(full_2)\n",
    "\n",
    "    # 上采样32倍\n",
    "    drop_2_n = conv2d_bn(drop_1, 21, (1,1), padding='valid')\n",
    "    #deconv_1 = Conv2DTranspose(21, (64,64), strides=32)(drop_2_n)\n",
    "\n",
    "    ratio = (int(input.shape[1].value/drop_2_n.shape[1].value), int(input.shape[2].value/drop_2_n.shape[2].value))\n",
    "    print(ratio)\n",
    "    bilinear_inter_1 = UpSampling2D(ratio)(drop_2_n)\n",
    "    deconv_1 = conv2d_bn(bilinear_inter_1, 21, (3,3))\n",
    "\n",
    "    output=Activation('softmax')(deconv_1)\n",
    "\n",
    "    model = Model(input, output, name='fcn_net')\n",
    "    return model\n",
    "\n",
    "model = create_fcn32((512, 512, 3))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "Epoch 1/10\n",
      "214/500 [===========>..................] - ETA: 1:24 - loss: 1.4426 - acc: 0.7418"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-dec1e1de5407>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     use_multiprocessing=False)\n\u001b[0m",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "optimizer = keras.optimizers.Adam(1e-4)\n",
    "model = create_fcn32((224, 224, 3))\n",
    "# model.summary()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(\n",
    "    datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=5,\n",
    "        shuffle=True,\n",
    "        image_set_loader=train_loader),\n",
    "    steps_per_epoch=500,\n",
    "    epochs=1,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 16:04:22.836684 140494861784896 deprecation.py:323] From /home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(32, 32)\n",
      "Epoch 1/1\n",
      "500/500 [==============================] - 120s 239ms/step - loss: 0.5536 - acc: 0.7920\n",
      "loss:  0.5105776464566588\n",
      "acc:  0.8322963178157806\n"
     ]
    }
   ],
   "source": [
    "#utils.get_model_memory_usage(10, model)\n",
    "#data_path = \"/home/super-workstation/Data/pascal/VOC_Data/VOC2012\"\n",
    "#train_data(model, image_root, batch_size=1, epochs=5)\n",
    "optimizer = keras.optimizers.Adam(1e-4)\n",
    "model = create_fcn32((224, 224, 3))\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "config = Config()\n",
    "config.batch_size = 1\n",
    "config.steps_per_epoch = 500\n",
    "config.validation_steps = 100\n",
    "config.epochs=1\n",
    "config.image_min_dims = 224\n",
    "config.image_max_dims = 224\n",
    "\n",
    "train_dataset = PascalDataset(path, is_train=True)\n",
    "val_dataset = PascalDataset(path, is_train=False)\n",
    "\n",
    "train_generator = data_generator(train_dataset, config)\n",
    "val_generator = data_generator(val_dataset, config)\n",
    "\n",
    "workers = 1  # multiprocessing.cpu_count()\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=config.steps_per_epoch, epochs=config.epochs,\n",
    "                    use_multiprocessing=False, max_queue_size=100, workers=workers\n",
    "                    )\n",
    "#                     validation_data=val_generator, validation_steps=config.validation_steps\n",
    "scores = model.evaluate_generator(val_generator, steps=10)\n",
    "print(\"loss: \", scores[0])\n",
    "print(\"acc: \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0903 16:09:59.913172 140494861784896 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio_1:  (2, 2)\n",
      "ratio_2:  (16, 16)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_35 (Conv2D)              (None, 512, 512, 64) 1792        input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_35[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_37 (Activation)      (None, 512, 512, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_36 (Conv2D)              (None, 512, 512, 64) 36928       activation_37[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 64) 256         conv2d_36[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_38 (Activation)      (None, 512, 512, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 256, 256, 64) 0           activation_38[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_37 (Conv2D)              (None, 256, 256, 128 73856       max_pooling2d_11[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 128 512         conv2d_37[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_39 (Activation)      (None, 256, 256, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_38 (Conv2D)              (None, 256, 256, 128 147584      activation_39[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 128 512         conv2d_38[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_40 (Activation)      (None, 256, 256, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_12 (MaxPooling2D) (None, 128, 128, 128 0           activation_40[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_39 (Conv2D)              (None, 128, 128, 256 295168      max_pooling2d_12[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_39[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_41 (Activation)      (None, 128, 128, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_40 (Conv2D)              (None, 128, 128, 256 590080      activation_41[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 256 1024        conv2d_40[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_42 (Activation)      (None, 128, 128, 256 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_41 (Conv2D)              (None, 128, 128, 256 590080      activation_42[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 128, 128, 256 1024        conv2d_41[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_43 (Activation)      (None, 128, 128, 256 0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_13 (MaxPooling2D) (None, 64, 64, 256)  0           activation_43[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_42 (Conv2D)              (None, 64, 64, 512)  1180160     max_pooling2d_13[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 512)  2048        conv2d_42[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_44 (Activation)      (None, 64, 64, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_43 (Conv2D)              (None, 64, 64, 512)  2359808     activation_44[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 64, 64, 512)  2048        conv2d_43[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_45 (Activation)      (None, 64, 64, 512)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_44 (Conv2D)              (None, 64, 64, 512)  2359808     activation_45[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 64, 64, 512)  2048        conv2d_44[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_46 (Activation)      (None, 64, 64, 512)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_14 (MaxPooling2D) (None, 32, 32, 512)  0           activation_46[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_45 (Conv2D)              (None, 32, 32, 512)  2359808     max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 32, 32, 512)  2048        conv2d_45[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_47 (Activation)      (None, 32, 32, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_46 (Conv2D)              (None, 32, 32, 512)  2359808     activation_47[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 32, 32, 512)  2048        conv2d_46[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_48 (Activation)      (None, 32, 32, 512)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_47 (Conv2D)              (None, 32, 32, 512)  2359808     activation_48[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 32, 32, 512)  2048        conv2d_47[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_49 (Activation)      (None, 32, 32, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_15 (MaxPooling2D) (None, 16, 16, 512)  0           activation_49[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_48 (Conv2D)              (None, 16, 16, 4096) 102764544   max_pooling2d_15[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 16, 16, 4096) 16384       conv2d_48[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_50 (Activation)      (None, 16, 16, 4096) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "dropout_5 (Dropout)             (None, 16, 16, 4096) 0           activation_50[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_50 (Conv2D)              (None, 16, 16, 21)   86037       dropout_5[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 16, 16, 21)   84          conv2d_50[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_52 (Activation)      (None, 16, 16, 21)   0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 32, 32, 21)   0           activation_52[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_51 (Conv2D)              (None, 32, 32, 21)   462         up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_52 (Conv2D)              (None, 32, 32, 21)   10773       max_pooling2d_14[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 32, 32, 21)   84          conv2d_51[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 32, 32, 21)   84          conv2d_52[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_53 (Activation)      (None, 32, 32, 21)   0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_54 (Activation)      (None, 32, 32, 21)   0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 32, 21)   0           activation_53[0][0]              \n",
      "                                                                 activation_54[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 21) 0           add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_53 (Conv2D)              (None, 512, 512, 21) 462         up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 512, 512, 21) 84          conv2d_53[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_55 (Activation)      (None, 512, 512, 21) 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "activation_56 (Activation)      (None, 512, 512, 21) 0           activation_55[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 117,610,582\n",
      "Trainable params: 117,593,774\n",
      "Non-trainable params: 16,808\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# fcn 16s\n",
    "# 直接从 pool4 上采样（反卷级）到原尺寸\n",
    "# 5 layers\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers import Conv2D, Conv2DTranspose, MaxPooling2D, Dropout, UpSampling2D\n",
    "from keras.layers import Input, ZeroPadding2D, BatchNormalization, Activation\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def create_fcn16(input_size=(512,512,3)):\n",
    "    # model = Sequential()\n",
    "    # preprocessing\n",
    "    input = Input(shape=(input_size))\n",
    "    #x = ZeroPadding2D(100)(input)\n",
    "    # layer1 2conv  1/2\n",
    "    x = conv2d_bn(input, 64, (3,3))\n",
    "    x = conv2d_bn(x, 64, (3,3))\n",
    "    pool1 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer2 2conv 1/4\n",
    "    x = conv2d_bn(pool1, 128, (3,3))\n",
    "    x = conv2d_bn(x, 128, (3,3))\n",
    "    pool2 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer3 3conv 1/8\n",
    "    x = conv2d_bn(pool2, 256, (3,3))\n",
    "    x = conv2d_bn(x, 256, (3,3))\n",
    "    x = conv2d_bn(x, 256, (3,3))\n",
    "    pool3 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer4 3conv 1/16\n",
    "    x = conv2d_bn(pool3, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    pool4 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer5 3conv 1/32\n",
    "    x = conv2d_bn(pool4, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    x = conv2d_bn(x, 512, (3,3))\n",
    "    pool5 = MaxPooling2D()(x)\n",
    "\n",
    "    # layer6 2full\n",
    "    full_1 = conv2d_bn(pool5, 4096, (7,7))\n",
    "    drop_1 = Dropout(0.5)(full_1)\n",
    "    full_2 = conv2d_bn(drop_1, 4096, (1,1))\n",
    "    drop_2 = Dropout(0.5)(full_2)\n",
    "\n",
    "    # 上采样2倍 = pool4 size\n",
    "    drop_2_n = conv2d_bn(drop_1, 21, (1,1))\n",
    "    #deconv_1 = Conv2DTranspose(21, (64,64), strides=32)(drop_2_n)\n",
    "\n",
    "    ratio_1 = (int(pool4.shape[1].value/drop_2_n.shape[1].value), int(pool4.shape[2].value/drop_2_n.shape[2].value))\n",
    "    print(\"ratio_1: \", ratio_1)\n",
    "    bilinear_inter_1 = UpSampling2D(ratio_1)(drop_2_n)\n",
    "    deconv_1 = conv2d_bn(bilinear_inter_1, 21, (1,1))\n",
    "    \n",
    "    # merge(+)\n",
    "    pool4_u = conv2d_bn(pool4, 21, (1,1))\n",
    "    merge_1 = keras.layers.add([deconv_1, pool4_u])\n",
    "    \n",
    "    # upsample 16\n",
    "    ratio_2 = (int(input.shape[1].value/merge_1.shape[1].value), int(input.shape[2].value/merge_1.shape[2].value))\n",
    "    print(\"ratio_2: \", ratio_2)\n",
    "    bilinear_inter_2 = UpSampling2D(ratio_2)(merge_1)\n",
    "    deconv_2 = conv2d_bn(bilinear_inter_2, 21, (1,1))\n",
    "    \n",
    "    output=Activation('softmax')(deconv_2)\n",
    "\n",
    "    model = Model(input, output, name='fcn_net')\n",
    "    return model\n",
    "\n",
    "model = create_fcn16((512, 512, 3))\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='sgd', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ratio_1:  (2, 2)\n",
      "ratio_2:  (16, 16)\n",
      "Epoch 1/1\n",
      "229/500 [============>.................] - ETA: 1:07 - loss: 0.5565 - acc: 0.0593"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-9093041ad33c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m model.fit_generator(train_generator, steps_per_epoch=config.steps_per_epoch, epochs=config.epochs,\n\u001b[0;32m---> 24\u001b[0;31m                     \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m                     )\n\u001b[1;32m     26\u001b[0m \u001b[0;31m#                     validation_data=val_generator, validation_steps=config.validation_steps\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# train fcn16\n",
    "#train_data(data_path)\n",
    "optimizer = keras.optimizers.Adam(1e-4)\n",
    "model = create_fcn16((224, 224, 3))\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "config = Config()\n",
    "config.batch_size = 1\n",
    "config.steps_per_epoch = 500\n",
    "config.validation_steps = 100\n",
    "config.epochs=1\n",
    "config.image_min_dims = 224\n",
    "config.image_max_dims = 224\n",
    "\n",
    "train_dataset = PascalDataset(path, is_train=True)\n",
    "val_dataset = PascalDataset(path, is_train=False)\n",
    "\n",
    "train_generator = data_generator(train_dataset, config)\n",
    "val_generator = data_generator(val_dataset, config)\n",
    "\n",
    "workers = 1  # multiprocessing.cpu_count()\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=config.steps_per_epoch, epochs=config.epochs,\n",
    "                    use_multiprocessing=False, max_queue_size=100, workers=workers\n",
    "                    )\n",
    "#                     validation_data=val_generator, validation_steps=config.validation_steps\n",
    "scores = model.evaluate_generator(val_generator, steps=10)\n",
    "print(\"loss: \", scores[0])\n",
    "print(\"acc: \", scores[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0902 16:33:02.345448 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0902 16:33:02.355477 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0902 16:33:02.357587 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0902 16:33:02.373154 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:174: The name tf.get_default_session is deprecated. Please use tf.compat.v1.get_default_session instead.\n",
      "\n",
      "W0902 16:33:02.373647 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:181: The name tf.ConfigProto is deprecated. Please use tf.compat.v1.ConfigProto instead.\n",
      "\n",
      "W0902 16:33:02.825331 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0902 16:33:02.913526 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "W0902 16:33:03.347532 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:2018: The name tf.image.resize_nearest_neighbor is deprecated. Please use tf.compat.v1.image.resize_nearest_neighbor instead.\n",
      "\n",
      "W0902 16:33:04.054751 139663675918144 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 512, 512, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 512, 512, 64) 1792        input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 512, 512, 64) 256         conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 512, 512, 64) 0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 512, 512, 64) 36928       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 512, 512, 64) 256         conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 512, 512, 64) 0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 256, 256, 64) 0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 256, 256, 128 73856       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 256, 256, 128 512         conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 256, 256, 128 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 256, 256, 128 147584      activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 256, 256, 128 512         conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 256, 256, 128 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 128, 128, 128 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 128, 128, 256 295168      max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 128, 128, 256 1024        conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 128, 128, 256 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 128, 128, 256 590080      activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 128, 128, 256 1024        conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128, 128, 256 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 64, 64, 256)  0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 64, 64, 512)  1180160     max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 64, 64, 512)  2048        conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 64, 64, 512)  0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 64, 64, 512)  2359808     activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 64, 64, 512)  2048        conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 64, 64, 512)  0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 32, 32, 512)  0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 32, 32, 1024) 4719616     max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 32, 32, 1024) 4096        conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 32, 32, 1024) 0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 32, 32, 1024) 9438208     activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 32, 32, 1024) 4096        conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 32, 32, 1024) 0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_1 (UpSampling2D)  (None, 64, 64, 1024) 0           activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 64, 64, 512)  4719104     up_sampling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 64, 64, 512)  2048        conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_11 (Activation)      (None, 64, 64, 512)  0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 64, 64, 1024) 0           activation_11[0][0]              \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 64, 64, 512)  4719104     concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 64, 64, 512)  2048        conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 64, 64, 512)  0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 64, 64, 512)  2359808     activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 64, 64, 512)  2048        conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 64, 64, 512)  0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_2 (UpSampling2D)  (None, 128, 128, 512 0           activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 128, 128, 256 1179904     up_sampling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 128, 128, 256 1024        conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 128, 128, 256 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 128, 512 0           activation_14[0][0]              \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 128, 128, 256 1179904     concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 128, 128, 256 1024        conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 128, 128, 256 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 128, 128, 256 590080      activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 128, 128, 256 1024        conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 128, 128, 256 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_3 (UpSampling2D)  (None, 256, 256, 256 0           activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 256, 256, 128 295040      up_sampling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 256, 256, 128 512         conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 256, 256, 128 0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 256, 256, 256 0           activation_17[0][0]              \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 256, 256, 128 295040      concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 256, 256, 128 512         conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 256, 256, 128 0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 256, 256, 128 147584      activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_19 (BatchNo (None, 256, 256, 128 512         conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 256, 256, 128 0           batch_normalization_19[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "up_sampling2d_4 (UpSampling2D)  (None, 512, 512, 128 0           activation_19[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_20 (Conv2D)              (None, 512, 512, 128 147584      up_sampling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_20 (BatchNo (None, 512, 512, 128 512         conv2d_20[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_20 (Activation)      (None, 512, 512, 128 0           batch_normalization_20[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 512, 512, 192 0           activation_20[0][0]              \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_21 (Conv2D)              (None, 512, 512, 128 221312      concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_21 (BatchNo (None, 512, 512, 128 512         conv2d_21[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_21 (Activation)      (None, 512, 512, 128 0           batch_normalization_21[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_22 (Conv2D)              (None, 512, 512, 128 147584      activation_21[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_22 (BatchNo (None, 512, 512, 128 512         conv2d_22[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_22 (Activation)      (None, 512, 512, 128 0           batch_normalization_22[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_23 (Conv2D)              (None, 512, 512, 21) 2709        activation_22[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_23 (BatchNo (None, 512, 512, 21) 84          conv2d_23[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_23 (Activation)      (None, 512, 512, 21) 0           batch_normalization_23[0][0]     \n",
      "==================================================================================================\n",
      "Total params: 34,876,201\n",
      "Trainable params: 34,862,079\n",
      "Non-trainable params: 14,122\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# u-net\n",
    "import keras\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Activation, Input, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def upsample_contract(input_1, input_2, nums_kernel, kernel_size=(3,3)):\n",
    "    up_ratio = (int(input_2.shape[1].value/input_1.shape[1].value), \n",
    "                int(input_2.shape[2].value/input_1.shape[2].value))\n",
    "    upsample = UpSampling2D(up_ratio)(input_1)\n",
    "    conv = conv2d_bn(upsample, nums_kernel, kernel_size)\n",
    "    concat = keras.layers.concatenate([conv, input_2])\n",
    "    return concat\n",
    "\n",
    "def create_unet(input_shape=(512,512,3)):\n",
    "    input = Input(input_shape)\n",
    "    # layer 1\n",
    "    conv_1a = conv2d_bn(input, 64, (3,3))\n",
    "    conv_1b = conv2d_bn(conv_1a, 64, (3,3))\n",
    "    pooling_1 = MaxPooling2D()(conv_1b)\n",
    "    # layer 2\n",
    "    conv_2a = conv2d_bn(pooling_1, 128, (3,3))\n",
    "    conv_2b = conv2d_bn(conv_2a, 128, (3,3))\n",
    "    pooling_2 = MaxPooling2D()(conv_2b)\n",
    "    # layer 3\n",
    "    conv_3a = conv2d_bn(pooling_2, 256, (3,3))\n",
    "    conv_3b = conv2d_bn(conv_3a, 256, (3,3))\n",
    "    pooling_3 = MaxPooling2D()(conv_3b)\n",
    "    # layer 4\n",
    "    conv_4a = conv2d_bn(pooling_3, 512, (3,3))\n",
    "    conv_4b = conv2d_bn(conv_4a, 512, (3,3))\n",
    "    pooling_4 = MaxPooling2D()(conv_4b)\n",
    "    # layer 5\n",
    "    conv_5a = conv2d_bn(pooling_4, 1024, (3,3))\n",
    "    conv_5b = conv2d_bn(conv_5a, 1024, (3,3))\n",
    "    #pooling_5 = MaxPooling2D()(conv_5b)\n",
    "\n",
    "    # inv_layer 4\n",
    "    de_conv_4a = upsample_contract(conv_5b, conv_4b, 512)\n",
    "    de_conv_4b = conv2d_bn(de_conv_4a, 512, (3,3))\n",
    "    de_conv_4c = conv2d_bn(de_conv_4b, 512, (3,3))\n",
    "\n",
    "    # inv_layer 3\n",
    "    de_conv_3a = upsample_contract(de_conv_4c, conv_3b, 256)\n",
    "    de_conv_3b = conv2d_bn(de_conv_3a, 256, (3,3))\n",
    "    de_conv_3c = conv2d_bn(de_conv_3b, 256, (3,3))\n",
    "\n",
    "    # inv_layer 2\n",
    "    de_conv_2a = upsample_contract(de_conv_3c, conv_2b, 128)\n",
    "    de_conv_2b = conv2d_bn(de_conv_2a, 128, (3,3))\n",
    "    de_conv_2c = conv2d_bn(de_conv_2b, 128, (3,3))\n",
    "\n",
    "    # inv_layer 1\n",
    "    de_conv_1a = upsample_contract(de_conv_2c, conv_1b, 128)\n",
    "    de_conv_1b = conv2d_bn(de_conv_1a, 128, (3,3))\n",
    "    de_conv_1c = conv2d_bn(de_conv_1b, 128, (3,3))\n",
    "\n",
    "    # output\n",
    "    output = conv2d_bn(de_conv_1c, 21, (1,1))\n",
    "\n",
    "    model = Model(input, output, name='u-net')\n",
    "    return model\n",
    "model = create_unet((512,512,3))\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6.067"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "utils.get_model_memory_usage(2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "180/180 [==============================] - 92s 513ms/step - loss: 1.0927 - acc: 0.0122 - val_loss: 0.6037 - val_acc: 0.0324\n",
      "Epoch 2/10\n",
      " 14/180 [=>............................] - ETA: 1:16 - loss: 0.6537 - acc: 0.0124"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-f949c5e01a80>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#utils.trainAndEvaluateData(model, train_data, train_one_hot_label, test_data, test_one_hot_label， 12， batch_size = 16)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"./check_points/unet_weights.hdf5\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-cc8000784544>\u001b[0m in \u001b[0;36mtrain_data\u001b[0;34m(path, batch_size, filepath, log_dir, epochs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     model.fit_generator(train_generator, steps_per_epoch=config.steps_per_epoch, epochs=epochs,\n\u001b[1;32m    137\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                        )\n\u001b[1;32m    140\u001b[0m '''    \n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2653\u001b[0m                 array_vals.append(\n\u001b[1;32m   2654\u001b[0m                     np.asarray(value,\n\u001b[0;32m-> 2655\u001b[0;31m                                dtype=tf.as_dtype(tensor.dtype).as_numpy_dtype))\n\u001b[0m\u001b[1;32m   2656\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2657\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/numpy/core/_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[0;34m(a, dtype, order)\u001b[0m\n\u001b[1;32m     83\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m     \"\"\"\n\u001b[0;32m---> 85\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#utils.trainAndEvaluateData(model, train_data, train_one_hot_label, test_data, test_one_hot_label， 12， batch_size = 16)\n",
    "train_data(image_root, batch_size=2, filepath=\"./check_points/unet_weights.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         (None, 224, 224, 3)       0         \n",
      "_________________________________________________________________\n",
      "block1_conv1 (Conv2D)        (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "block1_conv2 (Conv2D)        (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "block1_pool (MaxPooling2D)   (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "block2_conv1 (Conv2D)        (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "block2_conv2 (Conv2D)        (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "block2_pool (MaxPooling2D)   (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "block3_conv1 (Conv2D)        (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "block3_conv2 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_conv3 (Conv2D)        (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "block3_pool (MaxPooling2D)   (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "block4_conv1 (Conv2D)        (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "block4_conv2 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_conv3 (Conv2D)        (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block4_pool (MaxPooling2D)   (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "block5_conv1 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv2 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_conv3 (Conv2D)        (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "block5_pool (MaxPooling2D)   (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "fc1 (Conv2D)                 (None, 7, 7, 4096)        102764544 \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 7, 7, 4096)        0         \n",
      "_________________________________________________________________\n",
      "fc2 (Conv2D)                 (None, 7, 7, 4096)        16781312  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 7, 7, 4096)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 7, 7, 21)          86037     \n",
      "_________________________________________________________________\n",
      "bilinear_up_sampling2d_1 (Bi (None, 224, 224, 21)      0         \n",
      "=================================================================\n",
      "Total params: 134,346,581\n",
      "Trainable params: 134,346,581\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.regularizers import l2\n",
    "from keras.models import Model\n",
    "from keras.layers import Conv2D, Dense, MaxPooling2D, UpSampling2D\n",
    "from keras.layers import Activation, Input, BatchNormalization\n",
    "from keras.optimizers import SGD\n",
    "import keras.backend as K\n",
    "import tensorflow as tf\n",
    "from keras.layers import *\n",
    "\n",
    "def resize_images_bilinear(X, height_factor=1, width_factor=1, target_height=None, target_width=None, data_format='default'):\n",
    "    '''Resizes the images contained in a 4D tensor of shape\n",
    "    - [batch, channels, height, width] (for 'channels_first' data_format)\n",
    "    - [batch, height, width, channels] (for 'channels_last' data_format)\n",
    "    by a factor of (height_factor, width_factor). Both factors should be\n",
    "    positive integers.\n",
    "    '''\n",
    "    if data_format == 'default':\n",
    "        data_format = K.image_data_format()\n",
    "    if data_format == 'channels_first':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[2:]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = permute_dimensions(X, [0, 2, 3, 1])\n",
    "        X = tf.image.resize_bilinear(X, new_shape)\n",
    "        X = permute_dimensions(X, [0, 3, 1, 2])\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, None, target_height, target_width))\n",
    "        else:\n",
    "            X.set_shape((None, None, original_shape[2] * height_factor, original_shape[3] * width_factor))\n",
    "        return X\n",
    "    elif data_format == 'channels_last':\n",
    "        original_shape = K.int_shape(X)\n",
    "        if target_height and target_width:\n",
    "            new_shape = tf.constant(np.array((target_height, target_width)).astype('int32'))\n",
    "        else:\n",
    "            new_shape = tf.shape(X)[1:3]\n",
    "            new_shape *= tf.constant(np.array([height_factor, width_factor]).astype('int32'))\n",
    "        X = tf.image.resize_bilinear(X, new_shape)\n",
    "        if target_height and target_width:\n",
    "            X.set_shape((None, target_height, target_width, None))\n",
    "        else:\n",
    "            X.set_shape((None, original_shape[1] * height_factor, original_shape[2] * width_factor, None))\n",
    "        return X\n",
    "    else:\n",
    "        raise Exception('Invalid data_format: ' + data_format)\n",
    "\n",
    "class BilinearUpSampling2D(Layer):\n",
    "    def __init__(self, size=(1, 1), target_size=None, data_format='default', **kwargs):\n",
    "        if data_format == 'default':\n",
    "            data_format = K.image_data_format()\n",
    "        self.size = tuple(size)\n",
    "        if target_size is not None:\n",
    "            self.target_size = tuple(target_size)\n",
    "        else:\n",
    "            self.target_size = None\n",
    "        assert data_format in {'channels_last', 'channels_first'}, 'data_format must be in {tf, th}'\n",
    "        self.data_format = data_format\n",
    "        self.input_spec = [InputSpec(ndim=4)]\n",
    "        super(BilinearUpSampling2D, self).__init__(**kwargs)\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        if self.data_format == 'channels_first':\n",
    "            width = int(self.size[0] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[3] if input_shape[3] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    input_shape[1],\n",
    "                    width,\n",
    "                    height)\n",
    "        elif self.data_format == 'channels_last':\n",
    "            width = int(self.size[0] * input_shape[1] if input_shape[1] is not None else None)\n",
    "            height = int(self.size[1] * input_shape[2] if input_shape[2] is not None else None)\n",
    "            if self.target_size is not None:\n",
    "                width = self.target_size[0]\n",
    "                height = self.target_size[1]\n",
    "            return (input_shape[0],\n",
    "                    width,\n",
    "                    height,\n",
    "                    input_shape[3])\n",
    "        else:\n",
    "            raise Exception('Invalid data_format: ' + self.data_format)\n",
    "\n",
    "    def call(self, x, mask=None):\n",
    "        if self.target_size is not None:\n",
    "            return resize_images_bilinear(x, target_height=self.target_size[0], target_width=self.target_size[1], data_format=self.data_format)\n",
    "        else:\n",
    "            return resize_images_bilinear(x, height_factor=self.size[0], width_factor=self.size[1], data_format=self.data_format)\n",
    "\n",
    "    def get_config(self):\n",
    "        config = {'size': self.size, 'target_size': self.target_size}\n",
    "        base_config = super(BilinearUpSampling2D, self).get_config()\n",
    "        return dict(list(base_config.items()) + list(config.items()))\n",
    "\n",
    "def FCN_Vgg16_32s(input_shape=None, weight_decay=0., batch_momentum=0.9, batch_shape=None, classes=21):\n",
    "    if batch_shape:\n",
    "        img_input = Input(batch_shape=batch_shape)\n",
    "        image_size = batch_shape[1:3]\n",
    "    else:\n",
    "        img_input = Input(shape=input_shape)\n",
    "        image_size = input_shape[0:2]\n",
    "    # Block 1\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv1', kernel_regularizer=l2(weight_decay))(img_input)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same', name='block1_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block1_pool')(x)\n",
    "\n",
    "    # Block 2\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same', name='block2_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block2_pool')(x)\n",
    "\n",
    "    # Block 3\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same', name='block3_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block3_pool')(x)\n",
    "\n",
    "    # Block 4\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block4_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block4_pool')(x)\n",
    "\n",
    "    # Block 5\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Conv2D(512, (3, 3), activation='relu', padding='same', name='block5_conv3', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = MaxPooling2D((2, 2), strides=(2, 2), name='block5_pool')(x)\n",
    "\n",
    "    # Convolutional layers transfered from fully-connected layers\n",
    "    x = Conv2D(4096, (7, 7), activation='relu', padding='same', name='fc1', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    x = Conv2D(4096, (1, 1), activation='relu', padding='same', name='fc2', kernel_regularizer=l2(weight_decay))(x)\n",
    "    x = Dropout(0.5)(x)\n",
    "    #classifying layer\n",
    "    x = Conv2D(classes, (1, 1), kernel_initializer='he_normal', activation='linear', padding='valid', strides=(1, 1), kernel_regularizer=l2(weight_decay))(x)\n",
    "\n",
    "    x = BilinearUpSampling2D(size=(32, 32))(x)\n",
    "\n",
    "    model = Model(img_input, x)\n",
    "\n",
    "    #weights_path = os.path.expanduser(os.path.join('~', '.keras/models/fcn_vgg16_weights_tf_dim_ordering_tf_kernels.h5'))\n",
    "    #model.load_weights(weights_path, by_name=True)\n",
    "    return model\n",
    "\n",
    "model = FCN_Vgg16_32s(input_shape=(224,224,3))\n",
    "model.summary()\n",
    "\n",
    "sgd = SGD(lr=0.01, momentum=0.9)\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer=sgd, metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0902 17:35:44.055914 140474304669504 deprecation.py:323] From /home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
      "W0902 17:35:46.277788 140474304669504 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/callbacks.py:850: The name tf.summary.merge_all is deprecated. Please use tf.compat.v1.summary.merge_all instead.\n",
      "\n",
      "W0902 17:35:46.278340 140474304669504 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/callbacks.py:853: The name tf.summary.FileWriter is deprecated. Please use tf.compat.v1.summary.FileWriter instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "180/180 [==============================] - 203s 1s/step - loss: 1.0531 - acc: 0.0210 - val_loss: 1.2702 - val_acc: 0.0153\n",
      "Epoch 2/10\n",
      "180/180 [==============================] - 199s 1s/step - loss: 1.3795 - acc: 0.0194 - val_loss: 1.7661 - val_acc: 0.0143\n",
      "Epoch 3/10\n",
      "112/180 [=================>............] - ETA: 1:08 - loss: 1.7614 - acc: 0.0221"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-aa0209f40658>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#utils.get_model_memory_usage(20, model)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtrain_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_root\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-1-cc8000784544>\u001b[0m in \u001b[0;36mtrain_data\u001b[0;34m(path, batch_size, filepath, log_dir, epochs)\u001b[0m\n\u001b[1;32m    136\u001b[0m     model.fit_generator(train_generator, steps_per_epoch=config.steps_per_epoch, epochs=epochs,\n\u001b[1;32m    137\u001b[0m                         \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalidation_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_queue_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    139\u001b[0m                        )\n\u001b[1;32m    140\u001b[0m '''    \n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1215\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1216\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1217\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1218\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0munpack_singleton\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1219\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1456\u001b[0m         ret = tf_session.TF_SessionRunCallable(self._session._session,\n\u001b[1;32m   1457\u001b[0m                                                \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1458\u001b[0;31m                                                run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1459\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1460\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#utils.get_model_memory_usage(20, model)\n",
    "train_data(image_root, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.backend.tensorflow_backend import clear_session\n",
    "from keras.backend.tensorflow_backend import get_session\n",
    "import tensorflow\n",
    "\n",
    "def reset_keras():\n",
    "    sess = get_session()\n",
    "    clear_session()\n",
    "    sess.close()\n",
    "    sess = get_session()\n",
    "\n",
    "    try:\n",
    "        del classifier # this is from global space - change this as you need\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    #print(gc.collect()) # if it's done something you should see a number being outputted\n",
    "\n",
    "    # use the same config as you used to create the session\n",
    "    config = tensorflow.ConfigProto()\n",
    "    config.gpu_options.per_process_gpu_memory_fraction = 1\n",
    "    config.gpu_options.visible_device_list = \"0\"\n",
    "    set_session(tensorflow.Session(config=config))\n",
    "reset_keras()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "flow_from_imageset\n",
      "[0 1 2 3 4]\n",
      "(5, 224, 224, 3) (5, 224, 224, 21)\n",
      "info:\n",
      "image size -->  224 x 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/super-workstation/.local/lib/python3.6/site-packages/ipykernel_launcher.py:278: YAMLLoadWarning: calling yaml.load() without Loader=... is deprecated, as the default Loader is unsafe. Please read https://msg.pyyaml.org/load for full details.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " ...\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]\n",
      " [1 1 1 ... 1 1 1]]\n",
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\n    validation_data=datagen.flow_from_imageset(\\n        class_mode='categorical',\\n        classes=21,\\n        batch_size=5,\\n        shuffle=True,\\n        image_set_loader=val_loader),\\n    validation_steps=100,\\n\\nfcn_vgg16 = FCN(input_shape=(224, 224, 3), classes=21, weight_decay=3e-3,\\n                weights='imagenet', trainable_encoder=True)\\nfcn_vgg16.compile(optimizer=optimizer,\\n                  loss='categorical_crossentropy',\\n                  metrics=['accuracy'])\\n\\nfcn_vgg16.fit_generator(\\n    datagen.flow_from_imageset(\\n        class_mode='categorical',\\n        classes=21,\\n        batch_size=1,\\n        shuffle=True,\\n        image_set_loader=train_loader),\\n    steps_per_epoch=1112,\\n    epochs=100,\\n    validation_data=datagen.flow_from_imageset(\\n        class_mode='categorical',\\n        classes=21,\\n        batch_size=1,\\n        shuffle=True,\\n        image_set_loader=val_loader),\\n    validation_steps=1111,\\n    verbose=1,\\n    callbacks=[lr_reducer, early_stopper, csv_logger, checkpointer, nan_terminator])\\n\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Pascal VOC Segmenttion Generator.\"\"\"\n",
    "from __future__ import unicode_literals\n",
    "import os\n",
    "import numpy as np\n",
    "from keras import backend as K\n",
    "from keras.utils.np_utils import to_categorical\n",
    "import PIL.Image as pil_image\n",
    "from keras.preprocessing.image import (\n",
    "    ImageDataGenerator,\n",
    "    Iterator,\n",
    "    load_img,\n",
    "    img_to_array,\n",
    "    array_to_img)\n",
    "\n",
    "\n",
    "class PascalVocGenerator(ImageDataGenerator):\n",
    "    \"\"\"A real-time data augmentation generator for PASCAL VOC2011.\"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 image_shape=(500, 500, 3),\n",
    "                 image_resample=True,\n",
    "                 pixelwise_center=False,\n",
    "                 pixel_mean=(0., 0., 0.),\n",
    "                 pixelwise_std_normalization=False,\n",
    "                 pixel_std=(1., 1., 1.),\n",
    "                 featurewise_center=False,\n",
    "                 samplewise_center=False,\n",
    "                 featurewise_std_normalization=False,\n",
    "                 samplewise_std_normalization=False,\n",
    "                 zca_whitening=False,\n",
    "                 rotation_range=0.,\n",
    "                 width_shift_range=0.,\n",
    "                 height_shift_range=0.,\n",
    "                 shear_range=0.,\n",
    "                 zoom_range=0.,\n",
    "                 channel_shift_range=0.,\n",
    "                 fill_mode='nearest',\n",
    "                 cval=0.,\n",
    "                 horizontal_flip=False,\n",
    "                 vertical_flip=False,\n",
    "                 rescale=None,\n",
    "                 preprocessing_function=None,\n",
    "                 data_format=None):\n",
    "        \"\"\"Init.\"\"\"\n",
    "        self.image_shape = tuple(image_shape)\n",
    "        self.image_resample = image_resample\n",
    "        self.pixelwise_center = pixelwise_center\n",
    "        self.pixel_mean = np.array(pixel_mean)\n",
    "        self.pixelwise_std_normalization = pixelwise_std_normalization\n",
    "        self.pixel_std = np.array(pixel_std)\n",
    "        super(PascalVocGenerator, self).__init__()\n",
    "\n",
    "    def standardize(self, x):\n",
    "        \"\"\"Standardize image.\"\"\"\n",
    "        if self.pixelwise_center:\n",
    "            x -= self.pixel_mean\n",
    "        if self.pixelwise_std_normalization:\n",
    "            x /= self.pixel_std\n",
    "        return super(PascalVocGenerator, self).standardize(x)\n",
    "\n",
    "    def flow_from_imageset(self, image_set_loader,\n",
    "                           class_mode='categorical', classes=None,\n",
    "                           batch_size=1, shuffle=True, seed=None):\n",
    "        \"\"\"PascalVocGenerator.\"\"\"\n",
    "        print(\"flow_from_imageset\")\n",
    "        return IndexIterator(\n",
    "            image_set_loader, self,\n",
    "            class_mode=class_mode,\n",
    "            classes=classes,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed)\n",
    "\n",
    "\n",
    "class IndexIterator(Iterator):\n",
    "    \"\"\"Iterator over index.\"\"\"\n",
    "\n",
    "    def __init__(self, image_set_loader, image_data_generator,\n",
    "                 class_mode='categorical', classes=None,\n",
    "                 batch_size=1, shuffle=False, seed=None):\n",
    "        \"\"\"Init.\"\"\"\n",
    "        self.image_set_loader = image_set_loader\n",
    "        self.image_data_generator = image_data_generator\n",
    "\n",
    "        self.filenames = image_set_loader.filenames\n",
    "        self.image_shape = image_set_loader.image_shape\n",
    "\n",
    "        self.classes = classes\n",
    "        if class_mode == 'binary':\n",
    "            label_shape = list(self.image_shape).pop(self.channel_axis - 1)\n",
    "            self.label_shape = tuple(label_shape)\n",
    "        elif class_mode == 'categorical':\n",
    "            label_shape = list(self.image_shape)\n",
    "            label_shape[self.image_data_generator.channel_axis - 1] \\\n",
    "                = self.classes\n",
    "            self.label_shape = tuple(label_shape)\n",
    "        #print(self.label_shape)\n",
    "        super(IndexIterator, self).__init__(len(self.filenames), batch_size,\n",
    "                                            shuffle, seed)\n",
    "    def _get_batches_of_transformed_samples(self, index_array):\n",
    "        batch_x = np.zeros(\n",
    "            (self.batch_size,) + self.image_shape,\n",
    "            dtype=K.floatx())\n",
    "        batch_y = np.zeros(\n",
    "            (self.batch_size,) + self.label_shape,\n",
    "            dtype=np.int8)\n",
    "\n",
    "        for i, j in enumerate(index_array):\n",
    "            fn = self.filenames[j]\n",
    "            x = self.image_set_loader.load_img(fn)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "            y = self.image_set_loader.load_seg(fn)\n",
    "            y = to_categorical(y, self.classes).reshape(self.label_shape)\n",
    "            # y = np.reshape(y, (-1, self.classes))\n",
    "            batch_y[i] = y\n",
    "        return batch_x, batch_y\n",
    "        \n",
    "    def next(self):\n",
    "        \"\"\"Next batch.\"\"\"\n",
    "        with self.lock:\n",
    "            index_array= next(\n",
    "                self.index_generator)\n",
    "            print(index_array)\n",
    "        batch_x = np.zeros(\n",
    "            (self.batch_size,) + self.image_shape,\n",
    "            dtype=K.floatx())\n",
    "        batch_y = np.zeros(\n",
    "            (self.batch_size,) + self.label_shape,\n",
    "            dtype=np.int8)\n",
    "        #batch_y = np.reshape(batch_y, (current_batch_size, -1, self.classes))\n",
    "        \n",
    "        for i, j in enumerate(index_array):\n",
    "            fn = self.filenames[j]\n",
    "            x = self.image_set_loader.load_img(fn)\n",
    "            x = self.image_data_generator.standardize(x)\n",
    "            batch_x[i] = x\n",
    "            y = self.image_set_loader.load_seg(fn)\n",
    "            y = to_categorical(y, self.classes).reshape(self.label_shape)\n",
    "            #y = np.reshape(y, (-1, self.classes))\n",
    "            batch_y[i] = y\n",
    "\n",
    "        # save augmented images to disk for debugging\n",
    "        #if self.image_set_loader.save_to_dir:\n",
    "        #    for i in range(current_batch_size):\n",
    "        #        x = batch_x[i]\n",
    "        #        y = batch_y[i].argmax(\n",
    "        #            self.image_data_generator.channel_axis - 1)\n",
    "        #        if self.image_data_generator.data_format == 'channels_first':\n",
    "        #            y = y[np.newaxis, ...]\n",
    "        #        else:\n",
    "        #            y = y[..., np.newaxis]\n",
    "        #        self.image_set_loader.save(x, y, current_index + i)\n",
    "        #utils.showSingleImage(batch_y[0,:,:,0])\n",
    "        #print(batch_y.shape)\n",
    "        return batch_x, batch_y\n",
    "\n",
    "\n",
    "class ImageSetLoader(object):\n",
    "    \"\"\"Helper class to load image data into numpy arrays.\"\"\"\n",
    "\n",
    "    def __init__(self, image_set, image_dir, label_dir, target_size=(500, 500),\n",
    "                 image_format='jpg', color_mode='rgb', label_format='png',\n",
    "                 data_format=None,\n",
    "                 save_to_dir=None, save_prefix='', save_format='jpg'):\n",
    "        \"\"\"Init.\"\"\"\n",
    "        if data_format is None:\n",
    "            data_format = K.image_data_format()\n",
    "        self.data_format = data_format\n",
    "        self.target_size = tuple(target_size)\n",
    "\n",
    "        if not os.path.exists(image_set):\n",
    "            raise IOError('Image set {} does not exist. Please provide a'\n",
    "                          'valid file.'.format(image_set))\n",
    "        self.filenames = np.loadtxt(image_set, dtype=bytes)\n",
    "        try:\n",
    "            self.filenames = [fn.decode('utf-8') for fn in self.filenames]\n",
    "        except AttributeError as e:\n",
    "            print(str(e), self.filenames[:5])\n",
    "        if not os.path.exists(image_dir):\n",
    "            raise IOError('Directory {} does not exist. Please provide a '\n",
    "                          'valid directory.'.format(image_dir))\n",
    "        self.image_dir = image_dir\n",
    "        if label_dir and not os.path.exists(label_dir):\n",
    "            raise IOError('Directory {} does not exist. Please provide a '\n",
    "                          'valid directory.'.format(label_dir))\n",
    "        self.label_dir = label_dir\n",
    "\n",
    "        white_list_formats = {'png', 'jpg', 'jpeg', 'bmp'}\n",
    "        self.image_format = image_format\n",
    "        if self.image_format not in white_list_formats:\n",
    "            raise ValueError('Invalid image format:', image_format,\n",
    "                             '; expected \"png\", \"jpg\", \"jpeg\" or \"bmp\"')\n",
    "        self.label_format = label_format\n",
    "        if self.label_format not in white_list_formats:\n",
    "            raise ValueError('Invalid image format:', label_format,\n",
    "                             '; expected \"png\", \"jpg\", \"jpeg\" or \"bmp\"')\n",
    "\n",
    "        if color_mode not in {'rgb', 'grayscale'}:\n",
    "            raise ValueError('Invalid color mode:', color_mode,\n",
    "                             '; expected \"rgb\" or \"grayscale\".')\n",
    "        self.color_mode = color_mode\n",
    "        if self.color_mode == 'rgb':\n",
    "            if self.data_format == 'channels_last':\n",
    "                self.image_shape = self.target_size + (3,)\n",
    "            else:\n",
    "                self.image_shape = (3,) + self.target_size\n",
    "        else:\n",
    "            if self.data_format == 'channels_last':\n",
    "                self.image_shape = self.target_size + (1,)\n",
    "            else:\n",
    "                self.image_shape = (1,) + self.target_size\n",
    "\n",
    "        self.grayscale = self.color_mode == 'grayscale'\n",
    "\n",
    "        self.save_to_dir = save_to_dir\n",
    "        self.save_prefix = save_prefix\n",
    "        self.save_format = save_format\n",
    "\n",
    "    def load_img(self, fn):\n",
    "        \"\"\"Image load method.\n",
    "        # Arguments\n",
    "            fn: filename of the image (without extension suffix)\n",
    "        # Returns\n",
    "            arr: numpy array of shape self.image_shape\n",
    "        \"\"\"\n",
    "        img_path = os.path.join(self.image_dir,\n",
    "                                '{}.{}'.format(fn,\n",
    "                                               self.image_format))\n",
    "        if not os.path.exists(img_path):\n",
    "            raise IOError('Image {} does not exist.'.format(img_path))\n",
    "        #print(img_path)\n",
    "        color_mode = \"rgb\"\n",
    "        if self.grayscale:\n",
    "            color_mode = \"grayscale\"\n",
    "        img = load_img(img_path, self.grayscale, color_mode, self.target_size)\n",
    "        x = img_to_array(img, data_format=self.data_format)\n",
    "        #print(x.shape)\n",
    "        return x\n",
    "\n",
    "    def load_seg(self, fn):\n",
    "        \"\"\"Segmentation load method.\n",
    "        # Arguments\n",
    "            fn: filename of the image (without extension suffix)\n",
    "        # Returns\n",
    "            arr: numpy array of shape self.target_size\n",
    "        \"\"\"\n",
    "        label_path = os.path.join(self.label_dir,\n",
    "                                  '{}.{}'.format(fn, self.label_format))\n",
    "        img = pil_image.open(label_path)\n",
    "        if self.target_size:\n",
    "            wh_tuple = (self.target_size[1], self.target_size[0])\n",
    "        if img.size != wh_tuple:\n",
    "            img = img.resize(wh_tuple)\n",
    "        y = img_to_array(img, self.data_format)\n",
    "        y[y == 255] = 0\n",
    "        \n",
    "        #print(\"y: \", y.shape)\n",
    "        return y\n",
    "\n",
    "    def save(self, x, y, index):\n",
    "        \"\"\"Image save method.\"\"\"\n",
    "        img = array_to_img(x, self.data_format, scale=True)\n",
    "        mask = array_to_img(y, self.data_format, scale=True)\n",
    "        img.paste(mask, (0, 0), mask)\n",
    "\n",
    "        fname = 'img_{prefix}_{index}_{hash}.{format}'.format(\n",
    "            prefix=self.save_prefix,\n",
    "            index=index,\n",
    "            hash=np.random.randint(1e4),\n",
    "            format=self.save_format)\n",
    "        img.save(os.path.join(self.save_to_dir, fname))\n",
    "\n",
    "import yaml\n",
    "import keras\n",
    "with open(\"init_args.yml\", 'r') as stream:\n",
    "    try:\n",
    "        init_args = yaml.load(stream)\n",
    "    except yaml.YAMLError as exc:\n",
    "        print(exc)\n",
    "        \n",
    "datagen = PascalVocGenerator(image_shape=[224, 224, 3],\n",
    "                                    image_resample=True,\n",
    "                                    pixelwise_center=True,\n",
    "                                    pixel_mean=[115.85100, 110.50989, 102.16182],\n",
    "                                    pixelwise_std_normalization=True,\n",
    "                                    pixel_std=[70.30930, 69.41244, 72.60676])\n",
    "\n",
    "train_loader = ImageSetLoader(**init_args['image_set_loader']['train'])\n",
    "val_loader = ImageSetLoader(**init_args['image_set_loader']['val'])\n",
    "\n",
    "val_gen = datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=5,\n",
    "        shuffle=False,\n",
    "        image_set_loader=val_loader)\n",
    "count = 0\n",
    "for batch in val_gen:\n",
    "    print(batch[0].shape, batch[1].shape)\n",
    "    mask = batch[1][0,:,:,0]\n",
    "    utils.showSingleImage(batch[1][0,:,:,0])\n",
    "    print(mask)\n",
    "    print(mask[112][112])\n",
    "    count+=1\n",
    "    if count >= 1:\n",
    "        break\n",
    "'''\n",
    "optimizer = keras.optimizers.Adam(1e-4)\n",
    "model = create_fcn32((224,224,3))\n",
    "#model.summary()\n",
    "model.compile(optimizer=optimizer, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "model.fit_generator(\n",
    "    datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=5,\n",
    "        shuffle=True,\n",
    "        image_set_loader=train_loader),\n",
    "    steps_per_epoch=500,\n",
    "    epochs=10,\n",
    "    validation_data=datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=5,\n",
    "        shuffle=True,\n",
    "        image_set_loader=val_loader),\n",
    "    validation_steps=100,\n",
    "    verbose=1,\n",
    "    use_multiprocessing=False)\n",
    "\n",
    "#print(train_loader.filenames)\n",
    "'''\n",
    "\n",
    "'''\n",
    "    validation_data=datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=5,\n",
    "        shuffle=True,\n",
    "        image_set_loader=val_loader),\n",
    "    validation_steps=100,\n",
    "\n",
    "fcn_vgg16 = FCN(input_shape=(224, 224, 3), classes=21, weight_decay=3e-3,\n",
    "                weights='imagenet', trainable_encoder=True)\n",
    "fcn_vgg16.compile(optimizer=optimizer,\n",
    "                  loss='categorical_crossentropy',\n",
    "                  metrics=['accuracy'])\n",
    "\n",
    "fcn_vgg16.fit_generator(\n",
    "    datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        image_set_loader=train_loader),\n",
    "    steps_per_epoch=1112,\n",
    "    epochs=100,\n",
    "    validation_data=datagen.flow_from_imageset(\n",
    "        class_mode='categorical',\n",
    "        classes=21,\n",
    "        batch_size=1,\n",
    "        shuffle=True,\n",
    "        image_set_loader=val_loader),\n",
    "    validation_steps=1111,\n",
    "    verbose=1,\n",
    "    callbacks=[lr_reducer, early_stopper, csv_logger, checkpointer, nan_terminator])\n",
    "'''\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
