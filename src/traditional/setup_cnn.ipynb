{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/super-workstation/.local/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.14.0\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "#load data\n",
    "print(tf.__version__)\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(\"/home/super-workstation/program/LearnDeepLearning/data/mnist.npz\")\n",
    "x_train, x_test = x_train/255.0, x_test/255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "(60000, 28, 28)\n"
     ]
    }
   ],
   "source": [
    "print(type(x_train))\n",
    "print(x_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n",
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0814 10:27:20.645387 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0814 10:27:20.663993 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0814 10:27:20.672426 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0814 10:27:20.682118 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:133: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
      "\n",
      "W0814 10:27:20.686713 139894501590848 deprecation.py:506] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "W0814 10:27:20.709579 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0814 10:27:20.719970 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3341: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 784)\n",
      "(None, 1024)\n",
      "(None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten_1 (Flatten)          (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1024)              803840    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 1024)              0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 10)                10250     \n",
      "=================================================================\n",
      "Total params: 814,090\n",
      "Trainable params: 814,090\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# setup shallow network 一个隐藏层\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Flatten, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=(28,28))) # 展开\n",
    "print(model.output_shape)\n",
    "model.add(Dense(1024, activation='relu')) # 全连接(隐藏层1)\n",
    "print(model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(10, activation='softmax')) # 输出\n",
    "print(model.output_shape)\n",
    "\n",
    "sgd=SGD(lr=0.01, momentum=0.9, decay=1e-6, nesterov=True)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='sgd', metrics=[\"accuracy\"]) # 编译\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.trainAndEvaluateData(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\npredicts = model.predict(x_test)\\n\\nplt.figure(figsize=(10,10))\\nfor i in range(49):\\n    plt.subplot(7,7,i+1)\\n    plt.xticks([])\\n    plt.yticks([])\\n    plt.grid(False)\\n    #plt.imshow(x_test[i])#, cmap=plt.cm.binary)\\n    pred = predicts[i].tolist()\\n    pred_num = pred.index(max(pred))\\n    plt.xlabel(pred_num)\\n    plt.ylabel(y_test[i])\\n    if pred_num != y_test[i]:\\n        plt.imshow(x_test[i], cmap=plt.cm.binary)\\nplt.show()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "predicts = model.predict(x_test)\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "for i in range(49):\n",
    "    plt.subplot(7,7,i+1)\n",
    "    plt.xticks([])\n",
    "    plt.yticks([])\n",
    "    plt.grid(False)\n",
    "    #plt.imshow(x_test[i])#, cmap=plt.cm.binary)\n",
    "    pred = predicts[i].tolist()\n",
    "    pred_num = pred.index(max(pred))\n",
    "    plt.xlabel(pred_num)\n",
    "    plt.ylabel(y_test[i])\n",
    "    if pred_num != y_test[i]:\n",
    "        plt.imshow(x_test[i], cmap=plt.cm.binary)\n",
    "plt.show()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 10:27:54.838543 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3980: The name tf.nn.avg_pool is deprecated. Please use tf.nn.avg_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv2d_1-->  (None, 28, 28, 6)\n",
      "avg_pooling_1-->  (None, 14, 14, 6)\n",
      "conv2d_2-->  (None, 10, 10, 16)\n",
      "avg_pooling_2-->  (None, 5, 5, 16)\n",
      "flatten -->  (None, 400)\n",
      "full_1 -->  (None, 120)\n",
      "full_2 -->  (None, 84)\n",
      "output -->  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_1 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_1 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 10, 10, 16)        0         \n",
      "_________________________________________________________________\n",
      "average_pooling2d_2 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "flatten_2 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 120)               48120     \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "dense_5 (Dense)              (None, 10)                850       \n",
      "=================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# (!!!error)setup letnet-5 (7 layers)\n",
    "# alias avg_pooling == ap\n",
    "# conv1 + ap_1(5*5) + cov2 + ap_2(5*5) + full_1 + full_2 + output\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, AveragePooling2D, Dropout\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(6, (5,5), padding='same', input_shape=(28,28,1))) #1\n",
    "print(\"conv2d_1--> \", model.output_shape)\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#2\n",
    "print(\"avg_pooling_1--> \", model.output_shape)\n",
    "model.add(Conv2D(16, (5,5)))#3\n",
    "print(\"conv2d_2--> \", model.output_shape)\n",
    "model.add(Dropout(0.375))\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#4\n",
    "print(\"avg_pooling_2--> \", model.output_shape)\n",
    "model.add(Flatten())\n",
    "print(\"flatten --> \", model.output_shape)\n",
    "model.add(Dense(120))#5\n",
    "print(\"full_1 --> \", model.output_shape)\n",
    "model.add(Dense(84))#6\n",
    "print(\"full_2 --> \", model.output_shape)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print('output --> ', model.output_shape)#7\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "utils.trainAndEvaluateData(model, x_train, y_train, x_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "padding-->  (None, 32, 32, 1)\n",
      "conv2d_1-->  (None, 28, 28, 6)\n",
      "avg_pooling_1-->  (None, 14, 14, 6)\n",
      "conv2d_2-->  (None, 10, 10, 16)\n",
      "avg_pooling_2-->  (None, 5, 5, 16)\n",
      "conv2d_3 -->  (None, 1, 1, 120)\n",
      "full_1 -->  (None, 84)\n",
      "output -->  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "zero_padding2d_1 (ZeroPaddin (None, 32, 32, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 28, 28, 6)         156       \n",
      "_________________________________________________________________\n",
      "average_pooling2d_3 (Average (None, 14, 14, 6)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 10, 10, 16)        2416      \n",
      "_________________________________________________________________\n",
      "average_pooling2d_4 (Average (None, 5, 5, 16)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 1, 1, 120)         48120     \n",
      "_________________________________________________________________\n",
      "flatten_3 (Flatten)          (None, 120)               0         \n",
      "_________________________________________________________________\n",
      "dense_6 (Dense)              (None, 84)                10164     \n",
      "_________________________________________________________________\n",
      "rbf_layer_1 (RBFLayer)       (None, 10)                840       \n",
      "=================================================================\n",
      "Total params: 61,696\n",
      "Trainable params: 61,696\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "######## Lenet5 1998 #########\n",
    "# (correction)setup lenet-5 (7 layers) 原始版本\n",
    "# alias avg_pooling == ap\n",
    "# conv1 + ap_1(5*5) + cov2 + ap_2(5*5) + conv_3 + full_1 + output\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten, AveragePooling2D, Dropout, ZeroPadding2D\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "from keras.layers import Layer\n",
    "from keras import backend as K\n",
    "\n",
    "class RBFLayer(Layer):\n",
    "    def __init__(self, units, gamma, **kwargs):\n",
    "        super(RBFLayer, self).__init__(**kwargs)\n",
    "        self.units = units\n",
    "        self.gamma = K.cast_to_floatx(gamma)\n",
    "\n",
    "    def build(self, input_shape):\n",
    "        self.mu = self.add_weight(name='mu',\n",
    "                                  shape=(int(input_shape[1]), self.units),\n",
    "                                  initializer='uniform',\n",
    "                                  trainable=True)\n",
    "        super(RBFLayer, self).build(input_shape)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        diff = K.expand_dims(inputs) - self.mu\n",
    "        l2 = K.sum(K.pow(diff,2), axis=1) # 高斯径向基函数\n",
    "        res = K.exp(-1 * self.gamma * l2) # \n",
    "        return res\n",
    "\n",
    "    def compute_output_shape(self, input_shape):\n",
    "        return (input_shape[0], self.units)\n",
    "\n",
    "model = Sequential()\n",
    "model.add(ZeroPadding2D(2, input_shape=(28,28,1)))\n",
    "print(\"padding--> \", model.output_shape) \n",
    "#1 28×28×6\n",
    "# 训练参数计算规则 （cx_size*cy_size*上一层维度（特征图个数）+1）*当前层维度\n",
    "# 连接数 当前层和上一层的连接数  训练参数个数*特征图w*特征图h\n",
    "# 训练参数 156 = （5×5+1）×6 \n",
    "# 连接数 122304 = （5×5+1）×6×（28×28）\n",
    "model.add(Conv2D(6, (5,5)))#1 \n",
    "print(\"conv2d_1--> \", model.output_shape) \n",
    "#2 14×14×6 \n",
    "#训练参数 12 6*(1+1) 当前层数（偏置+采样参数）\n",
    "#连接数 5880 = （2×2 + 1）*6*(14*14)\n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#2\n",
    "print(\"avg_pooling_1--> \", model.output_shape)\n",
    "#3 10×10×16 \n",
    "#训练参数 1516 = (3*5*5+ 1)*6 + (4*5*5+1)*6 + (4*5*5+1)*3 + (6*5*5+1)\n",
    "#连接数 151600 = (3*5*5+ 1)*6×（10×10） + (4*5*5+1)*6×（10×10） + (4*5*5+1)*3*(10*10) + (6*5*5+1)*(10*10)\n",
    "model.add(Conv2D(16, (5,5)))#3\n",
    "print(\"conv2d_2--> \", model.output_shape)\n",
    "#4 5*5*16\n",
    "#训练参数 32 = 16*(1+1)\n",
    "#连接个数 2000 = （2*2*1 + 1）*6*(5*5) \n",
    "model.add(AveragePooling2D(pool_size=(2,2)))#4\n",
    "print(\"avg_pooling_2--> \", model.output_shape)\n",
    "#5 1*1*120\n",
    "#训练参数 48120 = (5*5*16 + 1)*120\n",
    "#连接个数 48120 = (5*5*16 + 1)*120*(1*1)\n",
    "model.add(Conv2D(120, (5,5)))#5\n",
    "print(\"conv2d_3 --> \", model.output_shape)\n",
    "model.add(Flatten())\n",
    "#6 1*1*84\n",
    "#训练参数 10164 = (1*1*120+1)*84\n",
    "#连接个数 10164 = (1*1*120+1)*84*(1*1)\n",
    "model.add(Dense(84, activation='tanh'))#6\n",
    "print(\"full_1 --> \", model.output_shape)\n",
    "#7 1*1*10\n",
    "#训练参数 850 = （1*1*84+1)*10(1*1)\n",
    "#连接个数 850 = （1*1*84+1)*10(1*1)\n",
    "#model.add(Dense(10, activation='sigmoid'))#7\n",
    "model.add(RBFLayer(10,0.5))\n",
    "print('output --> ', model.output_shape)\n",
    "\n",
    "# compile\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "train_data = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)\n",
    "test_data = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)\n",
    "train_label = y_train\n",
    "test_label = y_test\n",
    "\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 227, 227, 3)   (20000,)   (2000, 227, 227, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## Alexnet 2012 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 227\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "# 首次处理数据 将mnist数据集转换成需要形式（227×227×3）\n",
    "# x_train, y_train x_test y_test mnist 原始数据集\n",
    "'''\n",
    "import tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(\"/home/super-workstation/program/LearnDeepLearning/data/mnist.npz\")\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "'''\n",
    "\n",
    "alex_train_label = y_train[:train_nums]\n",
    "alex_test_label = y_test[:test_nums]\n",
    "\n",
    "alex_train_data = utils.preprocess4Alexnet(x_train, train_nums, dsize=(dims, dims))\n",
    "alex_test_data = utils.preprocess4Alexnet(x_test, test_nums, dsize=(dims, dims))\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "data_io.save_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\", \n",
    "                 alex_train_data, alex_train_label,\n",
    "                 alex_test_data, alex_test_label)\n",
    "\n",
    "\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1（input）:  (None, 55, 55, 96)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0814 10:28:31.612388 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:1834: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "W0814 10:28:31.649690 139894501590848 deprecation_wrapper.py:119] From /home/super-workstation/.local/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3976: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max_pool_1:  (None, 27, 27, 96)\n",
      "conv_2:  (None, 27, 27, 256)\n",
      "max_pool_2:  (None, 13, 13, 256)\n",
      "conv_3:  (None, 13, 13, 384)\n",
      "conv_4:  (None, 13, 13, 384)\n",
      "conv_5:  (None, 13, 13, 256)\n",
      "max_pool_3 (None, 6, 6, 256)\n",
      "full_1:  (None, 1, 1, 4096)\n",
      "flatten:  (None, 4096)\n",
      "full_2:  (None, 4096)\n",
      "full_3(output):  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_6 (Conv2D)            (None, 55, 55, 96)        34944     \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 55, 55, 96)        384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 27, 27, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 27, 27, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 1, 1, 4096)        37752832  \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "flatten_4 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_7 (Dense)              (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_5 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_9 (Dense)              (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 62,389,762\n",
      "Trainable params: 62,389,058\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########## Alexnet 2012 ###################\n",
    "# 8 layers 5 conv + 3 maxpool + 2 full + 1 output\n",
    "# 1-2 layers: conv(11*11, 5*5) + relu + normal + maxpool\n",
    "# 3-4 layers: conv(3*3, 3*3) + relu\n",
    "# 5 layers: conv + relu + maxpool\n",
    "# 6 layers: full(4096) + relu\n",
    "# 7 layers: full(4096)\n",
    "# 8 layers: full(1000 output)\n",
    "# 9 layers: full(10) 为mnist数据额外添加（因为mnist手写数据有10个类别）\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# 1 \n",
    "# conv1\n",
    "# output dim = (227-11)/4 + 1 = 55 --> 55*55*96\n",
    "model.add(Conv2D(96, (11,11), strides=4, activation='relu', input_shape=(227, 227, 3)))\n",
    "print(\"conv_1（input）: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_1 27*27*96\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_1: \", model.output_shape)\n",
    "# 2\n",
    "# conv2 27*27*256\n",
    "model.add(Conv2D(256, (5,5), padding='same', activation='relu'))\n",
    "print(\"conv_2: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_2 13*13*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_2: \", model.output_shape)\n",
    "# 3\n",
    "# conv3 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_3: \", model.output_shape)\n",
    "# 4\n",
    "# conv4 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_4: \", model.output_shape)\n",
    "# 5\n",
    "# conv5 13*13*256\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_5: \", model.output_shape)\n",
    "# max_pool_3 6*6*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_3\", model.output_shape)\n",
    "\n",
    "# 6\n",
    "# full_1\n",
    "model.add(Conv2D(4096, (6,6), activation='relu'))\n",
    "print(\"full_1: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "print(\"flatten: \", model.output_shape)\n",
    "# 7\n",
    "# full_2\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "print(\"full_2: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "# 8\n",
    "# full_3\n",
    "#model.add(Dense(1000, activation='softmax'))\n",
    "# change for apply mnist\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))                \n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "print(\"full_3(output): \", model.output_shape)\n",
    "\n",
    "# !使用adam 会导致结果不收敛\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 1s 1ms/step\n",
      "loss:  0.025560790936113336\n",
      "cost:  0.989\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "import cv2\n",
    "image_size = 227\n",
    "train_image = [cv2.cvtColor(cv2.resize(img,(image_size,image_size)),cv2.COLOR_GRAY2BGR) for img in x_train.astype('float32')]\n",
    "#test_image = [cv2.cvtColor(cv2.resize(img,(image_size,image_size)),cv2.COLOR_GRAY2BGR) for img in x_test]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1（input）:  (None, 111, 111, 96)\n",
      "max_pool_1:  (None, 55, 55, 96)\n",
      "conv_2:  (None, 28, 28, 256)\n",
      "max_pool_2:  (None, 13, 13, 256)\n",
      "conv_3:  (None, 13, 13, 384)\n",
      "conv_4:  (None, 13, 13, 384)\n",
      "conv_5:  (None, 13, 13, 256)\n",
      "max_pool_3 (None, 6, 6, 256)\n",
      "full_1:  (None, 1, 1, 4096)\n",
      "flatten:  (None, 4096)\n",
      "full_2:  (None, 4096)\n",
      "full_3(output):  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_12 (Conv2D)           (None, 111, 111, 96)      14208     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 111, 111, 96)      384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2 (None, 55, 55, 96)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 28, 28, 256)       614656    \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 28, 28, 256)       1024      \n",
      "_________________________________________________________________\n",
      "max_pooling2d_5 (MaxPooling2 (None, 13, 13, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 13, 13, 384)       885120    \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 13, 13, 384)       1327488   \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 13, 13, 256)       884992    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_6 (MaxPooling2 (None, 6, 6, 256)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 1, 1, 4096)        37752832  \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 1, 1, 4096)        0         \n",
      "_________________________________________________________________\n",
      "flatten_5 (Flatten)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_10 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_7 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_11 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_12 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 62,369,026\n",
      "Trainable params: 62,368,322\n",
      "Non-trainable params: 704\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "########## ZFnet 2013 ###################\n",
    "# 8 layers 5 conv + 3 maxpool + 2 full + 1 output\n",
    "# 1-2 layers: conv(7*7, 5*5) + relu + normal + maxpool\n",
    "# 3-4 layers: conv(3*3, 3*3) + relu\n",
    "# 5 layers: conv + relu + maxpool\n",
    "# 6 layers: full(4096) + relu\n",
    "# 7 layers: full(4096)\n",
    "# 8 layers: full(1000 output)\n",
    "# 9 layers: full(10) 为mnist数据额外添加（因为mnist手写数据有10个类别）\n",
    "# zfnet 和 alexnet 区别在于 1，2层:\n",
    "# alexnet 1 layer: conv 11*11*96 strides=4, 227*227*3 -> 55*55*96 + maxpool 55*55*96 -> 27*27*96\n",
    "#         2 layer: conv 5*5*256 strides=1, 27*27*96 -> 27*27*256 + maxpool 27*27*256 -> 13*13*256\n",
    "# zfnet   1 layer: conv 7*7*96 strides=2 227*227*3 -> 111*111*96 + maxpool 111*111*96 -> 55*55*96\n",
    "#         2 layer: conv 5*5*256 strides=2 padding=same 55*55*96 -> 27*27*256 + maxpool --> 13*13*256\n",
    "import keras\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Dropout, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "model = Sequential()\n",
    "# 1 \n",
    "# conv1\n",
    "# output dim = (227-7)/2 + 1 = 111 --> 111*111*96\n",
    "model.add(Conv2D(96, (7,7), strides=2, activation='relu', input_shape=(227, 227, 3)))\n",
    "print(\"conv_1（input）: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_1 55*55*96\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_1: \", model.output_shape)\n",
    "\n",
    "# 2\n",
    "# conv2 26*26*256\n",
    "model.add(Conv2D(256, (5,5), strides=2, padding = 'same', activation='relu'))\n",
    "print(\"conv_2: \", model.output_shape)\n",
    "# normalize layers\n",
    "model.add(BatchNormalization())\n",
    "# max_pool_2 13*13*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_2: \", model.output_shape)\n",
    "\n",
    "# 3\n",
    "# conv3 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_3: \", model.output_shape)\n",
    "# 4\n",
    "# conv4 13*13*384\n",
    "model.add(Conv2D(384, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_4: \", model.output_shape)\n",
    "# 5\n",
    "# conv5 13*13*256\n",
    "model.add(Conv2D(256, (3,3), padding='same', activation='relu'))\n",
    "print(\"conv_5: \", model.output_shape)\n",
    "# max_pool_3 6*6*256\n",
    "model.add(MaxPool2D(pool_size=(3,3), strides=2))\n",
    "print(\"max_pool_3\", model.output_shape)\n",
    "\n",
    "# 6\n",
    "# full_1\n",
    "model.add(Conv2D(4096, (6,6), activation='relu'))\n",
    "print(\"full_1: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Flatten())\n",
    "print(\"flatten: \", model.output_shape)\n",
    "# 7\n",
    "# full_2\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "print(\"full_2: \", model.output_shape)\n",
    "model.add(Dropout(0.5))\n",
    "# 8\n",
    "# full_3\n",
    "#model.add(Dense(1000, activation='softmax'))\n",
    "# change for apply mnist\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))                \n",
    "model.add(Dense(10, activation='softmax'))  \n",
    "print(\"full_3(output): \", model.output_shape)\n",
    "\n",
    "# !使用adam 会导致结果不收敛\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train model\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 224, 224, 3)   (20000,)   (2000, 224, 224, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## vggxnet 2014 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 224\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "# 首次处理数据 将mnist数据集转换成需要形式（227×227×3）\n",
    "# x_train, y_train x_test y_test mnist 原始数据集\n",
    "'''\n",
    "import tf\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data(\"/home/super-workstation/program/LearnDeepLearning/data/mnist.npz\")\n",
    "x_train, x_test = x_train/255.0, x_test/255.0\n",
    "'''\n",
    "\n",
    "alex_train_label = y_train[:train_nums]\n",
    "alex_test_label = y_test[:test_nums]\n",
    "\n",
    "alex_train_data = utils.preprocess4Alexnet(x_train, train_nums, dsize=(dims, dims))\n",
    "alex_test_data = utils.preprocess4Alexnet(x_test, test_nums, dsize=(dims, dims))\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "data_io.save_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\", \n",
    "                 alex_train_data, alex_train_label,\n",
    "                 alex_test_data, alex_test_label)\n",
    "\n",
    "\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "conv_1:  (None, 224, 224, 64)\n",
      "conv_2:  (None, 224, 224, 64)\n",
      "max_pool_1:  (None, 112, 112, 64)\n",
      "conv_3:  (None, 112, 112, 128)\n",
      "conv_4:  (None, 112, 112, 128)\n",
      "max_pool_2:  (None, 56, 56, 128)\n",
      "conv_5:  (None, 56, 56, 256)\n",
      "conv_6:  (None, 56, 56, 256)\n",
      "conv_7:  (None, 56, 56, 256)\n",
      "max_pool_3:  (None, 28, 28, 256)\n",
      "conv_8:  (None, 28, 28, 512)\n",
      "conv_9:  (None, 28, 28, 512)\n",
      "conv_10:  (None, 28, 28, 512)\n",
      "max_pool_4:  (None, 14, 14, 512)\n",
      "conv_11:  (None, 14, 14, 512)\n",
      "conv_12:  (None, 14, 14, 512)\n",
      "conv_13:  (None, 14, 14, 512)\n",
      "max_pool_5:  (None, 7, 7, 512)\n",
      "full_1:  (None, 4096)\n",
      "full_2:  (None, 4096)\n",
      "full_3:  (None, 1000)\n",
      "output:  (None, 10)\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_18 (Conv2D)           (None, 224, 224, 64)      1792      \n",
      "_________________________________________________________________\n",
      "conv2d_19 (Conv2D)           (None, 224, 224, 64)      36928     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_7 (MaxPooling2 (None, 112, 112, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_20 (Conv2D)           (None, 112, 112, 128)     73856     \n",
      "_________________________________________________________________\n",
      "conv2d_21 (Conv2D)           (None, 112, 112, 128)     147584    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_8 (MaxPooling2 (None, 56, 56, 128)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_22 (Conv2D)           (None, 56, 56, 256)       295168    \n",
      "_________________________________________________________________\n",
      "conv2d_23 (Conv2D)           (None, 56, 56, 256)       590080    \n",
      "_________________________________________________________________\n",
      "conv2d_24 (Conv2D)           (None, 56, 56, 256)       65792     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2 (None, 28, 28, 256)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_25 (Conv2D)           (None, 28, 28, 512)       1180160   \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 28, 28, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 28, 28, 512)       262656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling (None, 14, 14, 512)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 14, 14, 512)       2359808   \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 14, 14, 512)       262656    \n",
      "_________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling (None, 7, 7, 512)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 25088)             0         \n",
      "_________________________________________________________________\n",
      "dense_13 (Dense)             (None, 4096)              102764544 \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 4096)              16781312  \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 4096)              0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 1000)              4097000   \n",
      "_________________________________________________________________\n",
      "dropout_11 (Dropout)         (None, 1000)              0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 10)                10010     \n",
      "=================================================================\n",
      "Total params: 133,648,962\n",
      "Trainable params: 133,648,962\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# vgg 16\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Dense, MaxPool2D, BatchNormalization, Dropout, Flatten\n",
    "\n",
    "model = Sequential()\n",
    "# 64\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same', input_shape=(224,224,3)))\n",
    "print(\"conv_1: \", model.output_shape)\n",
    "model.add(Conv2D(64, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_2: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_1: \", model.output_shape)\n",
    "\n",
    "#128\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_3: \", model.output_shape)\n",
    "model.add(Conv2D(128, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_4: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_2: \", model.output_shape)\n",
    "\n",
    "#256\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_5: \", model.output_shape)\n",
    "model.add(Conv2D(256, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_6: \", model.output_shape)\n",
    "model.add(Conv2D(256, (1,1), activation='relu', padding='same'))\n",
    "print(\"conv_7: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_3: \", model.output_shape)\n",
    "\n",
    "#512\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_8: \", model.output_shape)\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_9: \", model.output_shape)\n",
    "model.add(Conv2D(512, (1,1), activation='relu', padding='same'))\n",
    "print(\"conv_10: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_4: \", model.output_shape)\n",
    "\n",
    "#512\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_11: \", model.output_shape)\n",
    "model.add(Conv2D(512, (3,3), activation='relu', padding='same'))\n",
    "print(\"conv_12: \", model.output_shape)\n",
    "model.add(Conv2D(512, (1,1), activation='relu', padding='same'))\n",
    "print(\"conv_13: \", model.output_shape)\n",
    "model.add(MaxPool2D())\n",
    "print(\"max_pool_5: \", model.output_shape)\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "print(\"full_1: \", model.output_shape)\n",
    "model.add(Dense(4096, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "print(\"full_2: \", model.output_shape)\n",
    "model.add(Dense(1000, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "print(\"full_3: \", model.output_shape)\n",
    "model.add(Dense(10, activation='softmax'))\n",
    "print(\"output: \", model.output_shape)\n",
    "\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12\n",
      "20000/20000 [==============================] - 149s 7ms/step - loss: 1.9738 - acc: 0.2918\n",
      "Epoch 2/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.3118 - acc: 0.9038\n",
      "Epoch 3/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.1500 - acc: 0.9541\n",
      "Epoch 4/12\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.1074 - acc: 0.9657\n",
      "Epoch 5/12\n",
      "20000/20000 [==============================] - 138s 7ms/step - loss: 0.0859 - acc: 0.9742\n",
      "Epoch 6/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.0712 - acc: 0.9781\n",
      "Epoch 7/12\n",
      "20000/20000 [==============================] - 141s 7ms/step - loss: 0.0605 - acc: 0.9819\n",
      "Epoch 8/12\n",
      "20000/20000 [==============================] - 140s 7ms/step - loss: 0.0519 - acc: 0.9844\n",
      "Epoch 9/12\n",
      "20000/20000 [==============================] - 141s 7ms/step - loss: 0.0432 - acc: 0.9864\n",
      "Epoch 10/12\n",
      "20000/20000 [==============================] - 142s 7ms/step - loss: 0.0392 - acc: 0.9888\n",
      "Epoch 11/12\n",
      "20000/20000 [==============================] - 139s 7ms/step - loss: 0.0337 - acc: 0.9891\n",
      "Epoch 12/12\n",
      "20000/20000 [==============================] - 141s 7ms/step - loss: 0.0299 - acc: 0.9905\n",
      "2000/2000 [==============================] - 6s 3ms/step\n",
      "loss:  0.03546125781838782\n",
      "acc:  0.988\n"
     ]
    }
   ],
   "source": [
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 224, 224, 3)   (20000,)   (2000, 224, 224, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## googLenet 2014 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 224\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_16 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_661 (Conv2D)             (None, 112, 112, 64) 9472        input_16[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_152 (MaxPooling2D (None, 56, 56, 64)   0           conv2d_661[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_198 (BatchN (None, 56, 56, 64)   256         max_pooling2d_152[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_662 (Conv2D)             (None, 56, 56, 64)   4160        batch_normalization_198[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_663 (Conv2D)             (None, 56, 56, 192)  110784      conv2d_662[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_199 (BatchN (None, 56, 56, 192)  768         conv2d_663[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_153 (MaxPooling2D (None, 28, 28, 192)  0           batch_normalization_199[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_665 (Conv2D)             (None, 28, 28, 96)   18528       max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_667 (Conv2D)             (None, 28, 28, 16)   3088        max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_201 (BatchN (None, 28, 28, 96)   384         conv2d_665[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_203 (BatchN (None, 28, 28, 16)   64          conv2d_667[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 28, 28, 96)   0           batch_normalization_201[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_172 (Activation)     (None, 28, 28, 16)   0           batch_normalization_203[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_154 (MaxPooling2D (None, 28, 28, 192)  0           max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_664 (Conv2D)             (None, 28, 28, 64)   12352       max_pooling2d_153[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_666 (Conv2D)             (None, 28, 28, 128)  110720      activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_668 (Conv2D)             (None, 28, 28, 32)   12832       activation_172[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_669 (Conv2D)             (None, 28, 28, 32)   6176        max_pooling2d_154[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_200 (BatchN (None, 28, 28, 64)   256         conv2d_664[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_202 (BatchN (None, 28, 28, 128)  512         conv2d_666[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_204 (BatchN (None, 28, 28, 32)   128         conv2d_668[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_205 (BatchN (None, 28, 28, 32)   128         conv2d_669[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 28, 28, 64)   0           batch_normalization_200[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 28, 28, 128)  0           batch_normalization_202[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_173 (Activation)     (None, 28, 28, 32)   0           batch_normalization_204[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_174 (Activation)     (None, 28, 28, 32)   0           batch_normalization_205[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_100 (Concatenate)   (None, 28, 28, 256)  0           activation_169[0][0]             \n",
      "                                                                 activation_171[0][0]             \n",
      "                                                                 activation_173[0][0]             \n",
      "                                                                 activation_174[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_671 (Conv2D)             (None, 28, 28, 128)  32896       concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_673 (Conv2D)             (None, 28, 28, 32)   8224        concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_207 (BatchN (None, 28, 28, 128)  512         conv2d_671[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_209 (BatchN (None, 28, 28, 32)   128         conv2d_673[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_176 (Activation)     (None, 28, 28, 128)  0           batch_normalization_207[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_178 (Activation)     (None, 28, 28, 32)   0           batch_normalization_209[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_155 (MaxPooling2D (None, 28, 28, 256)  0           concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_670 (Conv2D)             (None, 28, 28, 128)  32896       concatenate_100[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_672 (Conv2D)             (None, 28, 28, 192)  221376      activation_176[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_674 (Conv2D)             (None, 28, 28, 96)   76896       activation_178[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_675 (Conv2D)             (None, 28, 28, 64)   16448       max_pooling2d_155[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_206 (BatchN (None, 28, 28, 128)  512         conv2d_670[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_208 (BatchN (None, 28, 28, 192)  768         conv2d_672[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 28, 28, 96)   384         conv2d_674[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 28, 28, 64)   256         conv2d_675[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_175 (Activation)     (None, 28, 28, 128)  0           batch_normalization_206[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_177 (Activation)     (None, 28, 28, 192)  0           batch_normalization_208[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_179 (Activation)     (None, 28, 28, 96)   0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_180 (Activation)     (None, 28, 28, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_101 (Concatenate)   (None, 28, 28, 480)  0           activation_175[0][0]             \n",
      "                                                                 activation_177[0][0]             \n",
      "                                                                 activation_179[0][0]             \n",
      "                                                                 activation_180[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_156 (MaxPooling2D (None, 14, 14, 480)  0           concatenate_101[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_677 (Conv2D)             (None, 14, 14, 96)   46176       max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_679 (Conv2D)             (None, 14, 14, 16)   7696        max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 14, 14, 96)   384         conv2d_677[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 14, 14, 16)   64          conv2d_679[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_182 (Activation)     (None, 14, 14, 96)   0           batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_184 (Activation)     (None, 14, 14, 16)   0           batch_normalization_215[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_157 (MaxPooling2D (None, 14, 14, 480)  0           max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_676 (Conv2D)             (None, 14, 14, 192)  92352       max_pooling2d_156[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_678 (Conv2D)             (None, 14, 14, 208)  179920      activation_182[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_680 (Conv2D)             (None, 14, 14, 48)   19248       activation_184[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_681 (Conv2D)             (None, 14, 14, 64)   30784       max_pooling2d_157[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 14, 14, 192)  768         conv2d_676[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 14, 14, 208)  832         conv2d_678[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 14, 14, 48)   192         conv2d_680[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 14, 14, 64)   256         conv2d_681[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_181 (Activation)     (None, 14, 14, 192)  0           batch_normalization_212[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_183 (Activation)     (None, 14, 14, 208)  0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_185 (Activation)     (None, 14, 14, 48)   0           batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_186 (Activation)     (None, 14, 14, 64)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_102 (Concatenate)   (None, 14, 14, 512)  0           activation_181[0][0]             \n",
      "                                                                 activation_183[0][0]             \n",
      "                                                                 activation_185[0][0]             \n",
      "                                                                 activation_186[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_684 (Conv2D)             (None, 14, 14, 112)  57456       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_686 (Conv2D)             (None, 14, 14, 24)   12312       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 14, 14, 112)  448         conv2d_684[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 14, 14, 24)   96          conv2d_686[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_189 (Activation)     (None, 14, 14, 112)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_191 (Activation)     (None, 14, 14, 24)   0           batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_158 (MaxPooling2D (None, 14, 14, 512)  0           concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_683 (Conv2D)             (None, 14, 14, 160)  82080       concatenate_102[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_685 (Conv2D)             (None, 14, 14, 224)  226016      activation_189[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_687 (Conv2D)             (None, 14, 14, 64)   38464       activation_191[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_688 (Conv2D)             (None, 14, 14, 64)   32832       max_pooling2d_158[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 14, 14, 160)  640         conv2d_683[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 14, 14, 224)  896         conv2d_685[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 14, 14, 64)   256         conv2d_687[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 14, 14, 64)   256         conv2d_688[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_188 (Activation)     (None, 14, 14, 160)  0           batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_190 (Activation)     (None, 14, 14, 224)  0           batch_normalization_221[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_192 (Activation)     (None, 14, 14, 64)   0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_193 (Activation)     (None, 14, 14, 64)   0           batch_normalization_224[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_103 (Concatenate)   (None, 14, 14, 512)  0           activation_188[0][0]             \n",
      "                                                                 activation_190[0][0]             \n",
      "                                                                 activation_192[0][0]             \n",
      "                                                                 activation_193[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_690 (Conv2D)             (None, 14, 14, 128)  65664       concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_692 (Conv2D)             (None, 14, 14, 24)   12312       concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 14, 14, 128)  512         conv2d_690[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 14, 14, 24)   96          conv2d_692[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_195 (Activation)     (None, 14, 14, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_197 (Activation)     (None, 14, 14, 24)   0           batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_159 (MaxPooling2D (None, 14, 14, 512)  0           concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_689 (Conv2D)             (None, 14, 14, 128)  65664       concatenate_103[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_691 (Conv2D)             (None, 14, 14, 256)  295168      activation_195[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_693 (Conv2D)             (None, 14, 14, 64)   38464       activation_197[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_694 (Conv2D)             (None, 14, 14, 64)   32832       max_pooling2d_159[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 14, 14, 128)  512         conv2d_689[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 14, 14, 256)  1024        conv2d_691[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 14, 14, 64)   256         conv2d_693[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 14, 14, 64)   256         conv2d_694[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_194 (Activation)     (None, 14, 14, 128)  0           batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_196 (Activation)     (None, 14, 14, 256)  0           batch_normalization_227[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_198 (Activation)     (None, 14, 14, 64)   0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_199 (Activation)     (None, 14, 14, 64)   0           batch_normalization_230[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_104 (Concatenate)   (None, 14, 14, 512)  0           activation_194[0][0]             \n",
      "                                                                 activation_196[0][0]             \n",
      "                                                                 activation_198[0][0]             \n",
      "                                                                 activation_199[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_696 (Conv2D)             (None, 14, 14, 114)  58482       concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_698 (Conv2D)             (None, 14, 14, 32)   16416       concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 14, 14, 114)  456         conv2d_696[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 14, 14, 32)   128         conv2d_698[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_201 (Activation)     (None, 14, 14, 114)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_203 (Activation)     (None, 14, 14, 32)   0           batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_160 (MaxPooling2D (None, 14, 14, 512)  0           concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_695 (Conv2D)             (None, 14, 14, 112)  57456       concatenate_104[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_697 (Conv2D)             (None, 14, 14, 288)  295776      activation_201[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_699 (Conv2D)             (None, 14, 14, 64)   51264       activation_203[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_700 (Conv2D)             (None, 14, 14, 64)   32832       max_pooling2d_160[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 14, 14, 112)  448         conv2d_695[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 14, 14, 288)  1152        conv2d_697[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 14, 14, 64)   256         conv2d_699[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 14, 14, 64)   256         conv2d_700[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_200 (Activation)     (None, 14, 14, 112)  0           batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_202 (Activation)     (None, 14, 14, 288)  0           batch_normalization_233[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_204 (Activation)     (None, 14, 14, 64)   0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_205 (Activation)     (None, 14, 14, 64)   0           batch_normalization_236[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_105 (Concatenate)   (None, 14, 14, 528)  0           activation_200[0][0]             \n",
      "                                                                 activation_202[0][0]             \n",
      "                                                                 activation_204[0][0]             \n",
      "                                                                 activation_205[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_703 (Conv2D)             (None, 14, 14, 160)  84640       concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_705 (Conv2D)             (None, 14, 14, 32)   16928       concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 14, 14, 160)  640         conv2d_703[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 14, 14, 32)   128         conv2d_705[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_208 (Activation)     (None, 14, 14, 160)  0           batch_normalization_239[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_210 (Activation)     (None, 14, 14, 32)   0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_161 (MaxPooling2D (None, 14, 14, 528)  0           concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_702 (Conv2D)             (None, 14, 14, 256)  135424      concatenate_105[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_704 (Conv2D)             (None, 14, 14, 320)  461120      activation_208[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_706 (Conv2D)             (None, 14, 14, 128)  102528      activation_210[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_707 (Conv2D)             (None, 14, 14, 128)  67712       max_pooling2d_161[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 14, 14, 256)  1024        conv2d_702[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 14, 14, 320)  1280        conv2d_704[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 14, 14, 128)  512         conv2d_706[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 14, 14, 128)  512         conv2d_707[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_207 (Activation)     (None, 14, 14, 256)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_209 (Activation)     (None, 14, 14, 320)  0           batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_211 (Activation)     (None, 14, 14, 128)  0           batch_normalization_242[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_212 (Activation)     (None, 14, 14, 128)  0           batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_106 (Concatenate)   (None, 14, 14, 832)  0           activation_207[0][0]             \n",
      "                                                                 activation_209[0][0]             \n",
      "                                                                 activation_211[0][0]             \n",
      "                                                                 activation_212[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_162 (MaxPooling2D (None, 7, 7, 832)    0           concatenate_106[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_709 (Conv2D)             (None, 7, 7, 160)    133280      max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_711 (Conv2D)             (None, 7, 7, 32)     26656       max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 7, 7, 160)    640         conv2d_709[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 7, 7, 32)     128         conv2d_711[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_214 (Activation)     (None, 7, 7, 160)    0           batch_normalization_245[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_216 (Activation)     (None, 7, 7, 32)     0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_163 (MaxPooling2D (None, 7, 7, 832)    0           max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_708 (Conv2D)             (None, 7, 7, 256)    213248      max_pooling2d_162[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_710 (Conv2D)             (None, 7, 7, 320)    461120      activation_214[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_712 (Conv2D)             (None, 7, 7, 128)    102528      activation_216[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_713 (Conv2D)             (None, 7, 7, 128)    106624      max_pooling2d_163[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 7, 7, 256)    1024        conv2d_708[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 7, 7, 320)    1280        conv2d_710[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 7, 7, 128)    512         conv2d_712[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 7, 7, 128)    512         conv2d_713[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_213 (Activation)     (None, 7, 7, 256)    0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_215 (Activation)     (None, 7, 7, 320)    0           batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_217 (Activation)     (None, 7, 7, 128)    0           batch_normalization_248[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_218 (Activation)     (None, 7, 7, 128)    0           batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_107 (Concatenate)   (None, 7, 7, 832)    0           activation_213[0][0]             \n",
      "                                                                 activation_215[0][0]             \n",
      "                                                                 activation_217[0][0]             \n",
      "                                                                 activation_218[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_715 (Conv2D)             (None, 7, 7, 192)    159936      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_717 (Conv2D)             (None, 7, 7, 48)     39984       concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 192)    768         conv2d_715[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 48)     192         conv2d_717[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_220 (Activation)     (None, 7, 7, 192)    0           batch_normalization_251[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_222 (Activation)     (None, 7, 7, 48)     0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_164 (MaxPooling2D (None, 7, 7, 832)    0           concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_714 (Conv2D)             (None, 7, 7, 384)    319872      concatenate_107[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_716 (Conv2D)             (None, 7, 7, 384)    663936      activation_220[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_718 (Conv2D)             (None, 7, 7, 128)    153728      activation_222[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_719 (Conv2D)             (None, 7, 7, 128)    106624      max_pooling2d_164[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 384)    1536        conv2d_714[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 384)    1536        conv2d_716[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 128)    512         conv2d_718[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 128)    512         conv2d_719[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_219 (Activation)     (None, 7, 7, 384)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_221 (Activation)     (None, 7, 7, 384)    0           batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_223 (Activation)     (None, 7, 7, 128)    0           batch_normalization_254[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_224 (Activation)     (None, 7, 7, 128)    0           batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_108 (Concatenate)   (None, 7, 7, 1024)   0           activation_219[0][0]             \n",
      "                                                                 activation_221[0][0]             \n",
      "                                                                 activation_223[0][0]             \n",
      "                                                                 activation_224[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_36 (AveragePo (None, 1, 1, 1024)   0           concatenate_108[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "dropout_62 (Dropout)            (None, 1, 1, 1024)   0           average_pooling2d_36[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_34 (Flatten)            (None, 1024)         0           dropout_62[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_85 (Dense)                (None, 1000)         1025000     flatten_34[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_63 (Dropout)            (None, 1000)         0           dense_85[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_86 (Dense)                (None, 10)           10010       dropout_63[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 6,944,156\n",
      "Trainable params: 6,929,784\n",
      "Non-trainable params: 14,372\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "#google net 2014\n",
    "# 训练时需要副分类器， 预测时无视\n",
    "import keras\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Conv2D, MaxPooling2D, Input, AveragePooling2D, Dense, Flatten\n",
    "from keras.layers import BatchNormalization, Input, Dropout, Activation\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def getMaxPool(input):\n",
    "    return MaxPooling2D(pool_size=(3,3), strides=1, padding='same')(input)\n",
    "\n",
    "# conv strides=1 padding=same\n",
    "# maxpool size(3,3) strides=2 padding='same'\n",
    "# nums --> nums of filter for special size(1x1, 3x3, 5x5, pool)\n",
    "def Inception(input, nums_11, nums_11_33, nums_33, nums_11_55, nums_55, nums_11_pool):\n",
    "    conv_11 = conv2d_bn(input, nums_11, (1,1))\n",
    "    \n",
    "    conv_11_33 = conv2d_bn(input, nums_11_33, (1,1))\n",
    "    conv_33 = conv2d_bn(conv_11_33, nums_33, (3,3))\n",
    "    \n",
    "    conv_11_55 = conv2d_bn(input, nums_11_55, (1,1))\n",
    "    conv_55 = conv2d_bn(conv_11_55, nums_55, (5,5))\n",
    "    \n",
    "    conv_max_pool = getMaxPool(input)\n",
    "    conv_max_pool_11 = conv2d_bn(conv_max_pool, nums_11_pool, (1,1))\n",
    "    \n",
    "    output = keras.layers.concatenate([conv_11, conv_33, conv_55, conv_max_pool_11], axis=-1)\n",
    "    return output\n",
    "\n",
    "def AuxiliaryClassifier(input):\n",
    "    x = AveragePooling2D(pool_size=(5, 5), strides=3)(input)\n",
    "    x = conv2d_bn(x, 128, (1,1))\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1024, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    #output = Dense(1000, activation='softmax')(x)\n",
    "    # add 1 full layer for mnist\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.7)(x)\n",
    "    output = Dense(10, activation = 'softmax')(x)\n",
    "    return output\n",
    "\n",
    "def MainClassifier(input):\n",
    "    x = AveragePooling2D(pool_size=(7, 7), strides=1)(input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    #output = Dense(1000, activation='softmax')(x)\n",
    "    # add 1 full layer for mnist\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    return output\n",
    "    \n",
    "    \n",
    "input = Input(shape=(224, 224, 3))\n",
    "x = Conv2D(64, (7,7), strides=2, padding='same', activation='relu')(input)\n",
    "#x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = BatchNormalization()(x)\n",
    "\n",
    "x = Conv2D(64, (1,1), activation='relu')(x)\n",
    "x = Conv2D(192, (3,3), padding='same', activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "\n",
    "# inception_3a\n",
    "x = Inception(x, 64, 96, 128, 16, 32, 32)\n",
    "# inception_3b\n",
    "x = Inception(x, 128, 128, 192, 32, 96, 64)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "\n",
    "# inception_4a\n",
    "x = Inception(x, 192, 96, 208, 16, 48, 64)\n",
    "# Auxiliary Classifier 0\n",
    "softmax0 = AuxiliaryClassifier(x)\n",
    "# inception_4b\n",
    "x = Inception(x, 160, 112, 224, 24, 64, 64)\n",
    "# inception_4c\n",
    "x = Inception(x, 128, 128, 256, 24, 64, 64)\n",
    "# inception_4d\n",
    "x = Inception(x, 112, 114, 288, 32, 64, 64)\n",
    "# Auxiliary Classifier 1\n",
    "softmax1 = AuxiliaryClassifier(x)\n",
    "# inception_4e\n",
    "x = Inception(x, 256, 160, 320, 32, 128, 128)\n",
    "\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "\n",
    "# inception_5a\n",
    "x = Inception(x, 256, 160, 320, 32, 128, 128)\n",
    "# inception_5b\n",
    "x = Inception(x, 384, 192, 384, 48, 128, 128)\n",
    "\n",
    "# Main classifier\n",
    "softmax2 = MainClassifier(x)\n",
    "\n",
    "#[softmax0, softmax1, softmax2]\n",
    "model = Model(input, outputs=softmax2, name=\"googLenet\")\n",
    "#model.build(input)\n",
    "model.compile(optimizer='sgd', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "model.get_config()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "18000/18000 [==============================] - 57s 3ms/step - loss: 0.1535 - acc: 0.9584 - val_loss: 0.0540 - val_acc: 0.9815\n",
      "Epoch 2/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0715 - acc: 0.9806 - val_loss: 0.0545 - val_acc: 0.9845\n",
      "Epoch 3/12\n",
      "18000/18000 [==============================] - 56s 3ms/step - loss: 0.0547 - acc: 0.9844 - val_loss: 0.0599 - val_acc: 0.9820\n",
      "Epoch 4/12\n",
      "18000/18000 [==============================] - 54s 3ms/step - loss: 0.0401 - acc: 0.9883 - val_loss: 0.0693 - val_acc: 0.9795\n",
      "Epoch 5/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0314 - acc: 0.9911 - val_loss: 0.1001 - val_acc: 0.9705\n",
      "Epoch 6/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0219 - acc: 0.9933 - val_loss: 0.1082 - val_acc: 0.9690\n",
      "Epoch 7/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0188 - acc: 0.9943 - val_loss: 0.0434 - val_acc: 0.9880\n",
      "Epoch 8/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0134 - acc: 0.9969 - val_loss: 0.0247 - val_acc: 0.9925\n",
      "Epoch 9/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0346 - val_acc: 0.9905\n",
      "Epoch 10/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0094 - acc: 0.9978 - val_loss: 0.0263 - val_acc: 0.9915\n",
      "Epoch 11/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0082 - acc: 0.9978 - val_loss: 0.0340 - val_acc: 0.9895\n",
      "Epoch 12/12\n",
      "18000/18000 [==============================] - 55s 3ms/step - loss: 0.0076 - acc: 0.9978 - val_loss: 0.0440 - val_acc: 0.9880\n",
      "2000/2000 [==============================] - 3s 1ms/step\n",
      "loss:  0.06674277622526278\n",
      "acc:  0.9765\n"
     ]
    }
   ],
   "source": [
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 224, 224, 3)   (20000,)   (2000, 224, 224, 3)   (2000,)\n"
     ]
    }
   ],
   "source": [
    "########## googLenet 2014 ###################\n",
    "# 数据预处理\n",
    "from dpl import utils\n",
    "\n",
    "dims = 224\n",
    "train_nums = 20000\n",
    "test_nums = 2000\n",
    "\n",
    "from dpl.alexnet import data_io\n",
    "(train_data, train_label),(test_data, test_label) = data_io.load_data(\"../data/alex_mnist_data_\" + str(dims) + \".npz\")\n",
    "\n",
    "print(train_data.shape, \" \", train_label.shape, \" \", test_data.shape, \" \", test_label.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_192 (Conv2D)             (None, 112, 112, 64) 9472        input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_210 (BatchN (None, 112, 112, 64) 256         conv2d_192[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_139 (Activation)     (None, 112, 112, 64) 0           batch_normalization_210[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_22 (MaxPooling2D) (None, 56, 56, 64)   0           activation_139[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_193 (Conv2D)             (None, 56, 56, 64)   36928       max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_211 (BatchN (None, 56, 56, 64)   256         conv2d_193[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_140 (Activation)     (None, 56, 56, 64)   0           batch_normalization_211[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_194 (Conv2D)             (None, 56, 56, 64)   36928       activation_140[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_195 (Conv2D)             (None, 56, 56, 64)   4160        max_pooling2d_22[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_212 (BatchN (None, 56, 56, 64)   256         conv2d_194[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_213 (BatchN (None, 56, 56, 64)   256         conv2d_195[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_64 (Add)                    (None, 56, 56, 64)   0           batch_normalization_212[0][0]    \n",
      "                                                                 batch_normalization_213[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_141 (Activation)     (None, 56, 56, 64)   0           add_64[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_196 (Conv2D)             (None, 56, 56, 64)   36928       activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_214 (BatchN (None, 56, 56, 64)   256         conv2d_196[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_142 (Activation)     (None, 56, 56, 64)   0           batch_normalization_214[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_197 (Conv2D)             (None, 56, 56, 64)   36928       activation_142[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_215 (BatchN (None, 56, 56, 64)   256         conv2d_197[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_216 (BatchN (None, 56, 56, 64)   256         activation_141[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_65 (Add)                    (None, 56, 56, 64)   0           batch_normalization_215[0][0]    \n",
      "                                                                 batch_normalization_216[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_143 (Activation)     (None, 56, 56, 64)   0           add_65[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_198 (Conv2D)             (None, 56, 56, 64)   36928       activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_217 (BatchN (None, 56, 56, 64)   256         conv2d_198[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_144 (Activation)     (None, 56, 56, 64)   0           batch_normalization_217[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_199 (Conv2D)             (None, 56, 56, 64)   36928       activation_144[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_218 (BatchN (None, 56, 56, 64)   256         conv2d_199[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_219 (BatchN (None, 56, 56, 64)   256         activation_143[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_66 (Add)                    (None, 56, 56, 64)   0           batch_normalization_218[0][0]    \n",
      "                                                                 batch_normalization_219[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_145 (Activation)     (None, 56, 56, 64)   0           add_66[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_200 (Conv2D)             (None, 28, 28, 128)  73856       activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_220 (BatchN (None, 28, 28, 128)  512         conv2d_200[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_146 (Activation)     (None, 28, 28, 128)  0           batch_normalization_220[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_201 (Conv2D)             (None, 28, 28, 128)  147584      activation_146[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_202 (Conv2D)             (None, 28, 28, 128)  8320        activation_145[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_221 (BatchN (None, 28, 28, 128)  512         conv2d_201[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_222 (BatchN (None, 28, 28, 128)  512         conv2d_202[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_67 (Add)                    (None, 28, 28, 128)  0           batch_normalization_221[0][0]    \n",
      "                                                                 batch_normalization_222[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_147 (Activation)     (None, 28, 28, 128)  0           add_67[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_203 (Conv2D)             (None, 28, 28, 128)  147584      activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_223 (BatchN (None, 28, 28, 128)  512         conv2d_203[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_148 (Activation)     (None, 28, 28, 128)  0           batch_normalization_223[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_204 (Conv2D)             (None, 28, 28, 128)  147584      activation_148[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_224 (BatchN (None, 28, 28, 128)  512         conv2d_204[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_225 (BatchN (None, 28, 28, 128)  512         activation_147[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_68 (Add)                    (None, 28, 28, 128)  0           batch_normalization_224[0][0]    \n",
      "                                                                 batch_normalization_225[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_149 (Activation)     (None, 28, 28, 128)  0           add_68[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_205 (Conv2D)             (None, 28, 28, 128)  147584      activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_226 (BatchN (None, 28, 28, 128)  512         conv2d_205[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_150 (Activation)     (None, 28, 28, 128)  0           batch_normalization_226[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_206 (Conv2D)             (None, 28, 28, 128)  147584      activation_150[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_227 (BatchN (None, 28, 28, 128)  512         conv2d_206[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_228 (BatchN (None, 28, 28, 128)  512         activation_149[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_69 (Add)                    (None, 28, 28, 128)  0           batch_normalization_227[0][0]    \n",
      "                                                                 batch_normalization_228[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_151 (Activation)     (None, 28, 28, 128)  0           add_69[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_207 (Conv2D)             (None, 28, 28, 128)  147584      activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_229 (BatchN (None, 28, 28, 128)  512         conv2d_207[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_152 (Activation)     (None, 28, 28, 128)  0           batch_normalization_229[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_208 (Conv2D)             (None, 28, 28, 128)  147584      activation_152[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_230 (BatchN (None, 28, 28, 128)  512         conv2d_208[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_231 (BatchN (None, 28, 28, 128)  512         activation_151[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_70 (Add)                    (None, 28, 28, 128)  0           batch_normalization_230[0][0]    \n",
      "                                                                 batch_normalization_231[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_153 (Activation)     (None, 28, 28, 128)  0           add_70[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_209 (Conv2D)             (None, 14, 14, 256)  295168      activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_232 (BatchN (None, 14, 14, 256)  1024        conv2d_209[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_154 (Activation)     (None, 14, 14, 256)  0           batch_normalization_232[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_210 (Conv2D)             (None, 14, 14, 256)  590080      activation_154[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_211 (Conv2D)             (None, 14, 14, 256)  33024       activation_153[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_233 (BatchN (None, 14, 14, 256)  1024        conv2d_210[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_234 (BatchN (None, 14, 14, 256)  1024        conv2d_211[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_71 (Add)                    (None, 14, 14, 256)  0           batch_normalization_233[0][0]    \n",
      "                                                                 batch_normalization_234[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_155 (Activation)     (None, 14, 14, 256)  0           add_71[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_212 (Conv2D)             (None, 14, 14, 256)  590080      activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_235 (BatchN (None, 14, 14, 256)  1024        conv2d_212[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_156 (Activation)     (None, 14, 14, 256)  0           batch_normalization_235[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_213 (Conv2D)             (None, 14, 14, 256)  590080      activation_156[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_236 (BatchN (None, 14, 14, 256)  1024        conv2d_213[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_237 (BatchN (None, 14, 14, 256)  1024        activation_155[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_72 (Add)                    (None, 14, 14, 256)  0           batch_normalization_236[0][0]    \n",
      "                                                                 batch_normalization_237[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_157 (Activation)     (None, 14, 14, 256)  0           add_72[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_214 (Conv2D)             (None, 14, 14, 256)  590080      activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_238 (BatchN (None, 14, 14, 256)  1024        conv2d_214[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_158 (Activation)     (None, 14, 14, 256)  0           batch_normalization_238[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_215 (Conv2D)             (None, 14, 14, 256)  590080      activation_158[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_239 (BatchN (None, 14, 14, 256)  1024        conv2d_215[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_240 (BatchN (None, 14, 14, 256)  1024        activation_157[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_73 (Add)                    (None, 14, 14, 256)  0           batch_normalization_239[0][0]    \n",
      "                                                                 batch_normalization_240[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_159 (Activation)     (None, 14, 14, 256)  0           add_73[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_216 (Conv2D)             (None, 14, 14, 256)  590080      activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_241 (BatchN (None, 14, 14, 256)  1024        conv2d_216[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_160 (Activation)     (None, 14, 14, 256)  0           batch_normalization_241[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_217 (Conv2D)             (None, 14, 14, 256)  590080      activation_160[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_242 (BatchN (None, 14, 14, 256)  1024        conv2d_217[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_243 (BatchN (None, 14, 14, 256)  1024        activation_159[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_74 (Add)                    (None, 14, 14, 256)  0           batch_normalization_242[0][0]    \n",
      "                                                                 batch_normalization_243[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_161 (Activation)     (None, 14, 14, 256)  0           add_74[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_218 (Conv2D)             (None, 14, 14, 256)  590080      activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_244 (BatchN (None, 14, 14, 256)  1024        conv2d_218[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_162 (Activation)     (None, 14, 14, 256)  0           batch_normalization_244[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_219 (Conv2D)             (None, 14, 14, 256)  590080      activation_162[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_245 (BatchN (None, 14, 14, 256)  1024        conv2d_219[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_246 (BatchN (None, 14, 14, 256)  1024        activation_161[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_75 (Add)                    (None, 14, 14, 256)  0           batch_normalization_245[0][0]    \n",
      "                                                                 batch_normalization_246[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_163 (Activation)     (None, 14, 14, 256)  0           add_75[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_220 (Conv2D)             (None, 14, 14, 256)  590080      activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_247 (BatchN (None, 14, 14, 256)  1024        conv2d_220[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_164 (Activation)     (None, 14, 14, 256)  0           batch_normalization_247[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_221 (Conv2D)             (None, 14, 14, 256)  590080      activation_164[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_248 (BatchN (None, 14, 14, 256)  1024        conv2d_221[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_249 (BatchN (None, 14, 14, 256)  1024        activation_163[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_76 (Add)                    (None, 14, 14, 256)  0           batch_normalization_248[0][0]    \n",
      "                                                                 batch_normalization_249[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_165 (Activation)     (None, 14, 14, 256)  0           add_76[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_222 (Conv2D)             (None, 7, 7, 512)    1180160     activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_250 (BatchN (None, 7, 7, 512)    2048        conv2d_222[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_166 (Activation)     (None, 7, 7, 512)    0           batch_normalization_250[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_223 (Conv2D)             (None, 7, 7, 512)    2359808     activation_166[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_224 (Conv2D)             (None, 7, 7, 512)    131584      activation_165[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_251 (BatchN (None, 7, 7, 512)    2048        conv2d_223[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_252 (BatchN (None, 7, 7, 512)    2048        conv2d_224[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_77 (Add)                    (None, 7, 7, 512)    0           batch_normalization_251[0][0]    \n",
      "                                                                 batch_normalization_252[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_167 (Activation)     (None, 7, 7, 512)    0           add_77[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_225 (Conv2D)             (None, 7, 7, 512)    2359808     activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_253 (BatchN (None, 7, 7, 512)    2048        conv2d_225[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_168 (Activation)     (None, 7, 7, 512)    0           batch_normalization_253[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_226 (Conv2D)             (None, 7, 7, 512)    2359808     activation_168[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_254 (BatchN (None, 7, 7, 512)    2048        conv2d_226[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_255 (BatchN (None, 7, 7, 512)    2048        activation_167[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_78 (Add)                    (None, 7, 7, 512)    0           batch_normalization_254[0][0]    \n",
      "                                                                 batch_normalization_255[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_169 (Activation)     (None, 7, 7, 512)    0           add_78[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_227 (Conv2D)             (None, 7, 7, 512)    2359808     activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_256 (BatchN (None, 7, 7, 512)    2048        conv2d_227[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_170 (Activation)     (None, 7, 7, 512)    0           batch_normalization_256[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_228 (Conv2D)             (None, 7, 7, 512)    2359808     activation_170[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_257 (BatchN (None, 7, 7, 512)    2048        conv2d_228[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_258 (BatchN (None, 7, 7, 512)    2048        activation_169[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_79 (Add)                    (None, 7, 7, 512)    0           batch_normalization_257[0][0]    \n",
      "                                                                 batch_normalization_258[0][0]    \n",
      "__________________________________________________________________________________________________\n",
      "activation_171 (Activation)     (None, 7, 7, 512)    0           add_79[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_8 (AveragePoo (None, 1, 1, 512)    0           activation_171[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_12 (Dropout)            (None, 1, 1, 512)    0           average_pooling2d_8[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "flatten_10 (Flatten)            (None, 512)          0           dropout_12[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_23 (Dense)                (None, 1000)         513000      flatten_10[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_13 (Dropout)            (None, 1000)         0           dense_23[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_24 (Dense)                (None, 10)           10010       dropout_13[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,848,898\n",
      "Trainable params: 21,826,114\n",
      "Non-trainable params: 22,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet 2015\n",
    "from keras.layers import Dense, Conv2D\n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "def conv2d_bn(input, nums_kernal, size, strides=1, padding = 'same'):\n",
    "    x = Conv2D(nums_kernal, size, padding=padding, strides=strides)(input)\n",
    "    x = BatchNormalization()(x)\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# 匹配输入尺度和输出尺度\n",
    "# 每个convn_x 第一层调用\n",
    "def conv_block34(input, filter_nums1, filter_nums2, strides=2):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (3,3), strides=strides)\n",
    "    x = Conv2D(filter_nums2, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = Conv2D(filter_nums2, (1,1), strides=strides)(input)\n",
    "    short_cut = BatchNormalization()(short_cut)\n",
    "    # add\n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# identity mapping\n",
    "# 紧接conv_block34 调用\n",
    "def identity_block34(input, filter_nums1, filter_nums2):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (3,3))\n",
    "    x = Conv2D(filter_nums2, (3,3), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = BatchNormalization()(input)\n",
    "    \n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# 匹配输入尺度和输出尺度\n",
    "# 每个convn_x 第一层调用\n",
    "def conv_block(input, filter_nums1, filter_nums2, filter_nums3, strides=2):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (1,1), strides=strides)\n",
    "    x = conv2d_bn(x, filter_nums2, (3,3))\n",
    "    x = Conv2D(filter_nums3, (1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = Conv2D(filter_nums3, (1,1), strides=strides)(input)\n",
    "    short_cut = BatchNormalization()(short_cut)\n",
    "    # add\n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "# identity mapping\n",
    "# 紧接conv_block 调用\n",
    "def identity_block(input, filter_nums1, filter_nums2, filter_nums3):\n",
    "    # branch_normal\n",
    "    x = conv2d_bn(input, filter_nums1, (1,1))\n",
    "    x = conv2d_bn(x, filter_nums2, (3,3))\n",
    "    x = Conv2D(filter_nums3, (1,1))(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    # branch_shortcut\n",
    "    short_cut = BatchNormalization()(input)\n",
    "    \n",
    "    x = keras.layers.add([x, short_cut])\n",
    "    return Activation('relu')(x)\n",
    "\n",
    "def full_block(input):\n",
    "    x = AveragePooling2D(pool_size=(7,7))(input)\n",
    "    x = Dropout(0.4)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(1000, activation='relu')(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "    output = Dense(10, activation='softmax')(x)\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_27 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1062 (Conv2D)            (None, 112, 112, 64) 9472        input_27[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1315 (Batch (None, 112, 112, 64) 256         conv2d_1062[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_961 (Activation)     (None, 112, 112, 64) 0           batch_normalization_1315[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_35 (MaxPooling2D) (None, 56, 56, 64)   0           activation_961[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1063 (Conv2D)            (None, 56, 56, 64)   36928       max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1316 (Batch (None, 56, 56, 64)   256         conv2d_1063[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_962 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1316[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1064 (Conv2D)            (None, 56, 56, 64)   36928       activation_962[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1065 (Conv2D)            (None, 56, 56, 64)   4160        max_pooling2d_35[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1317 (Batch (None, 56, 56, 64)   256         conv2d_1064[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1318 (Batch (None, 56, 56, 64)   256         conv2d_1065[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_345 (Add)                   (None, 56, 56, 64)   0           batch_normalization_1317[0][0]   \n",
      "                                                                 batch_normalization_1318[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_963 (Activation)     (None, 56, 56, 64)   0           add_345[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1066 (Conv2D)            (None, 56, 56, 64)   36928       activation_963[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1319 (Batch (None, 56, 56, 64)   256         conv2d_1066[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_964 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1319[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1067 (Conv2D)            (None, 56, 56, 64)   36928       activation_964[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1320 (Batch (None, 56, 56, 64)   256         conv2d_1067[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1321 (Batch (None, 56, 56, 64)   256         activation_963[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_346 (Add)                   (None, 56, 56, 64)   0           batch_normalization_1320[0][0]   \n",
      "                                                                 batch_normalization_1321[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_965 (Activation)     (None, 56, 56, 64)   0           add_346[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1068 (Conv2D)            (None, 56, 56, 64)   36928       activation_965[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1322 (Batch (None, 56, 56, 64)   256         conv2d_1068[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_966 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1322[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1069 (Conv2D)            (None, 56, 56, 64)   36928       activation_966[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1323 (Batch (None, 56, 56, 64)   256         conv2d_1069[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1324 (Batch (None, 56, 56, 64)   256         activation_965[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_347 (Add)                   (None, 56, 56, 64)   0           batch_normalization_1323[0][0]   \n",
      "                                                                 batch_normalization_1324[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_967 (Activation)     (None, 56, 56, 64)   0           add_347[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1070 (Conv2D)            (None, 28, 28, 128)  73856       activation_967[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1325 (Batch (None, 28, 28, 128)  512         conv2d_1070[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_968 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1325[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1071 (Conv2D)            (None, 28, 28, 128)  147584      activation_968[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1072 (Conv2D)            (None, 28, 28, 128)  8320        activation_967[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1326 (Batch (None, 28, 28, 128)  512         conv2d_1071[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1327 (Batch (None, 28, 28, 128)  512         conv2d_1072[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_348 (Add)                   (None, 28, 28, 128)  0           batch_normalization_1326[0][0]   \n",
      "                                                                 batch_normalization_1327[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_969 (Activation)     (None, 28, 28, 128)  0           add_348[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1073 (Conv2D)            (None, 28, 28, 128)  147584      activation_969[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1328 (Batch (None, 28, 28, 128)  512         conv2d_1073[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_970 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1328[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1074 (Conv2D)            (None, 28, 28, 128)  147584      activation_970[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1329 (Batch (None, 28, 28, 128)  512         conv2d_1074[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1330 (Batch (None, 28, 28, 128)  512         activation_969[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_349 (Add)                   (None, 28, 28, 128)  0           batch_normalization_1329[0][0]   \n",
      "                                                                 batch_normalization_1330[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_971 (Activation)     (None, 28, 28, 128)  0           add_349[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1075 (Conv2D)            (None, 28, 28, 128)  147584      activation_971[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1331 (Batch (None, 28, 28, 128)  512         conv2d_1075[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_972 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1331[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1076 (Conv2D)            (None, 28, 28, 128)  147584      activation_972[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1332 (Batch (None, 28, 28, 128)  512         conv2d_1076[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1333 (Batch (None, 28, 28, 128)  512         activation_971[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_350 (Add)                   (None, 28, 28, 128)  0           batch_normalization_1332[0][0]   \n",
      "                                                                 batch_normalization_1333[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_973 (Activation)     (None, 28, 28, 128)  0           add_350[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1077 (Conv2D)            (None, 28, 28, 128)  147584      activation_973[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1334 (Batch (None, 28, 28, 128)  512         conv2d_1077[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_974 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1334[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1078 (Conv2D)            (None, 28, 28, 128)  147584      activation_974[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1335 (Batch (None, 28, 28, 128)  512         conv2d_1078[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1336 (Batch (None, 28, 28, 128)  512         activation_973[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_351 (Add)                   (None, 28, 28, 128)  0           batch_normalization_1335[0][0]   \n",
      "                                                                 batch_normalization_1336[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_975 (Activation)     (None, 28, 28, 128)  0           add_351[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1079 (Conv2D)            (None, 14, 14, 256)  295168      activation_975[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1337 (Batch (None, 14, 14, 256)  1024        conv2d_1079[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_976 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1337[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1080 (Conv2D)            (None, 14, 14, 256)  590080      activation_976[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1081 (Conv2D)            (None, 14, 14, 256)  33024       activation_975[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1338 (Batch (None, 14, 14, 256)  1024        conv2d_1080[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1339 (Batch (None, 14, 14, 256)  1024        conv2d_1081[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_352 (Add)                   (None, 14, 14, 256)  0           batch_normalization_1338[0][0]   \n",
      "                                                                 batch_normalization_1339[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_977 (Activation)     (None, 14, 14, 256)  0           add_352[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1082 (Conv2D)            (None, 14, 14, 256)  590080      activation_977[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1340 (Batch (None, 14, 14, 256)  1024        conv2d_1082[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_978 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1340[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1083 (Conv2D)            (None, 14, 14, 256)  590080      activation_978[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1341 (Batch (None, 14, 14, 256)  1024        conv2d_1083[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1342 (Batch (None, 14, 14, 256)  1024        activation_977[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_353 (Add)                   (None, 14, 14, 256)  0           batch_normalization_1341[0][0]   \n",
      "                                                                 batch_normalization_1342[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_979 (Activation)     (None, 14, 14, 256)  0           add_353[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1084 (Conv2D)            (None, 14, 14, 256)  590080      activation_979[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1343 (Batch (None, 14, 14, 256)  1024        conv2d_1084[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_980 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1343[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1085 (Conv2D)            (None, 14, 14, 256)  590080      activation_980[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1344 (Batch (None, 14, 14, 256)  1024        conv2d_1085[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1345 (Batch (None, 14, 14, 256)  1024        activation_979[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_354 (Add)                   (None, 14, 14, 256)  0           batch_normalization_1344[0][0]   \n",
      "                                                                 batch_normalization_1345[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_981 (Activation)     (None, 14, 14, 256)  0           add_354[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1086 (Conv2D)            (None, 14, 14, 256)  590080      activation_981[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1346 (Batch (None, 14, 14, 256)  1024        conv2d_1086[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_982 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1346[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1087 (Conv2D)            (None, 14, 14, 256)  590080      activation_982[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1347 (Batch (None, 14, 14, 256)  1024        conv2d_1087[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1348 (Batch (None, 14, 14, 256)  1024        activation_981[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_355 (Add)                   (None, 14, 14, 256)  0           batch_normalization_1347[0][0]   \n",
      "                                                                 batch_normalization_1348[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_983 (Activation)     (None, 14, 14, 256)  0           add_355[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1088 (Conv2D)            (None, 14, 14, 256)  590080      activation_983[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1349 (Batch (None, 14, 14, 256)  1024        conv2d_1088[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_984 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1349[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1089 (Conv2D)            (None, 14, 14, 256)  590080      activation_984[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1350 (Batch (None, 14, 14, 256)  1024        conv2d_1089[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1351 (Batch (None, 14, 14, 256)  1024        activation_983[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_356 (Add)                   (None, 14, 14, 256)  0           batch_normalization_1350[0][0]   \n",
      "                                                                 batch_normalization_1351[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_985 (Activation)     (None, 14, 14, 256)  0           add_356[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1090 (Conv2D)            (None, 14, 14, 256)  590080      activation_985[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1352 (Batch (None, 14, 14, 256)  1024        conv2d_1090[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_986 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1352[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1091 (Conv2D)            (None, 14, 14, 256)  590080      activation_986[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1353 (Batch (None, 14, 14, 256)  1024        conv2d_1091[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1354 (Batch (None, 14, 14, 256)  1024        activation_985[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_357 (Add)                   (None, 14, 14, 256)  0           batch_normalization_1353[0][0]   \n",
      "                                                                 batch_normalization_1354[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_987 (Activation)     (None, 14, 14, 256)  0           add_357[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1092 (Conv2D)            (None, 7, 7, 512)    1180160     activation_987[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1355 (Batch (None, 7, 7, 512)    2048        conv2d_1092[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_988 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1355[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1093 (Conv2D)            (None, 7, 7, 512)    2359808     activation_988[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1094 (Conv2D)            (None, 7, 7, 512)    131584      activation_987[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1356 (Batch (None, 7, 7, 512)    2048        conv2d_1093[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1357 (Batch (None, 7, 7, 512)    2048        conv2d_1094[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_358 (Add)                   (None, 7, 7, 512)    0           batch_normalization_1356[0][0]   \n",
      "                                                                 batch_normalization_1357[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_989 (Activation)     (None, 7, 7, 512)    0           add_358[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1095 (Conv2D)            (None, 7, 7, 512)    2359808     activation_989[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1358 (Batch (None, 7, 7, 512)    2048        conv2d_1095[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_990 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1358[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1096 (Conv2D)            (None, 7, 7, 512)    2359808     activation_990[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1359 (Batch (None, 7, 7, 512)    2048        conv2d_1096[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1360 (Batch (None, 7, 7, 512)    2048        activation_989[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_359 (Add)                   (None, 7, 7, 512)    0           batch_normalization_1359[0][0]   \n",
      "                                                                 batch_normalization_1360[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_991 (Activation)     (None, 7, 7, 512)    0           add_359[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1097 (Conv2D)            (None, 7, 7, 512)    2359808     activation_991[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1361 (Batch (None, 7, 7, 512)    2048        conv2d_1097[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_992 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1361[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1098 (Conv2D)            (None, 7, 7, 512)    2359808     activation_992[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1362 (Batch (None, 7, 7, 512)    2048        conv2d_1098[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1363 (Batch (None, 7, 7, 512)    2048        activation_991[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_360 (Add)                   (None, 7, 7, 512)    0           batch_normalization_1362[0][0]   \n",
      "                                                                 batch_normalization_1363[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_993 (Activation)     (None, 7, 7, 512)    0           add_360[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_18 (AveragePo (None, 1, 1, 512)    0           activation_993[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_32 (Dropout)            (None, 1, 1, 512)    0           average_pooling2d_18[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_20 (Flatten)            (None, 512)          0           dropout_32[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_43 (Dense)                (None, 1000)         513000      flatten_20[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_33 (Dropout)            (None, 1000)         0           dense_43[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_44 (Dense)                (None, 10)           10010       dropout_33[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 21,848,898\n",
      "Trainable params: 21,826,114\n",
      "Non-trainable params: 22,784\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet 18 34\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "depth = 34\n",
    "assert depth in [18, 34]\n",
    "conv_nums = []\n",
    "if depth == 18:\n",
    "    conv_nums=[2,2,2,2]\n",
    "elif depth == 34:\n",
    "    conv_nums=[3,4,6,3]\n",
    "\n",
    "# conv1 112*112\n",
    "input = Input(shape=(224,224,3))\n",
    "x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "\n",
    "# conv2_x 56*56 3subs\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = conv_block34(x, 64, 64, 1) #1\n",
    "for i in range(conv_nums[0]-1):\n",
    "    x = identity_block34(x, 64, 64) #2\n",
    "\n",
    "# conv3_x 28*28 4subs\n",
    "x = conv_block34(x, 128, 128) #1\n",
    "for i in range(conv_nums[1]-1):\n",
    "    x = identity_block34(x, 128, 128) #3\n",
    "\n",
    "# conv4_x 14*14 6subs\n",
    "x = conv_block34(x, 256, 256) #1\n",
    "for i in range(conv_nums[2]-1):\n",
    "    x = identity_block34(x, 256, 256) #2\n",
    "\n",
    "\n",
    "# conv5_x 7*7 3subs\n",
    "x = conv_block34(x, 512, 512) #1\n",
    "for i in range(conv_nums[3]-1):\n",
    "    x = identity_block34(x, 512, 512) #2\n",
    "\n",
    "# avg_pool 1\n",
    "x = full_block(x)\n",
    "\n",
    "model = Model(input, x, name=\"resnet\")\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 18000 samples, validate on 2000 samples\n",
      "Epoch 1/12\n",
      "18000/18000 [==============================] - 117s 7ms/step - loss: 0.7878 - acc: 0.7377 - val_loss: 0.2447 - val_acc: 0.9310\n",
      "Epoch 2/12\n",
      "18000/18000 [==============================] - 78s 4ms/step - loss: 0.1245 - acc: 0.9637 - val_loss: 0.1046 - val_acc: 0.9680\n",
      "Epoch 3/12\n",
      "18000/18000 [==============================] - 78s 4ms/step - loss: 0.0676 - acc: 0.9798 - val_loss: 0.1511 - val_acc: 0.9600\n",
      "Epoch 4/12\n",
      "18000/18000 [==============================] - 78s 4ms/step - loss: 0.0440 - acc: 0.9867 - val_loss: 0.0702 - val_acc: 0.9825\n",
      "Epoch 5/12\n",
      "18000/18000 [==============================] - 79s 4ms/step - loss: 0.0278 - acc: 0.9923 - val_loss: 0.4375 - val_acc: 0.9025\n",
      "Epoch 6/12\n",
      "18000/18000 [==============================] - 80s 4ms/step - loss: 0.0244 - acc: 0.9927 - val_loss: 0.0645 - val_acc: 0.9820\n",
      "Epoch 7/12\n",
      "18000/18000 [==============================] - 79s 4ms/step - loss: 0.0165 - acc: 0.9954 - val_loss: 0.1212 - val_acc: 0.9705\n",
      "Epoch 8/12\n",
      "18000/18000 [==============================] - 80s 4ms/step - loss: 0.0114 - acc: 0.9970 - val_loss: 0.0331 - val_acc: 0.9895\n",
      "Epoch 9/12\n",
      "18000/18000 [==============================] - 78s 4ms/step - loss: 0.0088 - acc: 0.9975 - val_loss: 0.3886 - val_acc: 0.9225\n",
      "Epoch 10/12\n",
      "18000/18000 [==============================] - 79s 4ms/step - loss: 0.0103 - acc: 0.9972 - val_loss: 0.0655 - val_acc: 0.9820\n",
      "Epoch 11/12\n",
      "18000/18000 [==============================] - 79s 4ms/step - loss: 0.0119 - acc: 0.9969 - val_loss: 0.0684 - val_acc: 0.9815\n",
      "Epoch 12/12\n",
      "18000/18000 [==============================] - 79s 4ms/step - loss: 0.0085 - acc: 0.9975 - val_loss: 0.0347 - val_acc: 0.9900\n",
      "cost:  987\n",
      "2000/2000 [==============================] - 4s 2ms/step\n",
      "loss:  0.04138617030601017\n",
      "acc:  0.987\n"
     ]
    }
   ],
   "source": [
    "from dpl import utils\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_26 (InputLayer)           (None, 224, 224, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_907 (Conv2D)             (None, 112, 112, 64) 9472        input_26[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1114 (Batch (None, 112, 112, 64) 256         conv2d_907[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_810 (Activation)     (None, 112, 112, 64) 0           batch_normalization_1114[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_34 (MaxPooling2D) (None, 56, 56, 64)   0           activation_810[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_908 (Conv2D)             (None, 56, 56, 64)   4160        max_pooling2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1115 (Batch (None, 56, 56, 64)   256         conv2d_908[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_811 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1115[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_909 (Conv2D)             (None, 56, 56, 64)   36928       activation_811[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1116 (Batch (None, 56, 56, 64)   256         conv2d_909[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_812 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1116[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_910 (Conv2D)             (None, 56, 56, 256)  16640       activation_812[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_911 (Conv2D)             (None, 56, 56, 256)  16640       max_pooling2d_34[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1117 (Batch (None, 56, 56, 256)  1024        conv2d_910[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1118 (Batch (None, 56, 56, 256)  1024        conv2d_911[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_295 (Add)                   (None, 56, 56, 256)  0           batch_normalization_1117[0][0]   \n",
      "                                                                 batch_normalization_1118[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_813 (Activation)     (None, 56, 56, 256)  0           add_295[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_912 (Conv2D)             (None, 56, 56, 64)   16448       activation_813[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1119 (Batch (None, 56, 56, 64)   256         conv2d_912[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_814 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1119[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_913 (Conv2D)             (None, 56, 56, 64)   36928       activation_814[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1120 (Batch (None, 56, 56, 64)   256         conv2d_913[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_815 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1120[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_914 (Conv2D)             (None, 56, 56, 256)  16640       activation_815[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1121 (Batch (None, 56, 56, 256)  1024        conv2d_914[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1122 (Batch (None, 56, 56, 256)  1024        activation_813[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_296 (Add)                   (None, 56, 56, 256)  0           batch_normalization_1121[0][0]   \n",
      "                                                                 batch_normalization_1122[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_816 (Activation)     (None, 56, 56, 256)  0           add_296[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_915 (Conv2D)             (None, 56, 56, 64)   16448       activation_816[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1123 (Batch (None, 56, 56, 64)   256         conv2d_915[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_817 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1123[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_916 (Conv2D)             (None, 56, 56, 64)   36928       activation_817[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1124 (Batch (None, 56, 56, 64)   256         conv2d_916[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_818 (Activation)     (None, 56, 56, 64)   0           batch_normalization_1124[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_917 (Conv2D)             (None, 56, 56, 256)  16640       activation_818[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1125 (Batch (None, 56, 56, 256)  1024        conv2d_917[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1126 (Batch (None, 56, 56, 256)  1024        activation_816[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_297 (Add)                   (None, 56, 56, 256)  0           batch_normalization_1125[0][0]   \n",
      "                                                                 batch_normalization_1126[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_819 (Activation)     (None, 56, 56, 256)  0           add_297[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_918 (Conv2D)             (None, 28, 28, 128)  32896       activation_819[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1127 (Batch (None, 28, 28, 128)  512         conv2d_918[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_820 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1127[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_919 (Conv2D)             (None, 28, 28, 128)  147584      activation_820[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1128 (Batch (None, 28, 28, 128)  512         conv2d_919[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_821 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1128[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_920 (Conv2D)             (None, 28, 28, 252)  32508       activation_821[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_921 (Conv2D)             (None, 28, 28, 252)  64764       activation_819[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1129 (Batch (None, 28, 28, 252)  1008        conv2d_920[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1130 (Batch (None, 28, 28, 252)  1008        conv2d_921[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_298 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1129[0][0]   \n",
      "                                                                 batch_normalization_1130[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_822 (Activation)     (None, 28, 28, 252)  0           add_298[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_922 (Conv2D)             (None, 28, 28, 128)  32384       activation_822[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1131 (Batch (None, 28, 28, 128)  512         conv2d_922[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_823 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1131[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_923 (Conv2D)             (None, 28, 28, 128)  147584      activation_823[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1132 (Batch (None, 28, 28, 128)  512         conv2d_923[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_824 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1132[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_924 (Conv2D)             (None, 28, 28, 252)  32508       activation_824[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1133 (Batch (None, 28, 28, 252)  1008        conv2d_924[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1134 (Batch (None, 28, 28, 252)  1008        activation_822[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_299 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1133[0][0]   \n",
      "                                                                 batch_normalization_1134[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_825 (Activation)     (None, 28, 28, 252)  0           add_299[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_925 (Conv2D)             (None, 28, 28, 128)  32384       activation_825[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1135 (Batch (None, 28, 28, 128)  512         conv2d_925[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_826 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1135[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_926 (Conv2D)             (None, 28, 28, 128)  147584      activation_826[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1136 (Batch (None, 28, 28, 128)  512         conv2d_926[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_827 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1136[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_927 (Conv2D)             (None, 28, 28, 252)  32508       activation_827[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1137 (Batch (None, 28, 28, 252)  1008        conv2d_927[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1138 (Batch (None, 28, 28, 252)  1008        activation_825[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_300 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1137[0][0]   \n",
      "                                                                 batch_normalization_1138[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_828 (Activation)     (None, 28, 28, 252)  0           add_300[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_928 (Conv2D)             (None, 28, 28, 128)  32384       activation_828[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1139 (Batch (None, 28, 28, 128)  512         conv2d_928[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_829 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1139[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_929 (Conv2D)             (None, 28, 28, 128)  147584      activation_829[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1140 (Batch (None, 28, 28, 128)  512         conv2d_929[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_830 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1140[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_930 (Conv2D)             (None, 28, 28, 252)  32508       activation_830[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1141 (Batch (None, 28, 28, 252)  1008        conv2d_930[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1142 (Batch (None, 28, 28, 252)  1008        activation_828[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_301 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1141[0][0]   \n",
      "                                                                 batch_normalization_1142[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_831 (Activation)     (None, 28, 28, 252)  0           add_301[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_931 (Conv2D)             (None, 28, 28, 128)  32384       activation_831[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1143 (Batch (None, 28, 28, 128)  512         conv2d_931[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_832 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1143[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_932 (Conv2D)             (None, 28, 28, 128)  147584      activation_832[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1144 (Batch (None, 28, 28, 128)  512         conv2d_932[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_833 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1144[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_933 (Conv2D)             (None, 28, 28, 252)  32508       activation_833[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1145 (Batch (None, 28, 28, 252)  1008        conv2d_933[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1146 (Batch (None, 28, 28, 252)  1008        activation_831[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_302 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1145[0][0]   \n",
      "                                                                 batch_normalization_1146[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_834 (Activation)     (None, 28, 28, 252)  0           add_302[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_934 (Conv2D)             (None, 28, 28, 128)  32384       activation_834[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1147 (Batch (None, 28, 28, 128)  512         conv2d_934[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_835 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1147[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_935 (Conv2D)             (None, 28, 28, 128)  147584      activation_835[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1148 (Batch (None, 28, 28, 128)  512         conv2d_935[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_836 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1148[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_936 (Conv2D)             (None, 28, 28, 252)  32508       activation_836[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1149 (Batch (None, 28, 28, 252)  1008        conv2d_936[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1150 (Batch (None, 28, 28, 252)  1008        activation_834[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_303 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1149[0][0]   \n",
      "                                                                 batch_normalization_1150[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_837 (Activation)     (None, 28, 28, 252)  0           add_303[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_937 (Conv2D)             (None, 28, 28, 128)  32384       activation_837[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1151 (Batch (None, 28, 28, 128)  512         conv2d_937[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_838 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1151[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_938 (Conv2D)             (None, 28, 28, 128)  147584      activation_838[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1152 (Batch (None, 28, 28, 128)  512         conv2d_938[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_839 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1152[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_939 (Conv2D)             (None, 28, 28, 252)  32508       activation_839[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1153 (Batch (None, 28, 28, 252)  1008        conv2d_939[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1154 (Batch (None, 28, 28, 252)  1008        activation_837[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_304 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1153[0][0]   \n",
      "                                                                 batch_normalization_1154[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_840 (Activation)     (None, 28, 28, 252)  0           add_304[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_940 (Conv2D)             (None, 28, 28, 128)  32384       activation_840[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1155 (Batch (None, 28, 28, 128)  512         conv2d_940[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_841 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1155[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_941 (Conv2D)             (None, 28, 28, 128)  147584      activation_841[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1156 (Batch (None, 28, 28, 128)  512         conv2d_941[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_842 (Activation)     (None, 28, 28, 128)  0           batch_normalization_1156[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_942 (Conv2D)             (None, 28, 28, 252)  32508       activation_842[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1157 (Batch (None, 28, 28, 252)  1008        conv2d_942[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1158 (Batch (None, 28, 28, 252)  1008        activation_840[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_305 (Add)                   (None, 28, 28, 252)  0           batch_normalization_1157[0][0]   \n",
      "                                                                 batch_normalization_1158[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_843 (Activation)     (None, 28, 28, 252)  0           add_305[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_943 (Conv2D)             (None, 14, 14, 256)  64768       activation_843[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1159 (Batch (None, 14, 14, 256)  1024        conv2d_943[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_844 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1159[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_944 (Conv2D)             (None, 14, 14, 256)  590080      activation_844[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1160 (Batch (None, 14, 14, 256)  1024        conv2d_944[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_845 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1160[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_945 (Conv2D)             (None, 14, 14, 1024) 263168      activation_845[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_946 (Conv2D)             (None, 14, 14, 1024) 259072      activation_843[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1161 (Batch (None, 14, 14, 1024) 4096        conv2d_945[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1162 (Batch (None, 14, 14, 1024) 4096        conv2d_946[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "add_306 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1161[0][0]   \n",
      "                                                                 batch_normalization_1162[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_846 (Activation)     (None, 14, 14, 1024) 0           add_306[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_947 (Conv2D)             (None, 14, 14, 256)  262400      activation_846[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1163 (Batch (None, 14, 14, 256)  1024        conv2d_947[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_847 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1163[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_948 (Conv2D)             (None, 14, 14, 256)  590080      activation_847[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1164 (Batch (None, 14, 14, 256)  1024        conv2d_948[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_848 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1164[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_949 (Conv2D)             (None, 14, 14, 1024) 263168      activation_848[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1165 (Batch (None, 14, 14, 1024) 4096        conv2d_949[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1166 (Batch (None, 14, 14, 1024) 4096        activation_846[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_307 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1165[0][0]   \n",
      "                                                                 batch_normalization_1166[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_849 (Activation)     (None, 14, 14, 1024) 0           add_307[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_950 (Conv2D)             (None, 14, 14, 256)  262400      activation_849[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1167 (Batch (None, 14, 14, 256)  1024        conv2d_950[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_850 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1167[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_951 (Conv2D)             (None, 14, 14, 256)  590080      activation_850[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1168 (Batch (None, 14, 14, 256)  1024        conv2d_951[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_851 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1168[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_952 (Conv2D)             (None, 14, 14, 1024) 263168      activation_851[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1169 (Batch (None, 14, 14, 1024) 4096        conv2d_952[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1170 (Batch (None, 14, 14, 1024) 4096        activation_849[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_308 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1169[0][0]   \n",
      "                                                                 batch_normalization_1170[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_852 (Activation)     (None, 14, 14, 1024) 0           add_308[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_953 (Conv2D)             (None, 14, 14, 256)  262400      activation_852[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1171 (Batch (None, 14, 14, 256)  1024        conv2d_953[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_853 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1171[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_954 (Conv2D)             (None, 14, 14, 256)  590080      activation_853[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1172 (Batch (None, 14, 14, 256)  1024        conv2d_954[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_854 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1172[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_955 (Conv2D)             (None, 14, 14, 1024) 263168      activation_854[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1173 (Batch (None, 14, 14, 1024) 4096        conv2d_955[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1174 (Batch (None, 14, 14, 1024) 4096        activation_852[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_309 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1173[0][0]   \n",
      "                                                                 batch_normalization_1174[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_855 (Activation)     (None, 14, 14, 1024) 0           add_309[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_956 (Conv2D)             (None, 14, 14, 256)  262400      activation_855[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1175 (Batch (None, 14, 14, 256)  1024        conv2d_956[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_856 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1175[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_957 (Conv2D)             (None, 14, 14, 256)  590080      activation_856[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1176 (Batch (None, 14, 14, 256)  1024        conv2d_957[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_857 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1176[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_958 (Conv2D)             (None, 14, 14, 1024) 263168      activation_857[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1177 (Batch (None, 14, 14, 1024) 4096        conv2d_958[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1178 (Batch (None, 14, 14, 1024) 4096        activation_855[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_310 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1177[0][0]   \n",
      "                                                                 batch_normalization_1178[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_858 (Activation)     (None, 14, 14, 1024) 0           add_310[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_959 (Conv2D)             (None, 14, 14, 256)  262400      activation_858[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1179 (Batch (None, 14, 14, 256)  1024        conv2d_959[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_859 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1179[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_960 (Conv2D)             (None, 14, 14, 256)  590080      activation_859[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1180 (Batch (None, 14, 14, 256)  1024        conv2d_960[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_860 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1180[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_961 (Conv2D)             (None, 14, 14, 1024) 263168      activation_860[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1181 (Batch (None, 14, 14, 1024) 4096        conv2d_961[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1182 (Batch (None, 14, 14, 1024) 4096        activation_858[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_311 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1181[0][0]   \n",
      "                                                                 batch_normalization_1182[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_861 (Activation)     (None, 14, 14, 1024) 0           add_311[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_962 (Conv2D)             (None, 14, 14, 256)  262400      activation_861[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1183 (Batch (None, 14, 14, 256)  1024        conv2d_962[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_862 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1183[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_963 (Conv2D)             (None, 14, 14, 256)  590080      activation_862[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1184 (Batch (None, 14, 14, 256)  1024        conv2d_963[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_863 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1184[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_964 (Conv2D)             (None, 14, 14, 1024) 263168      activation_863[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1185 (Batch (None, 14, 14, 1024) 4096        conv2d_964[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1186 (Batch (None, 14, 14, 1024) 4096        activation_861[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_312 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1185[0][0]   \n",
      "                                                                 batch_normalization_1186[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_864 (Activation)     (None, 14, 14, 1024) 0           add_312[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_965 (Conv2D)             (None, 14, 14, 256)  262400      activation_864[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1187 (Batch (None, 14, 14, 256)  1024        conv2d_965[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_865 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1187[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_966 (Conv2D)             (None, 14, 14, 256)  590080      activation_865[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1188 (Batch (None, 14, 14, 256)  1024        conv2d_966[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_866 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1188[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_967 (Conv2D)             (None, 14, 14, 1024) 263168      activation_866[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1189 (Batch (None, 14, 14, 1024) 4096        conv2d_967[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1190 (Batch (None, 14, 14, 1024) 4096        activation_864[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_313 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1189[0][0]   \n",
      "                                                                 batch_normalization_1190[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_867 (Activation)     (None, 14, 14, 1024) 0           add_313[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_968 (Conv2D)             (None, 14, 14, 256)  262400      activation_867[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1191 (Batch (None, 14, 14, 256)  1024        conv2d_968[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_868 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1191[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_969 (Conv2D)             (None, 14, 14, 256)  590080      activation_868[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1192 (Batch (None, 14, 14, 256)  1024        conv2d_969[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_869 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1192[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_970 (Conv2D)             (None, 14, 14, 1024) 263168      activation_869[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1193 (Batch (None, 14, 14, 1024) 4096        conv2d_970[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1194 (Batch (None, 14, 14, 1024) 4096        activation_867[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_314 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1193[0][0]   \n",
      "                                                                 batch_normalization_1194[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_870 (Activation)     (None, 14, 14, 1024) 0           add_314[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_971 (Conv2D)             (None, 14, 14, 256)  262400      activation_870[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1195 (Batch (None, 14, 14, 256)  1024        conv2d_971[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_871 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1195[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_972 (Conv2D)             (None, 14, 14, 256)  590080      activation_871[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1196 (Batch (None, 14, 14, 256)  1024        conv2d_972[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_872 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1196[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_973 (Conv2D)             (None, 14, 14, 1024) 263168      activation_872[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1197 (Batch (None, 14, 14, 1024) 4096        conv2d_973[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1198 (Batch (None, 14, 14, 1024) 4096        activation_870[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_315 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1197[0][0]   \n",
      "                                                                 batch_normalization_1198[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_873 (Activation)     (None, 14, 14, 1024) 0           add_315[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_974 (Conv2D)             (None, 14, 14, 256)  262400      activation_873[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1199 (Batch (None, 14, 14, 256)  1024        conv2d_974[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_874 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1199[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_975 (Conv2D)             (None, 14, 14, 256)  590080      activation_874[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1200 (Batch (None, 14, 14, 256)  1024        conv2d_975[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_875 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1200[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_976 (Conv2D)             (None, 14, 14, 1024) 263168      activation_875[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1201 (Batch (None, 14, 14, 1024) 4096        conv2d_976[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1202 (Batch (None, 14, 14, 1024) 4096        activation_873[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_316 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1201[0][0]   \n",
      "                                                                 batch_normalization_1202[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_876 (Activation)     (None, 14, 14, 1024) 0           add_316[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_977 (Conv2D)             (None, 14, 14, 256)  262400      activation_876[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1203 (Batch (None, 14, 14, 256)  1024        conv2d_977[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_877 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1203[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_978 (Conv2D)             (None, 14, 14, 256)  590080      activation_877[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1204 (Batch (None, 14, 14, 256)  1024        conv2d_978[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_878 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1204[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_979 (Conv2D)             (None, 14, 14, 1024) 263168      activation_878[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1205 (Batch (None, 14, 14, 1024) 4096        conv2d_979[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1206 (Batch (None, 14, 14, 1024) 4096        activation_876[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_317 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1205[0][0]   \n",
      "                                                                 batch_normalization_1206[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_879 (Activation)     (None, 14, 14, 1024) 0           add_317[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_980 (Conv2D)             (None, 14, 14, 256)  262400      activation_879[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1207 (Batch (None, 14, 14, 256)  1024        conv2d_980[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_880 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1207[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_981 (Conv2D)             (None, 14, 14, 256)  590080      activation_880[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1208 (Batch (None, 14, 14, 256)  1024        conv2d_981[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_881 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1208[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_982 (Conv2D)             (None, 14, 14, 1024) 263168      activation_881[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1209 (Batch (None, 14, 14, 1024) 4096        conv2d_982[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1210 (Batch (None, 14, 14, 1024) 4096        activation_879[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_318 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1209[0][0]   \n",
      "                                                                 batch_normalization_1210[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_882 (Activation)     (None, 14, 14, 1024) 0           add_318[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_983 (Conv2D)             (None, 14, 14, 256)  262400      activation_882[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1211 (Batch (None, 14, 14, 256)  1024        conv2d_983[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_883 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1211[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_984 (Conv2D)             (None, 14, 14, 256)  590080      activation_883[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1212 (Batch (None, 14, 14, 256)  1024        conv2d_984[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_884 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1212[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_985 (Conv2D)             (None, 14, 14, 1024) 263168      activation_884[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1213 (Batch (None, 14, 14, 1024) 4096        conv2d_985[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1214 (Batch (None, 14, 14, 1024) 4096        activation_882[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_319 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1213[0][0]   \n",
      "                                                                 batch_normalization_1214[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_885 (Activation)     (None, 14, 14, 1024) 0           add_319[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_986 (Conv2D)             (None, 14, 14, 256)  262400      activation_885[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1215 (Batch (None, 14, 14, 256)  1024        conv2d_986[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_886 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1215[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_987 (Conv2D)             (None, 14, 14, 256)  590080      activation_886[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1216 (Batch (None, 14, 14, 256)  1024        conv2d_987[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_887 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1216[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_988 (Conv2D)             (None, 14, 14, 1024) 263168      activation_887[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1217 (Batch (None, 14, 14, 1024) 4096        conv2d_988[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1218 (Batch (None, 14, 14, 1024) 4096        activation_885[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_320 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1217[0][0]   \n",
      "                                                                 batch_normalization_1218[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_888 (Activation)     (None, 14, 14, 1024) 0           add_320[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_989 (Conv2D)             (None, 14, 14, 256)  262400      activation_888[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1219 (Batch (None, 14, 14, 256)  1024        conv2d_989[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_889 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1219[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_990 (Conv2D)             (None, 14, 14, 256)  590080      activation_889[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1220 (Batch (None, 14, 14, 256)  1024        conv2d_990[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_890 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1220[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_991 (Conv2D)             (None, 14, 14, 1024) 263168      activation_890[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1221 (Batch (None, 14, 14, 1024) 4096        conv2d_991[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1222 (Batch (None, 14, 14, 1024) 4096        activation_888[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_321 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1221[0][0]   \n",
      "                                                                 batch_normalization_1222[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_891 (Activation)     (None, 14, 14, 1024) 0           add_321[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_992 (Conv2D)             (None, 14, 14, 256)  262400      activation_891[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1223 (Batch (None, 14, 14, 256)  1024        conv2d_992[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_892 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1223[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_993 (Conv2D)             (None, 14, 14, 256)  590080      activation_892[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1224 (Batch (None, 14, 14, 256)  1024        conv2d_993[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_893 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1224[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_994 (Conv2D)             (None, 14, 14, 1024) 263168      activation_893[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1225 (Batch (None, 14, 14, 1024) 4096        conv2d_994[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1226 (Batch (None, 14, 14, 1024) 4096        activation_891[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_322 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1225[0][0]   \n",
      "                                                                 batch_normalization_1226[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_894 (Activation)     (None, 14, 14, 1024) 0           add_322[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_995 (Conv2D)             (None, 14, 14, 256)  262400      activation_894[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1227 (Batch (None, 14, 14, 256)  1024        conv2d_995[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_895 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1227[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_996 (Conv2D)             (None, 14, 14, 256)  590080      activation_895[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1228 (Batch (None, 14, 14, 256)  1024        conv2d_996[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_896 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1228[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_997 (Conv2D)             (None, 14, 14, 1024) 263168      activation_896[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1229 (Batch (None, 14, 14, 1024) 4096        conv2d_997[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1230 (Batch (None, 14, 14, 1024) 4096        activation_894[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_323 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1229[0][0]   \n",
      "                                                                 batch_normalization_1230[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_897 (Activation)     (None, 14, 14, 1024) 0           add_323[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_998 (Conv2D)             (None, 14, 14, 256)  262400      activation_897[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1231 (Batch (None, 14, 14, 256)  1024        conv2d_998[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_898 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1231[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_999 (Conv2D)             (None, 14, 14, 256)  590080      activation_898[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1232 (Batch (None, 14, 14, 256)  1024        conv2d_999[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "activation_899 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1232[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1000 (Conv2D)            (None, 14, 14, 1024) 263168      activation_899[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1233 (Batch (None, 14, 14, 1024) 4096        conv2d_1000[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1234 (Batch (None, 14, 14, 1024) 4096        activation_897[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_324 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1233[0][0]   \n",
      "                                                                 batch_normalization_1234[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_900 (Activation)     (None, 14, 14, 1024) 0           add_324[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1001 (Conv2D)            (None, 14, 14, 256)  262400      activation_900[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1235 (Batch (None, 14, 14, 256)  1024        conv2d_1001[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_901 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1235[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1002 (Conv2D)            (None, 14, 14, 256)  590080      activation_901[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1236 (Batch (None, 14, 14, 256)  1024        conv2d_1002[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_902 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1236[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1003 (Conv2D)            (None, 14, 14, 1024) 263168      activation_902[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1237 (Batch (None, 14, 14, 1024) 4096        conv2d_1003[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1238 (Batch (None, 14, 14, 1024) 4096        activation_900[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_325 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1237[0][0]   \n",
      "                                                                 batch_normalization_1238[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_903 (Activation)     (None, 14, 14, 1024) 0           add_325[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1004 (Conv2D)            (None, 14, 14, 256)  262400      activation_903[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1239 (Batch (None, 14, 14, 256)  1024        conv2d_1004[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_904 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1239[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1005 (Conv2D)            (None, 14, 14, 256)  590080      activation_904[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1240 (Batch (None, 14, 14, 256)  1024        conv2d_1005[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_905 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1240[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1006 (Conv2D)            (None, 14, 14, 1024) 263168      activation_905[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1241 (Batch (None, 14, 14, 1024) 4096        conv2d_1006[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1242 (Batch (None, 14, 14, 1024) 4096        activation_903[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_326 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1241[0][0]   \n",
      "                                                                 batch_normalization_1242[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_906 (Activation)     (None, 14, 14, 1024) 0           add_326[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1007 (Conv2D)            (None, 14, 14, 256)  262400      activation_906[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1243 (Batch (None, 14, 14, 256)  1024        conv2d_1007[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_907 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1243[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1008 (Conv2D)            (None, 14, 14, 256)  590080      activation_907[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1244 (Batch (None, 14, 14, 256)  1024        conv2d_1008[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_908 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1244[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1009 (Conv2D)            (None, 14, 14, 1024) 263168      activation_908[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1245 (Batch (None, 14, 14, 1024) 4096        conv2d_1009[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1246 (Batch (None, 14, 14, 1024) 4096        activation_906[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_327 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1245[0][0]   \n",
      "                                                                 batch_normalization_1246[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_909 (Activation)     (None, 14, 14, 1024) 0           add_327[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1010 (Conv2D)            (None, 14, 14, 256)  262400      activation_909[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1247 (Batch (None, 14, 14, 256)  1024        conv2d_1010[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_910 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1247[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1011 (Conv2D)            (None, 14, 14, 256)  590080      activation_910[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1248 (Batch (None, 14, 14, 256)  1024        conv2d_1011[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_911 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1248[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1012 (Conv2D)            (None, 14, 14, 1024) 263168      activation_911[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1249 (Batch (None, 14, 14, 1024) 4096        conv2d_1012[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1250 (Batch (None, 14, 14, 1024) 4096        activation_909[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_328 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1249[0][0]   \n",
      "                                                                 batch_normalization_1250[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_912 (Activation)     (None, 14, 14, 1024) 0           add_328[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1013 (Conv2D)            (None, 14, 14, 256)  262400      activation_912[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1251 (Batch (None, 14, 14, 256)  1024        conv2d_1013[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_913 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1251[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1014 (Conv2D)            (None, 14, 14, 256)  590080      activation_913[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1252 (Batch (None, 14, 14, 256)  1024        conv2d_1014[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_914 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1252[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1015 (Conv2D)            (None, 14, 14, 1024) 263168      activation_914[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1253 (Batch (None, 14, 14, 1024) 4096        conv2d_1015[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1254 (Batch (None, 14, 14, 1024) 4096        activation_912[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_329 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1253[0][0]   \n",
      "                                                                 batch_normalization_1254[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_915 (Activation)     (None, 14, 14, 1024) 0           add_329[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1016 (Conv2D)            (None, 14, 14, 256)  262400      activation_915[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1255 (Batch (None, 14, 14, 256)  1024        conv2d_1016[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_916 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1255[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1017 (Conv2D)            (None, 14, 14, 256)  590080      activation_916[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1256 (Batch (None, 14, 14, 256)  1024        conv2d_1017[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_917 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1256[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1018 (Conv2D)            (None, 14, 14, 1024) 263168      activation_917[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1257 (Batch (None, 14, 14, 1024) 4096        conv2d_1018[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1258 (Batch (None, 14, 14, 1024) 4096        activation_915[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_330 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1257[0][0]   \n",
      "                                                                 batch_normalization_1258[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_918 (Activation)     (None, 14, 14, 1024) 0           add_330[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1019 (Conv2D)            (None, 14, 14, 256)  262400      activation_918[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1259 (Batch (None, 14, 14, 256)  1024        conv2d_1019[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_919 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1259[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1020 (Conv2D)            (None, 14, 14, 256)  590080      activation_919[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1260 (Batch (None, 14, 14, 256)  1024        conv2d_1020[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_920 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1260[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1021 (Conv2D)            (None, 14, 14, 1024) 263168      activation_920[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1261 (Batch (None, 14, 14, 1024) 4096        conv2d_1021[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1262 (Batch (None, 14, 14, 1024) 4096        activation_918[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_331 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1261[0][0]   \n",
      "                                                                 batch_normalization_1262[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_921 (Activation)     (None, 14, 14, 1024) 0           add_331[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1022 (Conv2D)            (None, 14, 14, 256)  262400      activation_921[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1263 (Batch (None, 14, 14, 256)  1024        conv2d_1022[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_922 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1263[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1023 (Conv2D)            (None, 14, 14, 256)  590080      activation_922[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1264 (Batch (None, 14, 14, 256)  1024        conv2d_1023[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_923 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1264[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1024 (Conv2D)            (None, 14, 14, 1024) 263168      activation_923[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1265 (Batch (None, 14, 14, 1024) 4096        conv2d_1024[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1266 (Batch (None, 14, 14, 1024) 4096        activation_921[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_332 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1265[0][0]   \n",
      "                                                                 batch_normalization_1266[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_924 (Activation)     (None, 14, 14, 1024) 0           add_332[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1025 (Conv2D)            (None, 14, 14, 256)  262400      activation_924[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1267 (Batch (None, 14, 14, 256)  1024        conv2d_1025[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_925 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1267[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1026 (Conv2D)            (None, 14, 14, 256)  590080      activation_925[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1268 (Batch (None, 14, 14, 256)  1024        conv2d_1026[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_926 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1268[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1027 (Conv2D)            (None, 14, 14, 1024) 263168      activation_926[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1269 (Batch (None, 14, 14, 1024) 4096        conv2d_1027[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1270 (Batch (None, 14, 14, 1024) 4096        activation_924[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_333 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1269[0][0]   \n",
      "                                                                 batch_normalization_1270[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_927 (Activation)     (None, 14, 14, 1024) 0           add_333[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1028 (Conv2D)            (None, 14, 14, 256)  262400      activation_927[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1271 (Batch (None, 14, 14, 256)  1024        conv2d_1028[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_928 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1271[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1029 (Conv2D)            (None, 14, 14, 256)  590080      activation_928[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1272 (Batch (None, 14, 14, 256)  1024        conv2d_1029[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_929 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1272[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1030 (Conv2D)            (None, 14, 14, 1024) 263168      activation_929[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1273 (Batch (None, 14, 14, 1024) 4096        conv2d_1030[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1274 (Batch (None, 14, 14, 1024) 4096        activation_927[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_334 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1273[0][0]   \n",
      "                                                                 batch_normalization_1274[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_930 (Activation)     (None, 14, 14, 1024) 0           add_334[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1031 (Conv2D)            (None, 14, 14, 256)  262400      activation_930[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1275 (Batch (None, 14, 14, 256)  1024        conv2d_1031[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_931 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1275[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1032 (Conv2D)            (None, 14, 14, 256)  590080      activation_931[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1276 (Batch (None, 14, 14, 256)  1024        conv2d_1032[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_932 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1276[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1033 (Conv2D)            (None, 14, 14, 1024) 263168      activation_932[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1277 (Batch (None, 14, 14, 1024) 4096        conv2d_1033[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1278 (Batch (None, 14, 14, 1024) 4096        activation_930[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_335 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1277[0][0]   \n",
      "                                                                 batch_normalization_1278[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_933 (Activation)     (None, 14, 14, 1024) 0           add_335[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1034 (Conv2D)            (None, 14, 14, 256)  262400      activation_933[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1279 (Batch (None, 14, 14, 256)  1024        conv2d_1034[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_934 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1279[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1035 (Conv2D)            (None, 14, 14, 256)  590080      activation_934[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1280 (Batch (None, 14, 14, 256)  1024        conv2d_1035[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_935 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1280[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1036 (Conv2D)            (None, 14, 14, 1024) 263168      activation_935[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1281 (Batch (None, 14, 14, 1024) 4096        conv2d_1036[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1282 (Batch (None, 14, 14, 1024) 4096        activation_933[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_336 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1281[0][0]   \n",
      "                                                                 batch_normalization_1282[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_936 (Activation)     (None, 14, 14, 1024) 0           add_336[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1037 (Conv2D)            (None, 14, 14, 256)  262400      activation_936[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1283 (Batch (None, 14, 14, 256)  1024        conv2d_1037[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_937 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1283[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1038 (Conv2D)            (None, 14, 14, 256)  590080      activation_937[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1284 (Batch (None, 14, 14, 256)  1024        conv2d_1038[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_938 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1284[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1039 (Conv2D)            (None, 14, 14, 1024) 263168      activation_938[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1285 (Batch (None, 14, 14, 1024) 4096        conv2d_1039[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1286 (Batch (None, 14, 14, 1024) 4096        activation_936[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_337 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1285[0][0]   \n",
      "                                                                 batch_normalization_1286[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_939 (Activation)     (None, 14, 14, 1024) 0           add_337[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1040 (Conv2D)            (None, 14, 14, 256)  262400      activation_939[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1287 (Batch (None, 14, 14, 256)  1024        conv2d_1040[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_940 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1287[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1041 (Conv2D)            (None, 14, 14, 256)  590080      activation_940[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1288 (Batch (None, 14, 14, 256)  1024        conv2d_1041[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_941 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1288[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1042 (Conv2D)            (None, 14, 14, 1024) 263168      activation_941[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1289 (Batch (None, 14, 14, 1024) 4096        conv2d_1042[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1290 (Batch (None, 14, 14, 1024) 4096        activation_939[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_338 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1289[0][0]   \n",
      "                                                                 batch_normalization_1290[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_942 (Activation)     (None, 14, 14, 1024) 0           add_338[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1043 (Conv2D)            (None, 14, 14, 256)  262400      activation_942[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1291 (Batch (None, 14, 14, 256)  1024        conv2d_1043[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_943 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1291[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1044 (Conv2D)            (None, 14, 14, 256)  590080      activation_943[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1292 (Batch (None, 14, 14, 256)  1024        conv2d_1044[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_944 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1292[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1045 (Conv2D)            (None, 14, 14, 1024) 263168      activation_944[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1293 (Batch (None, 14, 14, 1024) 4096        conv2d_1045[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1294 (Batch (None, 14, 14, 1024) 4096        activation_942[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_339 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1293[0][0]   \n",
      "                                                                 batch_normalization_1294[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_945 (Activation)     (None, 14, 14, 1024) 0           add_339[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1046 (Conv2D)            (None, 14, 14, 256)  262400      activation_945[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1295 (Batch (None, 14, 14, 256)  1024        conv2d_1046[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_946 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1295[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1047 (Conv2D)            (None, 14, 14, 256)  590080      activation_946[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1296 (Batch (None, 14, 14, 256)  1024        conv2d_1047[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_947 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1296[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1048 (Conv2D)            (None, 14, 14, 1024) 263168      activation_947[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1297 (Batch (None, 14, 14, 1024) 4096        conv2d_1048[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1298 (Batch (None, 14, 14, 1024) 4096        activation_945[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_340 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1297[0][0]   \n",
      "                                                                 batch_normalization_1298[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_948 (Activation)     (None, 14, 14, 1024) 0           add_340[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1049 (Conv2D)            (None, 14, 14, 256)  262400      activation_948[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1299 (Batch (None, 14, 14, 256)  1024        conv2d_1049[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_949 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1299[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1050 (Conv2D)            (None, 14, 14, 256)  590080      activation_949[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1300 (Batch (None, 14, 14, 256)  1024        conv2d_1050[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_950 (Activation)     (None, 14, 14, 256)  0           batch_normalization_1300[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1051 (Conv2D)            (None, 14, 14, 1024) 263168      activation_950[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1301 (Batch (None, 14, 14, 1024) 4096        conv2d_1051[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1302 (Batch (None, 14, 14, 1024) 4096        activation_948[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_341 (Add)                   (None, 14, 14, 1024) 0           batch_normalization_1301[0][0]   \n",
      "                                                                 batch_normalization_1302[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_951 (Activation)     (None, 14, 14, 1024) 0           add_341[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1052 (Conv2D)            (None, 7, 7, 512)    524800      activation_951[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1303 (Batch (None, 7, 7, 512)    2048        conv2d_1052[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_952 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1303[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1053 (Conv2D)            (None, 7, 7, 512)    2359808     activation_952[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1304 (Batch (None, 7, 7, 512)    2048        conv2d_1053[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_953 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1304[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1054 (Conv2D)            (None, 7, 7, 2048)   1050624     activation_953[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1055 (Conv2D)            (None, 7, 7, 2048)   2099200     activation_951[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1305 (Batch (None, 7, 7, 2048)   8192        conv2d_1054[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1306 (Batch (None, 7, 7, 2048)   8192        conv2d_1055[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "add_342 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1305[0][0]   \n",
      "                                                                 batch_normalization_1306[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_954 (Activation)     (None, 7, 7, 2048)   0           add_342[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1056 (Conv2D)            (None, 7, 7, 512)    1049088     activation_954[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1307 (Batch (None, 7, 7, 512)    2048        conv2d_1056[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_955 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1307[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1057 (Conv2D)            (None, 7, 7, 512)    2359808     activation_955[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1308 (Batch (None, 7, 7, 512)    2048        conv2d_1057[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_956 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1308[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1058 (Conv2D)            (None, 7, 7, 2048)   1050624     activation_956[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1309 (Batch (None, 7, 7, 2048)   8192        conv2d_1058[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1310 (Batch (None, 7, 7, 2048)   8192        activation_954[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_343 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1309[0][0]   \n",
      "                                                                 batch_normalization_1310[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_957 (Activation)     (None, 7, 7, 2048)   0           add_343[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1059 (Conv2D)            (None, 7, 7, 512)    1049088     activation_957[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1311 (Batch (None, 7, 7, 512)    2048        conv2d_1059[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_958 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1311[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1060 (Conv2D)            (None, 7, 7, 512)    2359808     activation_958[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1312 (Batch (None, 7, 7, 512)    2048        conv2d_1060[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "activation_959 (Activation)     (None, 7, 7, 512)    0           batch_normalization_1312[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1061 (Conv2D)            (None, 7, 7, 2048)   1050624     activation_959[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1313 (Batch (None, 7, 7, 2048)   8192        conv2d_1061[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1314 (Batch (None, 7, 7, 2048)   8192        activation_957[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "add_344 (Add)                   (None, 7, 7, 2048)   0           batch_normalization_1313[0][0]   \n",
      "                                                                 batch_normalization_1314[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "activation_960 (Activation)     (None, 7, 7, 2048)   0           add_344[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "average_pooling2d_17 (AveragePo (None, 1, 1, 2048)   0           activation_960[0][0]             \n",
      "__________________________________________________________________________________________________\n",
      "dropout_30 (Dropout)            (None, 1, 1, 2048)   0           average_pooling2d_17[0][0]       \n",
      "__________________________________________________________________________________________________\n",
      "flatten_19 (Flatten)            (None, 2048)         0           dropout_30[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dense_41 (Dense)                (None, 1000)         2049000     flatten_19[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "dropout_31 (Dropout)            (None, 1000)         0           dense_41[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_42 (Dense)                (None, 10)           10010       dropout_31[0][0]                 \n",
      "==================================================================================================\n",
      "Total params: 59,688,542\n",
      "Trainable params: 59,457,374\n",
      "Non-trainable params: 231,168\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# resnet 50,101,152 2015\n",
    "from keras.models import Model\n",
    "from keras.layers import Dense, Conv2D, Flatten, MaxPooling2D \n",
    "from keras.layers import BatchNormalization, Input, Activation\n",
    "\n",
    "depth = 152\n",
    "assert depth in [50,101,152]\n",
    "conv_nums = [3,4,6,3]\n",
    "if depth == 101:\n",
    "    conv_nums[2]=23\n",
    "elif depth == 152:\n",
    "    conv_nums[1]=8\n",
    "    conv_nums[2]=36\n",
    "\n",
    "# conv1 112*112\n",
    "input = Input(shape=(224,224,3))\n",
    "x = conv2d_bn(input, 64, size=(7,7), strides=2)\n",
    "\n",
    "# conv2_x 56*56 3subs\n",
    "x = MaxPooling2D(pool_size=(3,3), strides=2, padding='same')(x)\n",
    "x = conv_block(x, 64, 64, 256, 1) #1\n",
    "for i in range(conv_nums[0]-1):\n",
    "    x = identity_block(x, 64, 64, 256) #2\n",
    "\n",
    "# conv3_x 28*28 4subs\n",
    "x = conv_block(x, 128, 128, 252) #1\n",
    "for i in range(conv_nums[1]-1):\n",
    "    x = identity_block(x, 128, 128, 252) #2\n",
    "\n",
    "# conv4_x 14*14 6subs\n",
    "x = conv_block(x, 256, 256, 1024) #1\n",
    "for i in range(conv_nums[2]-1):\n",
    "    x = identity_block(x, 256, 256, 1024) #2\n",
    "\n",
    "# conv5_x 7*7 3subs\n",
    "x = conv_block(x, 512, 512, 2048) #1\n",
    "for i in range(conv_nums[3]-1):\n",
    "    x = identity_block(x, 512, 512, 2048) #2\n",
    "\n",
    "# avg_pool 1\n",
    "x = full_block(x)\n",
    "\n",
    "model = Model(input, x, name=\"resnet\")\n",
    "model.compile(optimizer='sgd', \n",
    "              loss='sparse_categorical_crossentropy', \n",
    "              metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dpl import utils\n",
    "utils.trainAndEvaluateData(model, train_data, train_label, test_data, test_label)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
